---
title: "Theoretical Framework"
subtitle: "Conceptual Foundations for Intelligent Portfolio Management"
format:
  html:
    toc: true
    toc-depth: 4
    code-fold: true
    code-tools: true
    number-sections: true
    theme: cosmo
    css: styles.css
execute:
  warning: false
  message: false
  cache: true
---

```{r setup, include=FALSE}

# Load required libraries
library(tidyverse)
library(plotly)
library(knitr)
library(kableExtra)

# Set default chunk options for fast execution
knitr::opts_chunk$set(
  echo = TRUE,
  cache = TRUE,
  warning = FALSE,
  message = FALSE
)

```

# Theoretical Framework Overview {#sec-overview}

This research project establishes a comprehensive methodological framework built upon three interconnected pillars that collectively address the complex challenge of agricultural commodities portfolio optimization under uncertainty. Each pillar represents a distinct yet complementary approach to understanding and managing financial risk in volatile markets.

::: {.callout-note icon=false appearance="default"}
## Research Foundation

**Core Research Question:** How can we integrate advanced volatility modeling, multi-objective optimization, and adaptive learning to create robust portfolio management strategies for agricultural commodity markets?

This question motivates our theoretical framework, which synthesizes insights from financial econometrics, operations research, and computational intelligence.
:::

## Interactive Research Framework Map

```{mermaid}

graph TB
    A[Agricultural Commodity Markets<br/>High Volatility & Regime Changes] --> B[Pillar 1: Volatility Modeling]
    A --> C[Pillar 2: Multi-Objective Optimization]
    A --> D[Pillar 3: Reinforcement Learning]
    
    B --> E[GAMLSS Models<br/>Distributional Flexibility]
    B --> F[MSGARCH Models<br/>Regime Detection]
    
    C --> G[NSGA-II Algorithm<br/>Pareto Optimization]
    C --> H[Differential Evolution<br/>Non-Convex Search]
    
    D --> I[Q-Learning<br/>Value-Based RL]
    D --> J[Policy Gradient<br/>Direct Policy Search]
    
    E --> K[Integrated Framework]
    F --> K
    G --> K
    H --> K
    I --> K
    J --> K
    
    K --> L[Adaptive Portfolio<br/>Management System]
    
    L --> M[Expected Outcomes]
    M --> N[Patent Development]
    M --> O[Scientific Publications]
    M --> P[Practical Tools]
    
    style A fill:#ff6b35,stroke:#333,stroke-width:3px,color:#fff
    style K fill:#003d7a,stroke:#333,stroke-width:3px,color:#fff
    style L fill:#28a745,stroke:#333,stroke-width:3px,color:#fff
    style B fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff
    style C fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff
    style D fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff
    style M fill:#ffc107,stroke:#333,stroke-width:2px,color:#333
    
```

---

# Pillar 1: Advanced Volatility Modeling {#sec-volatility}

## Motivation and Context

Traditional portfolio optimization relies on assumptions of normally distributed returns with constant volatility. However, agricultural commodity markets exhibit several stylized facts that violate these assumptions, including heavy tails, asymmetry, volatility clustering, and regime changes. These characteristics necessitate more sophisticated modeling approaches to capture the true risk profile of commodity portfolios.

```{r volatility-comparison, fig.width=10, fig.height=5}
# Generate synthetic data to demonstrate stylized facts (fast execution)
set.seed(123)
n <- 500

# Normal distribution vs Student-t (heavy tails)
normal_returns <- rnorm(n, mean = 0, sd = 0.02)
heavy_tail_returns <- rt(n, df = 5) * 0.02

# Create comparison plot
df_comparison <- data.frame(
  Normal = normal_returns,
  HeavyTail = heavy_tail_returns
) %>%
  pivot_longer(cols = everything(), names_to = "Distribution", values_to = "Returns")

p1 <- ggplot(df_comparison, aes(x = Returns, fill = Distribution)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("Normal" = "#6c757d", "HeavyTail" = "#ff6b35")) +
  labs(
    title = "Distribution Comparison: Normal vs Heavy-Tailed Returns",
    subtitle = "Agricultural commodities exhibit fat tails",
    x = "Returns", y = "Density"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "bottom"
  )

print(p1)
```

## GAMLSS: Generalized Additive Models for Location, Scale and Shape {#sec-gamlss}

### Theoretical Foundation

GAMLSS extends traditional regression by modeling all parameters of the distribution, not merely the mean. This approach allows flexible representation of returns with heavy tails and asymmetry through the specification of location, scale, skewness, and kurtosis parameters as functions of covariates.

**Mathematical Formulation:**

The GAMLSS framework models up to four distributional parameters:

$$
\begin{aligned}
\mu_t &= g_1(\mathbf{X}_t^T \boldsymbol{\beta}_1) \quad &&\text{(Location)} \\
\sigma_t &= g_2(\mathbf{X}_t^T \boldsymbol{\beta}_2) \quad &&\text{(Scale)} \\
\nu_t &= g_3(\mathbf{X}_t^T \boldsymbol{\beta}_3) \quad &&\text{(Skewness)} \\
\tau_t &= g_4(\mathbf{X}_t^T \boldsymbol{\beta}_4) \quad &&\text{(Kurtosis)}
\end{aligned}
$$

### Interactive Concept Map: GAMLSS Components

```{mermaid}

graph LR
    A[GAMLSS Framework] --> B[Location μ]
    A --> C[Scale σ]
    A --> D[Skewness ν]
    A --> E[Kurtosis τ]
    
    B --> F[Expected Return<br/>Modeling]
    C --> G[Volatility<br/>Dynamics]
    D --> H[Asymmetric<br/>Risk]
    E --> I[Tail Risk<br/>Management]
    
    F --> J[Portfolio<br/>Optimization]
    G --> J
    H --> J
    I --> J
    
    J --> K[Risk-Adjusted<br/>Allocation]
    
    style A fill:#003d7a,color:#fff,stroke:#333,stroke-width:2px
    style J fill:#28a745,color:#fff,stroke:#333,stroke-width:2px
    style K fill:#ffc107,color:#333,stroke:#333,stroke-width:2px
    
```

### Demonstration: Time-Varying Parameters

```{r gamlss-demo, fig.width=10, fig.height=6}
# Simulate time-varying volatility (fast execution)
set.seed(456)
time <- 1:250
base_vol <- 0.02
vol_cycle <- base_vol * (1 + 0.5 * sin(2 * pi * time / 50))
returns <- rnorm(250, mean = 0.001, sd = vol_cycle)

# Calculate rolling statistics
df_gamlss <- data.frame(
  Time = time,
  Returns = returns,
  Volatility = vol_cycle,
  CumulativeReturn = cumsum(returns)
)

# Create interactive plot
plot_ly(df_gamlss, x = ~Time) %>%
  add_trace(y = ~Returns, type = 'scatter', mode = 'lines', 
            name = 'Daily Returns', line = list(color = '#6c757d', width = 1)) %>%
  add_trace(y = ~Volatility, type = 'scatter', mode = 'lines', 
            name = 'Time-Varying Volatility', 
            line = list(color = '#ff6b35', width = 2),
            yaxis = 'y2') %>%
  layout(
    title = list(text = "GAMLSS Concept: Time-Varying Scale Parameter", 
                 font = list(size = 16, family = "Montserrat")),
    xaxis = list(title = "Time"),
    yaxis = list(title = "Returns", side = "left"),
    yaxis2 = list(title = "Volatility (σₜ)", overlaying = "y", side = "right"),
    legend = list(x = 0.1, y = 0.9),
    hovermode = "x unified"
  )

```

---

## MSGARCH: Markov-Switching GARCH Models {#sec-msgarch}

### Theoretical Foundation

MSGARCH models capture regime-dependent volatility dynamics by assuming that the market alternates between hidden states, such as calm and turbulent regimes. Transitions between regimes are governed by a Markov chain, allowing the model to automatically detect structural breaks and adapt volatility forecasts accordingly.

**Mathematical Formulation:**

The return process follows:

$$
\begin{aligned}
r_t &= \mu_{s_t} + \epsilon_t \\
\epsilon_t &= \sigma_{t,s_t} z_t, \quad z_t \sim D(0, 1) \\
\sigma_{t,s_t}^2 &= \omega_{s_t} + \alpha_{s_t} \epsilon_{t-1}^2 + \beta_{s_t} \sigma_{t-1,s_t}^2
\end{aligned}
$$

where regime state $s_t \in \{1, 2, \ldots, K\}$ follows a Markov chain with transition probabilities $P(s_t = j | s_{t-1} = i) = p_{ij}$.

### Animated Concept: Regime Switching

```{mermaid}

sequenceDiagram
    participant M as Market
    participant R1 as Regime 1<br/>(Low Volatility)
    participant R2 as Regime 2<br/>(High Volatility)
    participant F as Forecast
    
    M->>R1: Normal conditions
    R1->>F: σ² = 0.0004
    Note over R1,F: Calm market<br/>α₁=0.05, β₁=0.90
    
    M->>R2: Crisis/Shock
    R2->>F: σ² = 0.0025
    Note over R2,F: Turbulent market<br/>α₂=0.15, β₂=0.70
    
    R2->>R1: Recovery
    R1->>F: σ² = 0.0004
    Note over R1,F: Return to calm
    
```

### Regime Detection Demonstration

```{r msgarch-demo, fig.width=10, fig.height=7}
# Simulate two-regime process (fast execution)
set.seed(789)
n <- 300
regime <- rep(1, n)

# Introduce regime changes at specific points
regime[100:150] <- 2
regime[220:260] <- 2

# Generate returns based on regime
returns_regime <- numeric(n)
for(i in 1:n) {
  if(regime[i] == 1) {
    returns_regime[i] <- rnorm(1, 0.0005, 0.015)  # Low volatility
  } else {
    returns_regime[i] <- rnorm(1, -0.001, 0.035)  # High volatility
  }
}

# Calculate rolling volatility
rolling_vol <- zoo::rollapply(returns_regime, width = 20, FUN = sd, 
                               fill = NA, align = "right")

df_regime <- data.frame(
  Time = 1:n,
  Returns = returns_regime,
  Regime = factor(regime, labels = c("Low Vol", "High Vol")),
  RollingVol = rolling_vol
)

# Create regime visualization
p2 <- ggplot(df_regime, aes(x = Time)) +
  geom_rect(aes(xmin = Time - 0.5, xmax = Time + 0.5, 
                ymin = -0.1, ymax = 0.1, fill = Regime), 
            alpha = 0.3) +
  geom_line(aes(y = Returns), color = "black", size = 0.5) +
  scale_fill_manual(values = c("Low Vol" = "#28a745", "High Vol" = "#dc3545")) +
  labs(
    title = "MSGARCH: Automatic Regime Detection",
    subtitle = "Model identifies structural breaks and adjusts volatility estimates",
    x = "Time", y = "Returns"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "bottom"
  )

print(p2)

```

### Regime Characteristics Comparison

```{r regime-table}

regime_params <- data.frame(
  Regime = c("Regime 1 (Calm)", "Regime 2 (Turbulent)"),
  `Mean Return` = c("0.05%", "-0.10%"),
  `Volatility` = c("1.5%", "3.5%"),
  `GARCH α` = c("0.05", "0.15"),
  `GARCH β` = c("0.90", "0.70"),
  `Persistence` = c("0.95", "0.85"),
  check.names = FALSE
)

kable(regime_params, 
      caption = "Two-Regime MSGARCH Parameter Estimates",
      align = "lccccc") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE) %>%
  row_spec(1, background = "#d4edda") %>%
  row_spec(2, background = "#f8d7da")

```

---

# Pillar 2: Multi-Objective Optimization {#sec-moo}

## The Portfolio Optimization Problem

Traditional mean-variance optimization considers only two objectives, which fails to capture the multidimensional nature of investment decisions. Real-world investors simultaneously care about return maximization, risk minimization, diversification, liquidity, and robustness, creating a complex multi-objective problem that requires sophisticated solution techniques.

### Multi-Objective Framework

```{mermaid}

graph TB
    A[Portfolio Decision] --> B[Objective 1:<br/>Maximize Return]
    A --> C[Objective 2:<br/>Minimize Risk CVaR]
    A --> D[Objective 3:<br/>Minimize Volatility]
    A --> E[Objective 4:<br/>Maximize Diversification]
    
    B --> F{Conflicting<br/>Objectives}
    C --> F
    D --> F
    E --> F
    
    F --> G[Multi-Objective<br/>Optimization]
    
    G --> H[NSGA-II<br/>Genetic Algorithm]
    G --> I[Differential<br/>Evolution]
    
    H --> J[Pareto-Optimal<br/>Frontier]
    I --> J
    
    J --> K[Portfolio<br/>Selection]
    
    style A fill:#6c757d,color:#fff
    style F fill:#ff6b35,color:#fff
    style G fill:#003d7a,color:#fff
    style J fill:#28a745,color:#fff
    style K fill:#ffc107,color:#333
    
```

## NSGA-II Algorithm Animation {#sec-nsga2}

### Algorithm Workflow

```{mermaid}

graph LR
    A[Initialize<br/>Population<br/>N=100] --> B[Evaluate<br/>Objectives<br/>f₁, f₂, f₃]
    B --> C[Non-Dominated<br/>Sorting<br/>Fronts 1,2,3...]
    C --> D[Crowding<br/>Distance<br/>Diversity]
    D --> E[Selection<br/>Tournament<br/>Size=2]
    E --> F[Crossover<br/>SBX<br/>pc=0.9]
    F --> G[Mutation<br/>Polynomial<br/>pm=1/n]
    G --> H{Generation<br/>< Max?}
    H -->|Yes| B
    H -->|No| I[Pareto<br/>Front<br/>Output]
    
    style A fill:#4a90e2,color:#fff,stroke:#333,stroke-width:2px
    style I fill:#28a745,color:#fff,stroke:#333,stroke-width:2px
    style H fill:#ffc107,color:#333,stroke:#333,stroke-width:2px
```

### NSGA-II Demonstration

```{r nsga2-demo, fig.width=10, fig.height=6}
# Simulate Pareto front (fast execution - analytical)
set.seed(321)
n_solutions <- 100

# Generate Pareto-optimal solutions analytically
# Using convex combination for demonstration
lambda <- seq(0, 1, length.out = n_solutions)
obj1 <- lambda^2 + 0.1  # Risk proxy
obj2 <- -(1 - lambda)^2 + 0.1  # Return proxy (negative because we minimize)
obj3 <- sqrt(lambda * (1 - lambda)) * 0.5  # Volatility

# Add some dominated solutions for visualization
n_dominated <- 30
dominated_obj1 <- runif(n_dominated, min(obj1), max(obj1) * 1.5)
dominated_obj2 <- runif(n_dominated, min(obj2) * 1.5, max(obj2))
dominated_obj3 <- runif(n_dominated, 0, max(obj3) * 1.2)

# Combine data
df_pareto <- data.frame(
  Risk = c(obj1, dominated_obj1),
  Return = c(-obj2, -dominated_obj2),  # Convert back to maximize
  Volatility = c(obj3, dominated_obj3),
  Type = c(rep("Pareto-Optimal", n_solutions), 
           rep("Dominated", n_dominated))
)

# Create 3D interactive plot
plot_ly(df_pareto, x = ~Return, y = ~Risk, z = ~Volatility, 
        color = ~Type, colors = c("#dc3545", "#28a745"),
        type = "scatter3d", mode = "markers",
        marker = list(size = 4)) %>%
  layout(
    title = list(text = "NSGA-II Output: Pareto-Optimal Frontier",
                 font = list(size = 16, family = "Montserrat")),
    scene = list(
      xaxis = list(title = "Expected Return"),
      yaxis = list(title = "Risk (CVaR)"),
      zaxis = list(title = "Volatility (σ)")
    ),
    legend = list(x = 0.7, y = 0.9)
  )
```

## Differential Evolution Process {#sec-de}

### DE Mutation Strategies

```{mermaid}

graph TB
    A[Current Population<br/>P = w₁, w₂, ..., wₙ] --> B[Random Selection<br/>r1, r2, r3]
    
    B --> C[Mutation Vector<br/>v = wᵣ₁ + F×wᵣ₂ - wᵣ₃]
    
    C --> D[Crossover<br/>Mix with current]
    
    D --> E[Trial Solution<br/>u = Cross v, wᵢ]
    
    E --> F{f u < f wᵢ?}
    
    F -->|Yes| G[Replace<br/>wᵢ ← u]
    F -->|No| H[Keep<br/>wᵢ unchanged]
    
    G --> I[Next Generation]
    H --> I
    
    I --> J{Converged?}
    J -->|No| B
    J -->|Yes| K[Optimal<br/>Solution]
    
    style A fill:#4a90e2,color:#fff
    style C fill:#ff6b35,color:#fff
    style F fill:#ffc107,color:#333
    style K fill:#28a745,color:#fff
```

---

# Pillar 3: Reinforcement Learning {#sec-rl}

## From Static to Dynamic Portfolio Management

Traditional optimization produces static solutions that fail to adapt to changing market conditions. Reinforcement learning addresses this limitation by enabling agents to learn adaptive rebalancing policies that respond dynamically to evolving market regimes, correlations, and risk profiles.

### MDP Framework Visualization

```{mermaid}

graph LR
    A[State sₜ<br/>Market Conditions<br/>Portfolio Weights<br/>Regime Probabilities] --> B[Agent<br/>Policy π]
    
    B --> C[Action aₜ<br/>Portfolio<br/>Adjustment<br/>Δw]
    
    C --> D[Environment<br/>Market]
    
    D --> E[Reward rₜ<br/>Return - λ×Risk<br/>- κ×TxCost]
    
    D --> F[Next State<br/>sₜ₊₁]
    
    E --> G[Policy Update<br/>Learn from<br/>Experience]
    F --> G
    
    G --> B
    
    style A fill:#6c757d,color:#fff,stroke:#333,stroke-width:2px
    style B fill:#003d7a,color:#fff,stroke:#333,stroke-width:2px
    style E fill:#28a745,color:#fff,stroke:#333,stroke-width:2px
    style G fill:#ff6b35,color:#fff,stroke:#333,stroke-width:2px
```

## Q-Learning Algorithm Flow {#sec-qlearning}

```{mermaid}

sequenceDiagram
    participant E as Environment
    participant A as Agent
    participant Q as Q-Table
    participant P as Policy
    
    E->>A: State sₜ
    A->>Q: Query Q(sₜ, a)
    Q->>A: Q-values for all actions
    A->>P: ε-greedy selection
    P->>E: Execute action aₜ
    E->>A: Reward rₜ, State sₜ₊₁
    A->>Q: Update Q(sₜ,aₜ) ← Q + α[rₜ + γ max Q(sₜ₊₁,a') - Q(sₜ,aₜ)]
    Note over A,Q: Learning occurs
    Q->>A: Updated Q-values
```

### Q-Learning Demonstration

```{r qlearning-demo, fig.width=10, fig.height=5}
# Simulate Q-learning convergence (fast execution)
set.seed(555)
episodes <- 100
q_values <- cumsum(rnorm(episodes, mean = 0.01, sd = 0.05))
rewards <- cumsum(rnorm(episodes, mean = 0.02, sd = 0.08))

df_rl <- data.frame(
  Episode = 1:episodes,
  QValue = q_values,
  CumulativeReward = rewards
)

# Create convergence plot
plot_ly(df_rl, x = ~Episode) %>%
  add_trace(y = ~QValue, type = 'scatter', mode = 'lines',
            name = 'Q-Value Evolution',
            line = list(color = '#003d7a', width = 2)) %>%
  add_trace(y = ~CumulativeReward, type = 'scatter', mode = 'lines',
            name = 'Cumulative Reward',
            line = list(color = '#28a745', width = 2)) %>%
  layout(
    title = list(text = "Q-Learning Convergence Over Training Episodes",
                 font = list(size = 16, family = "Montserrat")),
    xaxis = list(title = "Training Episode"),
    yaxis = list(title = "Value"),
    legend = list(x = 0.1, y = 0.9),
    hovermode = "x unified"
  )
```

## Policy Gradient Methods (PPO) {#sec-ppo}

### PPO Algorithm Structure

```{mermaid}

graph TB
    A[Actor Network<br/>π_θ s → a] --> B[Collect<br/>Trajectories<br/>Experience Buffer]
    
    B --> C[Compute<br/>Advantages<br/>Â = r + γV s' - V s]
    
    C --> D[Policy Update<br/>Clipped Objective<br/>L^CLIP]
    
    D --> E[Value Update<br/>Critic Loss<br/>V s - Target²]
    
    E --> F{KL Divergence<br/>< threshold?}
    
    F -->|Yes| G[Accept Update<br/>θ ← θ_new]
    F -->|No| H[Reject Update<br/>θ unchanged]
    
    G --> I[Next Iteration]
    H --> I
    
    I --> J{Performance<br/>Satisfactory?}
    J -->|No| A
    J -->|Yes| K[Trained Policy<br/>Deploy]
    
    style A fill:#4a90e2,color:#fff
    style D fill:#ff6b35,color:#fff
    style F fill:#ffc107,color:#333
    style K fill:#28a745,color:#fff
```

---

# Integrated Framework: Complete System {#sec-integration}

## End-to-End Workflow

```{mermaid}

graph TB
    A[Historical Data<br/>Prices, Volumes<br/>Macro Indicators] --> B[Preprocessing<br/>Cleaning<br/>Feature Engineering]
    
    B --> C1[GAMLSS<br/>Distribution Modeling]
    B --> C2[MSGARCH<br/>Regime Detection]
    
    C1 --> D[Forecast<br/>μₜ, σₜ, νₜ, τₜ<br/>Time-Varying Parameters]
    C2 --> E[Forecast<br/>Volatility by Regime<br/>P Regime]
    
    D --> F[Multi-Objective<br/>Optimization]
    E --> F
    
    F --> G1[NSGA-II<br/>Population-Based]
    F --> G2[DEOptim<br/>Differential Evolution]
    
    G1 --> H[Pareto Front<br/>w₁, w₂, ..., wₖ<br/>Trade-off Solutions]
    G2 --> H
    
    H --> I[RL Agent<br/>Q-Learning / PPO<br/>Policy Learning]
    E --> I
    
    I --> J[Dynamic Policy<br/>π: State → Action<br/>Adaptive Selection]
    
    J --> K[Portfolio Execution<br/>Rebalancing<br/>Risk Management]
    
    K --> L[Performance<br/>Monitoring<br/>Metrics Tracking]
    
    L --> M{Feedback Loop<br/>Continuous Learning}
    M --> I
    
    style A fill:#6c757d,color:#fff
    style C1 fill:#4a90e2,color:#fff
    style C2 fill:#4a90e2,color:#fff
    style F fill:#4a90e2,color:#fff
    style H fill:#003d7a,color:#fff
    style I fill:#003d7a,color:#fff
    style J fill:#28a745,color:#fff
    style K fill:#ff6b35,color:#fff
```

## Model Comparison: Traditional vs Integrated Approach

```{r comparison-table}
comparison_df <- data.frame(
  Aspect = c(
    "Return Distribution",
    "Volatility Modeling",
    "Regime Changes",
    "Optimization Objectives",
    "Solution Approach",
    "Adaptability",
    "Tail Risk Management",
    "Computational Cost"
  ),
  `Traditional Approach` = c(
    "Assumes normality",
    "Constant or single GARCH",
    "Not captured",
    "Mean-variance only",
    "Quadratic programming",
    "Static allocation",
    "Limited (variance-based)",
    "Low"
  ),
  `Our Integrated Framework` = c(
    "Flexible (GAMLSS)",
    "Regime-dependent (MSGARCH)",
    "Automatic detection",
    "Multi-objective (Return, CVaR, Diversification)",
    "Evolutionary algorithms",
    "Dynamic RL-based",
    "Explicit (CVaR modeling)",
    "Moderate (parallelizable)"
  ),
  `Advantage` = c(
    "Captures fat tails & asymmetry",
    "Better volatility forecasts",
    "Crisis preparedness",
    "Realistic investor preferences",
    "Handles non-convexity",
    "Responds to market changes",
    "Superior downside protection",
    "Scalable implementation"
  ),
  check.names = FALSE
)

kable(comparison_df,
      caption = "Methodological Comparison: Traditional vs Integrated Framework",
      align = "llll") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = TRUE, 
                font_size = 12) %>%
  column_spec(1, bold = TRUE, width = "15em") %>%
  column_spec(2, width = "18em", background = "#f8f9fa") %>%
  column_spec(3, width = "20em", background = "#d4edda") %>%
  column_spec(4, width = "18em", italic = TRUE)
```

## Performance Comparison Simulation

```{r performance-comparison, fig.width=10, fig.height=6}
# Simulate portfolio performance comparison (fast execution)
set.seed(999)
days <- 252  # One trading year

# Traditional mean-variance
mv_returns <- cumsum(rnorm(days, 0.0004, 0.015))

# Our integrated approach (better Sharpe, lower drawdowns)
integrated_returns <- cumsum(rnorm(days, 0.0006, 0.012))

df_performance <- data.frame(
  Day = rep(1:days, 2),
  CumulativeReturn = c(mv_returns, integrated_returns),
  Strategy = rep(c("Traditional Mean-Variance", 
                   "Integrated Framework"), each = days)
)

# Calculate metrics
sharpe_mv <- (mean(diff(mv_returns)) * 252) / (sd(diff(mv_returns)) * sqrt(252))
sharpe_int <- (mean(diff(integrated_returns)) * 252) / (sd(diff(integrated_returns)) * sqrt(252))

# Interactive performance plot
plot_ly(df_performance, x = ~Day, y = ~CumulativeReturn, 
        color = ~Strategy, 
        colors = c("Traditional Mean-Variance" = "#6c757d", 
                   "Integrated Framework" = "#003d7a"),
        type = "scatter", mode = "lines",
        line = list(width = 2)) %>%
  layout(
    title = list(
      text = sprintf("Simulated Performance Comparison<br><sub>Sharpe: Traditional=%.2f vs Integrated=%.2f</sub>",
                     sharpe_mv, sharpe_int),
      font = list(size = 16, family = "Montserrat")
    ),
    xaxis = list(title = "Trading Days"),
    yaxis = list(title = "Cumulative Return", tickformat = ".2%"),
    legend = list(x = 0.1, y = 0.9),
    hovermode = "x unified"
  )
```

---

# Expected Contributions and Outcomes {#sec-outcomes}

## Scientific Deliverables

Our research framework is expected to generate substantial contributions across multiple dimensions, spanning theoretical innovation, methodological advancement, and practical application in agricultural commodity markets.

### Theoretical Contributions

```{mermaid}

mindmap
  root((Contributions))
    Volatility Modeling
      GAMLSS + MSGARCH Integration
      Regime-Aware Forecasting
      Tail Risk Quantification
    Multi-Objective Optimization
      Beyond Mean-Variance
      Pareto Front Analysis
      Realistic Constraints
    Reinforcement Learning
      Adaptive Rebalancing
      Policy Learning
      Non-Stationary Markets
    Novel Integration
      End-to-End Framework
      Patent Potential
      Open Source Implementation
```

### Expected Outcomes Summary

```{r outcomes-table}
outcomes_df <- data.frame(
  Category = c("Academic", "Academic", "Academic", "Practical", "Practical", "Educational"),
  Deliverable = c(
    "Scientific Articles",
    "Conference Presentations",
    "Patent Application",
    "Open-Source Software",
    "Risk Management Tools",
    "Teaching Materials"
  ),
  Target = c(
    "2-3 publications in Q1/Q2 journals",
    "SPPAIC, SBFin, LAFN conferences",
    "Novel integrated methodology",
    "R/Python packages on GitHub",
    "Portfolio optimization dashboard",
    "Case studies and tutorials"
  ),
  Timeline = c(
    "Months 12-18",
    "Months 9-15",
    "Month 15",
    "Months 6-18",
    "Months 10-16",
    "Months 8-18"
  ),
  Status = c(
    "In Progress",
    "Planned",
    "Planned",
    "In Development",
    "Planned",
    "In Progress"
  ),
  check.names = FALSE
)

kable(outcomes_df,
      caption = "Expected Project Outcomes and Timeline",
      align = "lllll") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE) %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(5, color = "white", background = spec_color(1:6, 
                                                          begin = 0.4, 
                                                          end = 0.9,
                                                          option = "viridis",
                                                          direction = 1))
```

---

# Key References {#sec-references}

## Foundational Literature

**Volatility Modeling:**

- Rigby, R. A., & Stasinopoulos, D. M. (2005). Generalized additive models for location, scale and shape. *Journal of the Royal Statistical Society: Series C (Applied Statistics)*, 54(3), 507-554.

- Ardia, D., Bluteau, K., Boudt, K., Catania, L., & Trottier, D. A. (2019). Markov-switching GARCH models in R: The MSGARCH package. *Journal of Statistical Software*, 91(4), 1-38.

- Engle, R. F. (1982). Autoregressive conditional heteroskedasticity with estimates of the variance of United Kingdom inflation. *Econometrica*, 50(4), 987-1007.

**Multi-Objective Optimization:**

- Markowitz, H. (1952). Portfolio selection. *The Journal of Finance*, 7(1), 77-91.

- Deb, K., Pratap, A., Agarwal, S., & Meyarivan, T. (2002). A fast and elitist multiobjective genetic algorithm: NSGA-II. *IEEE Transactions on Evolutionary Computation*, 6(2), 182-197.

- Storn, R., & Price, K. (1997). Differential evolution—A simple and efficient heuristic for global optimization over continuous spaces. *Journal of Global Optimization*, 11, 341-359.

**Reinforcement Learning:**

- Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press.

- Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal policy optimization algorithms. *arXiv preprint arXiv:1707.06347*.

**Agricultural Commodities:**

- Gorton, G., & Rouwenhorst, K. G. (2006). Facts and fantasies about commodity futures. *Financial Analysts Journal*, 62(2), 47-68.

---

::: {.callout-note appearance="simple"}
## Additional Resources

For detailed implementation examples and extended analysis:

- [Research Methodology](research.html) - Complete methodological framework
- [Time Series Forecasting](time_series_portfolio.html) - GAMLSS and MSGARCH applications  
- [Multi-Objective Optimization](portfolio_multiobj_opt_algos.html) - NSGA-II and DEOptim implementations
- [Reinforcement Learning](pareto_front_reinforcement.html) - RL agent development and training

Visit our [GitHub repository](https://github.com/PAICEconometrics) for reproducible code and data.
:::

---

**Document Information:**

- **Last Updated:** `r format(Sys.Date(), "%B %d, %Y")`
- **Authors:** PAIC Econometrics Research Team, FAE Business School
- **Version:** 1.0
- **License:** CC BY-NC-SA 4.0

---


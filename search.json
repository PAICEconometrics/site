[
  {
    "objectID": "weekly_papers.html",
    "href": "weekly_papers.html",
    "title": "Weekly Papers Digest",
    "section": "",
    "text": "A continuously updated collection of the latest research papers in applied econometrics, multi-period multi-objective optimization, time series forecasting, and reinforcement learning for finance.\nLast Updated: outubro 21, 2025\nTotal Papers Catalogued: 24 papers across 4 weeks"
  },
  {
    "objectID": "weekly_papers.html#about-this-digest",
    "href": "weekly_papers.html#about-this-digest",
    "title": "Weekly Papers Digest",
    "section": "üìñ About This Digest",
    "text": "üìñ About This Digest\nThis page is automatically updated every Friday with the latest scientific papers discovered by our Paper Hunter agent. Each week, we curate articles from:\n\narXiv (econ.EM, q-fin, cs.LG, math.OC)\nSSRN Working Papers\nGoogle Scholar Recent Publications\nMajor Journals (early access articles)\n\n\nCategories\nPapers are classified into four main categories:\n\n\n\n\n\n\n\nCategory\nFocus Area\n\n\n\n\nüîµ Econometrics\nTime series models, volatility forecasting, spillovers, cointegration\n\n\nüü¢ Optimization\nMulti-objective optimization, MOO, NSGA-II/III, portfolio optimization\n\n\nüü£ RL\nReinforcement learning, Q-learning, Deep RL, policy optimization\n\n\nüü† Volatility\nGARCH models, implied volatility, risk modeling, VaR/CVaR"
  },
  {
    "objectID": "weekly_papers.html#october-2025",
    "href": "weekly_papers.html#october-2025",
    "title": "Weekly Papers Digest",
    "section": "üóìÔ∏è October 2025",
    "text": "üóìÔ∏è October 2025\n\nWeek of October 11-17, 2025\n\nSummary\nThis week we found 7 papers across multiple databases. Key highlights include advances in bootstrap robust optimization, candlestick-based covariance estimation, and crisis-aware regime conditioning with CVaR allocation.\nTop Pick: Deep Learning for Portfolio Optimization by Osaf Ali - A comprehensive multi-agent RL approach optimizing multiple risk metrics jointly.\n\n\nüìä Featured Papers\n\n\nüîµ Econometrics (3 papers)\n\n\n1. Beyond Returns: A Candlestick-Based Approach to Spot Covariance Estimation\nAuthors: Yasin Simsek\nVenue: arXiv (econ.EM) | Date: 2025-10-14\nLink: arXiv:2510.12911\nSummary: Introduces an applied econometrics method using high-frequency candlestick data to improve spot covariance estimates‚Äîa critical input for multi-period portfolio models. The paper demonstrates superior performance in capturing intraday volatility patterns.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\nEssential for our volatility modeling component. The candlestick approach could enhance our GARCH/MSGARCH forecasting pipeline.\n\n\n\n2. Spatial and Temporal Boundaries in Difference-in-Differences\nAuthors: Tatsuru Kikuchi\nVenue: arXiv (econ.EM) | Date: 2025-10-13\nLink: arXiv:2510.11013\nSummary: Develops physics-inspired diagnostics using the Navier-Stokes equation framework to validate DID identification over space and time. Practical for credible applied econometric program-evaluation designs.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê\nMethodological interest for causal inference in time series contexts.\n\n\n\n3. (Non-Parametric) Bootstrap Robust Optimization for Portfolios\nAuthors: Daniel C. Oliveira, Grover Guzman, Nick Firoozye\nVenue: arXiv (q-fin.ST) | Date: 2025-10-14\nLink: arXiv:2510.12725\nSummary: Proposes a bootstrap-based robust optimization framework to harden portfolio and trading strategy design against estimation error. Particularly useful for risk-aware (multi-objective) allocation under uncertainty.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\nHIGH PRIORITY - Directly applicable to our portfolio optimization pipeline. Should be incorporated into robustness checks.\n\n\n\nüü¢ Optimization (2 papers)\n\n\n\n4. Deep Learning for Portfolio Optimization: AI-Driven Risk-Adjusted Returns\nAuthors: Osaf Ali\nVenue: SSRN | Date: 2025-10-15\nLink: SSRN 5510579\nSummary: Proposes a hybrid multi-agent RL + multi-objective approach optimizing Sharpe/Sortino/CVaR jointly. The framework is squarely positioned in multi-objective, multi-period portfolio design with deep learning integration.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\nMUST READ - This is exactly our intersection: MOO + RL + portfolios. Excellent benchmark for our own implementation.\nKey Contributions: - Multi-agent architecture for different objectives - Joint optimization of multiple risk metrics - Backtesting on commodity futures data\n\n\n\n5. Evaluating Investment Performance: The p-index and Empirical Efficient Frontier\nAuthors: Jing Li, Bowei Guo, Xinqi Xie, Kuo-Ping Chang\nVenue: arXiv (q-fin.PM) | Date: 2025-10-13\nLink: arXiv:2510.11074\nSummary: Defines a put-option-based risk index and empirical efficient frontier for performance evaluation. Relevant to objective specification and evaluation in portfolio studies.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê\nUseful for benchmarking our Pareto front against traditional efficient frontiers.\n\n\n\nüü£ RL (1 paper)\n\n\n\n6. Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation\nAuthors: Ali Atiah Alzahrani\nVenue: arXiv (cs.LG ‚Üí q-fin.CP) | Date: 2025-10-12\nLink: arXiv:2510.10807\nSummary: Combines regime-aware generative scenarios with a CVaR allocator to improve drawdown control. Directly aligned with multi-objective (risk/return) portfolio optimization under different market regimes.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\nHIGH PRIORITY - The regime-switching + CVaR combination is exactly what we need for our multi-period framework.\n\n\n\nüü† Volatility (1 paper)\n\n\n\n7. On Evaluating Loss Functions for Stock Ranking with Transformer Models\nAuthors: Jan Kwiatkowski, Jaros≈Çaw A. Chudziak\nVenue: arXiv (cs.LG ‚Üí q-fin.PM) | Date: 2025-10-15\nLink: arXiv:2510.14156\nSummary: Benchmarks pointwise/pairwise/listwise loss functions for stock ranking using Transformer architecture. Provides guidance for objective-function choices in portfolio selection pipelines.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê\nUseful for our ML/DL forecasting module, particularly for ranking-based portfolio construction."
  },
  {
    "objectID": "weekly_papers.html#september-2025",
    "href": "weekly_papers.html#september-2025",
    "title": "Weekly Papers Digest",
    "section": "üóìÔ∏è September 2025",
    "text": "üóìÔ∏è September 2025\n\nWeek of September 5-11, 2025\n\nSummary\nStrong week for multi-period optimization papers! Found 6 papers with particular emphasis on neural methods for volatility forecasting and multi-period asset-liability management with reinforcement learning.\nTop Pick: Multi-period Asset-Liability Management with RL by Gao et al.¬†- Breakthrough application of RL to ALM under regime-switching dynamics.\n\n\nüìä Featured Papers\n\n\nüîµ Econometrics (2 papers)\n\n\n8. Neural L√©vy SDE for State-Dependent Risk and Density Forecasting\nAuthors: Ziyao Wang, Svetlozar T. Rachev\nVenue: arXiv (q-fin.RM) | Date: 2025-09-03\nLink: arXiv:2509.01041\nSummary: Proposes a neural jump-diffusion model with state-dependent parameters for multi-horizon density and risk forecasting. Outperforms traditional GARCH models and pure diffusion approaches in volatility forecasting tasks.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\nMUST READ - Neural L√©vy processes are cutting-edge for our volatility modeling. Should compare against our MSGARCH implementation.\nKey Innovations: - State-dependent jump intensity - Multi-horizon density forecasts - Better tail risk estimation than GARCH\n\n\n\n9. Signal from Noise: Neural Network Denoising for Financial Spillovers\nAuthors: Abdullah Karasan, √ñzge Seda Alp\nVenue: arXiv (econ.EM) | Date: 2025-09-03\nLink: arXiv:2509.01156\nSummary: Introduces neural denoising applied to covariance matrices before estimating return/volatility spillovers. Significantly improves systemic risk signal extraction, useful for multi-objective risk constraints.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê\nImportant for our diversification objectives and correlation-based constraints in the optimization model.\n\n\n\nüü¢ Optimization (1 paper)\n\n\n\n10. Mean-Variance Stackelberg Games with Asymmetric Information\nAuthors: Yu-Jui Huang, Shihao Zhu\nVenue: arXiv (q-fin.PM) | Date: 2025-09-05\nLink: arXiv:2509.03669\nSummary: Formulates a leader-follower game with asymmetric information and entropy regularization in mean-variance optimization. Derives equilibrium with Gaussian random strategies‚Äîrelevant for multi-objective optimization under competition/benchmarking scenarios.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê\nTheoretical interest, especially if we consider relative performance objectives.\n\n\n\nüü£ RL (1 paper)\n\n\n\n11. Multi-period Asset-Liability Management with RL in Regime-Switching Market\nAuthors: Zhongqin Gao, Ping Chen, Xun Li, Yan Lv, Wenhao Zhang\nVenue: arXiv (q-fin.PM) | Date: 2025-09-03\nLink: arXiv:2509.03251\nSummary: Resolves multi-period mean-variance optimization with regime switching and uncontrollable liabilities using reinforcement learning and filtering. Demonstrates significant improvements in return/risk metrics compared to classical approaches.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\nBREAKTHROUGH PAPER - This is the exact intersection we‚Äôre working on! Multi-period + RL + regime-switching. Essential reference.\nImplementation Details: - Uses Hidden Markov Model for regime detection - Deep Q-Network for policy learning - Transaction costs and constraints incorporated\n\n\n\nüü† Volatility (2 papers)\n\n\n\n12. Controllable Generation of Implied Volatility Surfaces with VAEs\nAuthors: Jing Wang, Shuaiqiang Liu, Cornelis Vuik\nVenue: arXiv (q-fin.CP) | Date: 2025-09-01\nLink: arXiv:2509.01743\nSummary: Generates controllable implied volatility surfaces (level, slope, curvature, term structure) with no-arbitrage verification using Variational Autoencoders. Useful for scenario simulation and stress testing.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê‚≠ê\nExcellent for generating multiple scenarios in our multi-period optimization framework.\n\n\n\n13. Data-driven Modeling of Multiple Interest Rates with Generalized Vasicek\nAuthors: Pekka Ilmonen, Matti Laurikkala, Kirill Ralchenko, Timo Sottinen, Lauri Viitasaari\nVenue: arXiv (econ.EM) | Date: 2025-09-03\nLink: arXiv:2509.03208\nSummary: Joint modeling of multiple interest rate curves using generalized Vasicek-type models with non-Gaussian innovations. Applicable to asset-liability management and multi-period optimization contexts.\nRelevance to Our Research: ‚≠ê‚≠ê‚≠ê\nRelevant if we extend to fixed-income commodities or futures with interest rate exposure."
  },
  {
    "objectID": "weekly_papers.html#research-impact-tracker",
    "href": "weekly_papers.html#research-impact-tracker",
    "title": "Weekly Papers Digest",
    "section": "üìà Research Impact Tracker",
    "text": "üìà Research Impact Tracker\n\nPapers by Category (All-Time)\n\n\n\n\n\n\n\n\n\n\n\nRelevance Distribution"
  },
  {
    "objectID": "weekly_papers.html#search-by-topic",
    "href": "weekly_papers.html#search-by-topic",
    "title": "Weekly Papers Digest",
    "section": "üîç Search by Topic",
    "text": "üîç Search by Topic\n\nQuick Filters\n\n\nüéØ Portfolio Optimization\nJump to papers\nPapers on multi-objective, multi-period portfolio construction, Pareto frontiers, and allocation strategies.\n\n\nüìä Volatility Forecasting\nJump to papers\nGARCH models, neural volatility, implied volatility surfaces, and risk metrics.\n\n\nü§ñ Reinforcement Learning\nJump to papers\nDeep RL, Q-learning, policy optimization for dynamic trading and portfolio management.\n\n\nüìà Econometric Methods\nJump to papers\nTime series analysis, spillover estimation, cointegration, and causal inference."
  },
  {
    "objectID": "weekly_papers.html#reading-list-by-priority",
    "href": "weekly_papers.html#reading-list-by-priority",
    "title": "Weekly Papers Digest",
    "section": "üìö Reading List by Priority",
    "text": "üìö Reading List by Priority\n\nüî• Must Read (Priority 1)\nEssential papers that directly align with our thesis objectives:\n\nDeep Learning for Portfolio Optimization (Ali, 2025) - Multi-agent RL for MOO\nMulti-period ALM with RL (Gao et al., 2025) - Regime-switching + RL\nNeural L√©vy SDE (Wang & Rachev, 2025) - Advanced volatility forecasting\nBootstrap Robust Optimization (Oliveira et al., 2025) - Portfolio robustness\nCrisis-Aware CVaR Allocation (Alzahrani, 2025) - Regime-conditional allocation\n\n\n\n‚ö° High Priority (Priority 2)\nImportant papers for specific components:\n\nCandlestick Covariance Estimation (Simsek, 2025) - High-frequency data\nSignal from Noise (Karasan & Alp, 2025) - Correlation denoising\nEvaluating Performance (Li et al., 2025) - Benchmarking framework\nControllable IV Surfaces (Wang et al., 2025) - Scenario generation\n\n\n\nüìñ Additional Reading (Priority 3)\nRelevant for methodology and context:\n\nMean-Variance Stackelberg Games (Huang & Zhu, 2025) - Game theory\nDID Boundaries (Kikuchi, 2025) - Causal inference\nStock Ranking Loss Functions (Kwiatkowski & Chudziak, 2025) - ML metrics\nVasicek Interest Rates (Ilmonen et al., 2025) - Fixed income"
  },
  {
    "objectID": "weekly_papers.html#download-options",
    "href": "weekly_papers.html#download-options",
    "title": "Weekly Papers Digest",
    "section": "üì• Download Options",
    "text": "üì• Download Options\n\nComplete Database\nDownload the full database of papers in various formats:\n\nExcel File (.xlsx): Download Master Spreadsheet\nCSV Format (.csv): Download CSV\nBibTeX (.bib): Download Citations\nZotero RDF: Import to Zotero\n\n\n\nWeekly Reports\nIndividual weekly reports in PDF format:\n\nWeek of Oct 11-17, 2025 (PDF)\nWeek of Sep 05-11, 2025 (PDF)"
  },
  {
    "objectID": "weekly_papers.html#stay-updated",
    "href": "weekly_papers.html#stay-updated",
    "title": "Weekly Papers Digest",
    "section": "üîî Stay Updated",
    "text": "üîî Stay Updated\n\nSubscribe to Weekly Digest\nWant to receive these updates directly? Join our mailing list:\n\n Subscribe\n\n\n\nRSS Feed\nAdd our RSS feed to your reader: RSS Feed URL"
  },
  {
    "objectID": "weekly_papers.html#statistics",
    "href": "weekly_papers.html#statistics",
    "title": "Weekly Papers Digest",
    "section": "üìä Statistics",
    "text": "üìä Statistics\n\n\n\n\n\n\nDatabase Metrics\n\n\n\n\nTotal Papers Catalogued: 13\nAverage Papers/Week: 6.5\nMost Active Category: Econometrics (38%)\nHighest Rated Papers: 6 five-star papers\nSources Covered: arXiv, SSRN, Google Scholar\nTime Span: September - October 2025"
  },
  {
    "objectID": "weekly_papers.html#contributing",
    "href": "weekly_papers.html#contributing",
    "title": "Weekly Papers Digest",
    "section": "ü§ù Contributing",
    "text": "ü§ù Contributing\nFound a relevant paper we missed? Submit it here:\nPaper Submission Form: - Paper Title - Authors - Venue/Date - Link - Brief Summary (50-100 words) - Suggested Category\nContact: rodrigo.ozon@fae.edu"
  },
  {
    "objectID": "weekly_papers.html#related-resources",
    "href": "weekly_papers.html#related-resources",
    "title": "Weekly Papers Digest",
    "section": "üìñ Related Resources",
    "text": "üìñ Related Resources\n\nPaper Hunter: Our Automated Agent\nLiterature Review Methodology\nTheoretical Framework\nProject Overview\n\n\n\nüìö PAIC Econometrics | FAE Business School Weekly Papers Digest - Updated Every Friday at 08:00 AM (BRT) Powered by Paper Hunter AI Agent"
  },
  {
    "objectID": "mindmap.html",
    "href": "mindmap.html",
    "title": "Research Mindmap",
    "section": "",
    "text": "Interactive visualization of the methodological structure, official timeline and connections of the project ‚ÄúInnovations in Financial Modeling: AI & Econometrics for Agricultural Commodity Portfolio Optimization‚Äù",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#project-overview",
    "href": "mindmap.html#project-overview",
    "title": "Research Mindmap",
    "section": "Project Overview",
    "text": "Project Overview\nThis conceptual map presents the complete architecture of the PAIC 2025/26 research project, visually organizing the three methodological pillars, the six execution stages according to the official schedule and the expected results aligned with the program guidelines.\n\n\n\n\n\n\nüí° How to Use This Mindmap\n\n\n\n\nExplore interactive nodes to understand each methodological component\nFollow colored connections to comprehend relationships between techniques\nIdentify temporal stages in the PAIC 2025/26 timeline flow\nHover over elements to see detailed descriptions\n\n\n\n\n\n\n\n\n\nüéØ Project‚Äôs Central Objective\n\n\n\nDevelop an integrated model for analysis and optimization of agricultural commodity portfolios, combining:\n\nAdvanced Forecasting (GARCH/MSGARCH + ML/DL)\nMulti-Objective Optimization (NSGA-II, Differential Evolution)\nReinforcement Learning (PPO, adaptive strategies)\n\nGoal: Create tools for risk management and dynamic allocation in commodity markets, with potential for patent and scientific publications.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#interactive-mindmap",
    "href": "mindmap.html#interactive-mindmap",
    "title": "Research Mindmap",
    "section": "Interactive Mindmap",
    "text": "Interactive Mindmap",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#detailed-project-structure",
    "href": "mindmap.html#detailed-project-structure",
    "title": "Research Mindmap",
    "section": "Detailed Project Structure",
    "text": "Detailed Project Structure\n\nüéØ Three Methodological Pillars\n\n\nPILLAR 1: Forecasting\nObjectives: - Forecast expected returns of agricultural commodities - Estimate conditional volatilities and risk regimes - Capture complex temporal dependencies\nMain Methods: - GARCH/MSGARCH: Volatility modeling with regime changes (Markov-Switching) - Machine Learning: LSTM, MLP, XGBoost, LightGBM - Deep Learning: Deep neural networks for non-linear patterns\nTools: - R: rugarch, MSGARCH, forecast - Python: torch, keras, xgboost, statsmodels\n\n\nPILLAR 2: Multi-Objective Optimization\nObjectives: - Determine efficient portfolio compositions - Balance return, risk, and diversification - Generate Pareto frontier with non-dominated solutions\nMain Methods: - NSGA-II: Non-dominated Sorting Genetic Algorithm II - Differential Evolution: Global evolutionary optimization - SPEA2: Strength Pareto Evolutionary Algorithm 2\nTools: - R: DEoptim, mco, nsga2R - Python: pymoo, DEAP, scipy.optimize\n\n\nPILLAR 3: Reinforcement Learning\nObjectives: - Develop dynamic and adaptive trading strategies - Simulate tactical allocation decisions - Implement reallocation policies under uncertainty\nMain Methods: - PPO: Proximal Policy Optimization - Gym Environment: Market simulation for training - Strategies: Momentum, dynamic hedging, trigger-based rebalancing\nTools: - Python: stable-baselines3, gym, ray[rllib] - R: Integration via reticulate",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#official-paic-202526-timeline",
    "href": "mindmap.html#official-paic-202526-timeline",
    "title": "Research Mindmap",
    "section": "üìÖ Official PAIC 2025/26 Timeline",
    "text": "üìÖ Official PAIC 2025/26 Timeline\n\nStage 1: Setup and Governance (Aug-Sep/2025)\n\n\n\n\n\n\nüîß Main Activities\n\n\n\n\nPAIC 2025/26 Opening: August 13, 2025\nCommitment Term Signing\nScope review and research questions definition\nComputational environment setup (R/Python + Git/GitHub)\nData source mapping: YahooQuery, Quandl, FAO, B3, CME\nSuccess criteria and risk management definition\n\n\n\nDeliverables: - Detailed work plan - Structured Git repository - Data sources documentation\n\n\n\nStage 2: Data Collection and Curation (Sep-Oct/2025)\n\n\n\n\n\n\nüìä Main Activities\n\n\n\n\nHistorical commodity series collection (corn, soybeans, meal, soybean oil)\nData cleaning and normalization (frequencies, outliers, contract adjustments)\nFinancial feature engineering: log-return, volatility, drawdown, technical indicators\nExploratory analysis and descriptive statistics\n\n\n\nDeliverables: - Curated and documented dataset - Complete exploratory data analysis (EDA) - Automated collection scripts\n\n\n\nStage 3: Volatility and Return Modeling (Oct-Nov/2025)\n\n\n\n\n\n\nü§ñ Main Activities\n\n\n\n\nGARCH/MSGARCH model estimation (asymmetric distributions, regimes)\nML/DL prototype development: LSTM, MLP for forecasting\nPerformance comparison between econometric and ML models\nüìù Partial Report 1: November 24, 2025\nüé§ 13th SPPAIC: October 24, 2025\n\n\n\nDeliverables: - Calibrated forecasting models - Partial Report 1 (methodology and preliminary results) - Presentation at 13th PAIC Symposium\n\n\n\nStage 4: Optimization and Frontiers (Nov/2025-Jan/2026)\n\n\n\n\n\n\nüéØ Main Activities\n\n\n\n\nNSGA-II and Differential Evolution implementation\nPareto frontier generation (risk-return-diversification trade-offs)\nSensitivity and robustness analysis of solutions\nComparison with benchmarks (buy-and-hold, risk parity, mean-variance)\n\n\n\nDeliverables: - Functional multi-objective optimization algorithms - Efficient portfolios on Pareto frontier - Alternative scenario analyses\n\n\n\nStage 5: RL and Backtesting (Jan-Mar/2026)\n\n\n\n\n\n\nüöÄ Main Activities\n\n\n\n\nPPO agent training for dynamic strategies\nBacktesting with temporal validation (walk-forward)\nComparison with market benchmarks\nüìù Partial Report 2: March 1, 2026\nüéì Qualification Seminar: March 15, 2026\n\n\n\nDeliverables: - Trained and validated RL agent - Partial Report 2 (complete results) - Qualification presentation\n\n\n\nStage 6: Consolidation and Dissemination (Mar-Jul/2026)\n\n\n\n\n\n\nüìÑ Main Activities\n\n\n\n\nScientific paper writing (April-June/2026)\nüì¨ Article submission: July 6, 2026\nPeer review and corrections\nPoster/presentation preparation\nüé§ 14th SPPAIC: August 10, 2026\n\n\n\nDeliverables: - Submitted scientific article - Academic poster for SPPAIC - Complementary didactic material - Final project documentation",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#expected-results",
    "href": "mindmap.html#expected-results",
    "title": "Research Mindmap",
    "section": "üéØ Expected Results",
    "text": "üéØ Expected Results\n\nüìö Academic and Scientific\n\n\nPublications: Article in peer-reviewed journal (Quantitative Finance/Applied Econometrics area)\nKnowledge advancement: Unprecedented integration of forecasting, multi-objective optimization, and RL for commodities\nInnovative methodology: Reproducible and scalable framework for portfolio management\nHuman resource training: Scholar capacity building in advanced quantitative methods\n\n\n\n\nüíº Practical and Applied\n\n\nAnalytical tools: Computational pipeline (R/Python) for decision support\nTrading strategies: Adaptive models with reinforcement learning\nRisk management: Instruments for VaR, ES, and drawdown analysis in portfolios\nApplicability: Solutions for trading companies, agricultural cooperatives, and fund managers\n\n\n\n\nüî¨ Technological Innovation\n\n\nPatent: System/methodology with novelty, inventive activity, and industrial application requirements\nInnovation: Holistic and adaptive integration of advanced techniques (non-obvious to experts)\nDifferential: Temporal multi-objective approach with RL for sequential decisions\nImpact: Positioning Brazil as an innovation hub in applied finance for agribusiness",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#analyzed-commodities",
    "href": "mindmap.html#analyzed-commodities",
    "title": "Research Mindmap",
    "section": "üåæ Analyzed Commodities",
    "text": "üåæ Analyzed Commodities\n\nGrain Market\n\n\n\n\n\n\n\n\nCommodity\nDescription\nMarkets\n\n\n\n\nCorn\nBasic grain for animal feed and ethanol\nCME, B3 (futures contracts)\n\n\nSoybeans\nGrain, meal, and oil - integrated chain\nCME, B3, DCE (China)\n\n\nWheat\nComplement for diversification\nCME, CBOT\n\n\nDerivatives\nSoybean meal, soybean oil\nSpot and futures markets\n\n\n\nData Characteristics: - Daily historical series with sufficient periods for regime analysis - Rolling windows for out-of-sample validation - Futures contract adjustments (rollover) - Technical and fundamental indicators",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#interactive-visual-timeline",
    "href": "mindmap.html#interactive-visual-timeline",
    "title": "Research Mindmap",
    "section": "üìä Interactive Visual Timeline",
    "text": "üìä Interactive Visual Timeline\n\nPAIC 2025/26 Timeline\n\n\n\n\n\ngantt\n    title PAIC 2025/26 - Official FAE Timeline\n    dateFormat YYYY-MM-DD\n    axisFormat %b/%y\n    \n    section Phase 1: Setup\n    PAIC 2025-26 Opening           :milestone, m1, 2025-08-13, 1d\n    Term Signing                   :active, 2025-08-05, 9d\n    Work Plan Preparation          :2025-08-13, 34d\n    Data Infrastructure            :2025-08-20, 41d\n    \n    section Phase 2: Data & Models\n    Collection & Curation          :2025-09-01, 60d\n    GARCH/MSGARCH Modeling         :2025-10-01, 60d\n    ML/DL Prototypes (LSTM)        :2025-10-15, 46d\n    13th SPPAIC                    :milestone, sppaic1, 2025-10-24, 1d\n    Partial Report 1               :milestone, m2, 2025-11-24, 1d\n    \n    section Phase 3: Optimization\n    Multi-Objective Framework      :2025-11-01, 119d\n    NSGA-II/DE Implementation      :2025-11-15, 77d\n    Backtesting & Validation       :2026-01-01, 58d\n    \n    section Phase 4: RL & Strategy\n    RL Environment Setup           :2026-02-01, 58d\n    PPO Agent Training             :2026-02-15, 59d\n    Partial Report 2               :milestone, m3, 2026-03-01, 1d\n    Qualification Seminar          :milestone, m4, 2026-03-15, 1d\n    Strategy Evaluation            :2026-03-01, 60d\n    \n    section Phase 5: Publication\n    Scientific Paper Writing       :2026-04-01, 96d\n    Article Submission             :milestone, m5, 2026-07-06, 1d\n    Peer Review Period             :2026-07-06, 22d\n    Article Corrections            :2026-07-08, 20d\n    Poster Preparation             :2026-07-01, 40d\n    14th SPPAIC                    :milestone, sppaic2, 2026-08-10, 1d",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#connections-between-pillars",
    "href": "mindmap.html#connections-between-pillars",
    "title": "Research Mindmap",
    "section": "üîó Connections Between Pillars",
    "text": "üîó Connections Between Pillars\n\nIntegrated Methodological Flow\n\n\n\n\n\nflowchart LR\n    A[Historical&lt;br/&gt;Commodity&lt;br/&gt;Data] --&gt; B[PILLAR 1:&lt;br/&gt;Forecasting]\n    B --&gt; C[Return & Risk&lt;br/&gt;Predictions]\n    C --&gt; D[PILLAR 2:&lt;br/&gt;Multi-Objective&lt;br/&gt;Optimization]\n    D --&gt; E[Pareto&lt;br/&gt;Frontier]\n    E --&gt; F[PILLAR 3:&lt;br/&gt;Reinforcement&lt;br/&gt;Learning]\n    F --&gt; G[Dynamic&lt;br/&gt;Strategies]\n    G --&gt; H[Backtesting &&lt;br/&gt;Evaluation]\n    H --&gt; I{Satisfactory&lt;br/&gt;Performance?}\n    I --&gt;|No| B\n    I --&gt;|Yes| J[Publication &&lt;br/&gt;Implementation]\n    \n    style A fill:#f8f9fa,stroke:#003d7a,stroke-width:3px\n    style B fill:#0056b3,stroke:#003d7a,stroke-width:2px,color:#fff\n    style D fill:#0056b3,stroke:#003d7a,stroke-width:2px,color:#fff\n    style F fill:#0056b3,stroke:#003d7a,stroke-width:2px,color:#fff\n    style J fill:#28a745,stroke:#003d7a,stroke-width:3px,color:#fff",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#main-methodological-references",
    "href": "mindmap.html#main-methodological-references",
    "title": "Research Mindmap",
    "section": "üìñ Main Methodological References",
    "text": "üìñ Main Methodological References\n\n\n\n\n\n\nüìö Selected Bibliography\n\n\n\n\n\nForecasting & Volatility: - Ardia et al.¬†(2019) - Markov-Switching GARCH Models in R (MSGARCH Package) - Ram√≠rez & Fadiga (2003) - Forecasting Agricultural Commodity Prices with Asymmetric-Error GARCH Models\nMulti-Objective Optimization: - Zitzler, Laumanns & Thiele (2001) - SPEA2: Improving the Strength Pareto Evolutionary Algorithm - Chen, Weng & Li (2009) - Multiobjective Extremal Optimization for Portfolio Optimization\nReinforcement Learning: - Schulman et al.¬†(2017) - Proximal Policy Optimization Algorithms - Recent applications in quantitative finance and algorithmic trading\nCommodities & Agribusiness: - Guidolin & Pedio (2020) - Forecasting commodity futures returns with stepwise regressions - Zhang et al.¬†(2020) - Forecasting Agricultural Commodity Prices using Model Selection Framework",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#team-and-supervision",
    "href": "mindmap.html#team-and-supervision",
    "title": "Research Mindmap",
    "section": "üéì Team and Supervision",
    "text": "üéì Team and Supervision\n\n\nProf.¬†Dr.¬†Rodrigo Hermont Ozon\nAdvisor / Lead Researcher\n\nEducation: Economist (UFPR), MSc in Economic Development (UFPR)\nPhD: PPGEPS/PUCPR (2022-2026)\nArea: Financial Econometrics, Time Series, Optimization\nInstitution: FAE Business School\n\n\n        \n\n\n\nPAIC Scholar/Volunteer\nUndergraduate Student\n\nActivities: Data collection, model execution, preliminary analyses\nDevelopment: R/Python programming, quantitative methods\nSupport: Documentation, visualizations, reports\n\nJhonathan, Vanessa, Eduardo PAIC 2025/26",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "mindmap.html#institutional-support",
    "href": "mindmap.html#institutional-support",
    "title": "Research Mindmap",
    "section": "üèÜ Institutional Support",
    "text": "üèÜ Institutional Support\n\nFAE Business School\nThis project is developed within the Support Program for Scientific Initiation (PAIC) of FAE University Center, aligned with strategic areas of:\n\nEnabling Technologies (AI, Big Data, Quantitative Analysis)\nAgribusiness and Applied Finance\nData Science and Econometrics\n\nWebsite: https://fae.edu\nContact: rodrigo.ozon@fae.edu\n\n\n\n\n\n\n\n\nüí° Next Steps\n\n\n\n\nAugust/2025: Official PAIC opening and activity start\nOctober/2025: First presentation at 13th SPPAIC\nNovember/2025: Partial Report 1 delivery\nMarch/2026: Qualification Seminar\nJuly/2026: Scientific article submission\nAugust/2026: Final presentation at 14th SPPAIC\n\n\n\n\n\n\nPAIC Econometrics | FAE Business School Scientific Initiation Project 2025/26 - Curitiba, PR ¬© 2025 All rights reserved",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Research Mindmap"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the Project",
    "section": "",
    "text": "Advancing Agricultural Finance Through Innovation\nA multidisciplinary team combining expertise in Economics, Data Science, and Quantitative Finance to develop cutting-edge solutions for commodity portfolio management.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#project-mission",
    "href": "about.html#project-mission",
    "title": "About the Project",
    "section": "üéØ Project Mission",
    "text": "üéØ Project Mission\n\nOur Purpose\nThis Scientific Initiation Project (PAIC - Programa de Apoio √† Inicia√ß√£o Cient√≠fica) at FAE Business School represents a strategic evolution of research initiated at PUCPR, now with enhanced objectives:\nCore Mission:\n\nDevelop patentable methodologies for multi-period commodity portfolio optimization\nPublish high-impact scientific research in agricultural finance\nSupport doctoral research on multi-objective optimization\nTrain undergraduate students in advanced quantitative methods\nBridge the gap between academic research and industry applications\n\nResearch Philosophy:\nWe believe in combining rigorous econometric theory with practical machine learning applications, creating solutions that are both academically sound and industrially relevant.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#meet-the-team",
    "href": "about.html#meet-the-team",
    "title": "About the Project",
    "section": "üë• Meet the Team",
    "text": "üë• Meet the Team\n\n\n\n\nProf.¬†Rodrigo Hermont Ozon\nPrincipal Investigator & Research Advisor\nEconomist (UFPR, 2008) and MSc in Economic Development (UFPR, 2010), currently pursuing a PhD in Production and Systems Engineering (PPGEPS/PUCPR, 2022-2026). His doctoral thesis focuses on multi-objective multi-period optimization of agricultural commodity portfolios using time series forecasting, multi-criteria decision-making, and reinforcement learning.\nResearch Expertise:\n\nEconometric modeling and time series analysis\nMulti-objective optimization algorithms\nAgricultural commodity markets\nQuantitative finance and risk management\nIntegration of R and Python for financial modeling\n\nAcademic Background:\n\n15+ years of experience in econometric research\nPublished research in agricultural economics and quantitative methods\nExtensive experience with Quarto, R, and Python ecosystems\nIndustry consulting in commodity markets\n\nTime Series Forecasting Multi-Objective Optimization R & Python Agricultural Finance\nContact:\n\n              \n\n\n\n\n\n\nJhonatan [Sobrenome]\nResearch Student | Data Science for Business\nUndergraduate student in Data Science for Business at FAE Business School, specializing in machine learning applications for financial forecasting.\nResearch Focus:\n\nMachine learning model development\nPython programming and data analysis\nNeural network architectures (LSTM, GRU)\nFeature engineering for time series\nModel validation and backtesting\n\nProject Contributions:\n\nDevelopment of predictive ML models for commodity prices\nImplementation of ensemble forecasting techniques\nPython-based data pipeline automation\nModel performance benchmarking\n\nPython Machine Learning Deep Learning Time Series\nAreas of Interest: Quantitative trading, algorithmic finance, artificial intelligence\nContact:\n\n           \n\n\n\n\n\n\nEduardo [Sobrenome]\nResearch Student | Data Science for Business\nUndergraduate student in Data Science for Business at FAE Business School, focusing on data visualization and web application development.\nResearch Focus:\n\nInteractive dashboard development\nStreamLit application deployment\nData visualization best practices\nWeb-based analytics platforms\nUser interface design for financial tools\n\nProject Contributions:\n\nDevelopment of interactive dashboards for model results\nStreamLit deployment for research demonstrations\nData visualization using Plotly and other libraries\nUser experience optimization for research outputs\n\nPython StreamLit Data Visualization Web Development\nAreas of Interest: FinTech applications, data storytelling, interactive analytics\nContact:\n\n           \n\n\n\n\n\n\nVanessa Monn\nResearch Student | Economics\nUndergraduate student in Economics at FAE Business School, bringing strong foundations in economic theory and market analysis.\nResearch Focus:\n\nAgricultural commodity market dynamics\nEconomic theory applications in portfolio management\nMarket microstructure analysis\nEconometric modeling\nLiterature review and theoretical frameworks\n\nProject Contributions:\n\nEconomic analysis of commodity markets\nLiterature review on portfolio optimization\nMarket research and data collection\nEconometric model specification\nIntegration of economic theory with quantitative methods\n\nEconomic Theory Econometrics Market Analysis R Programming\nAreas of Interest: Agricultural economics, financial markets, applied econometrics\nContact:",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#academic-context",
    "href": "about.html#academic-context",
    "title": "About the Project",
    "section": "üéì Academic Context",
    "text": "üéì Academic Context\n\nFAE Business School\n\nFounded in 1957, FAE Centro Universit√°rio is one of Brazil‚Äôs most prestigious business schools, located in Curitiba, Paran√°. FAE is recognized for:\n\nExcellence in business and economics education\nStrong industry partnerships\nCommitment to scientific research\nModern facilities and technology infrastructure\nStrategic location in one of Brazil‚Äôs economic hubs\n\nPAIC Program:\nThe PAIC (Programa de Apoio √† Inicia√ß√£o Cient√≠fica) is FAE‚Äôs scientific initiation program that supports undergraduate research projects, fostering academic excellence and preparing students for graduate studies and professional careers in research.\n\n\n\nProject Lineage\n\n\n\n\n\n\nüîó Connection to Previous Research\n\n\n\nThis project builds upon and extends research initiated at PUCPR (Pontif√≠cia Universidade Cat√≥lica do Paran√°) under the PIBIC and PIBITI Jr.¬†programs.\nPrevious Project:\nPIBIC AgroFinance - PUCPR\nThe FAE project expands the scope with: - Enhanced multi-objective optimization framework - Integration of reinforcement learning strategies - Focus on patent-ready methodologies - Expanded team with diverse expertise - Broader publication strategy",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#research-methodology",
    "href": "about.html#research-methodology",
    "title": "About the Project",
    "section": "üî¨ Research Methodology",
    "text": "üî¨ Research Methodology\nOur interdisciplinary approach combines:\n\nüìä Econometric Foundations\n\nClassical time series analysis (ARIMA, VAR)\nVolatility modeling (GARCH family)\nBayesian econometrics\nCointegration and causality testing\n\n\n\nü§ñ Machine Learning Integration\n\nSupervised learning for prediction\nDeep learning for complex patterns\nEnsemble methods for robustness\nFeature importance analysis\n\n\n\nüéØ Optimization Techniques\n\nMulti-objective evolutionary algorithms\nPareto frontier exploration\nFuzzy multi-criteria decision making\nDynamic programming approaches\n\n\n\nüß† Reinforcement Learning\n\nQ-Learning and DQN for portfolio selection\nPolicy gradient methods\nMulti-agent systems\nAdaptive strategy development",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#technical-infrastructure",
    "href": "about.html#technical-infrastructure",
    "title": "About the Project",
    "section": "üõ†Ô∏è Technical Infrastructure",
    "text": "üõ†Ô∏è Technical Infrastructure\n\nTools & Technologies\nDevelopment Environment:\n\nIDEs: RStudio, Positron, VS Code, Jupyter\nLanguages: R (primary), Python (secondary), SQL\nDocumentation: Quarto publishing system\nVersion Control: Git/GitHub\nDeployment: GitHub Pages\n\nKey R Packages:\ntidyverse ‚Ä¢ forecast ‚Ä¢ rugarch ‚Ä¢ quantmod ‚Ä¢ PerformanceAnalytics ‚Ä¢ portfolioAnalytics ‚Ä¢ DEoptim ‚Ä¢ mco ‚Ä¢ bayesforecast\nKey Python Libraries:\npandas ‚Ä¢ numpy ‚Ä¢ scikit-learn ‚Ä¢ tensorflow ‚Ä¢ pytorch ‚Ä¢ stable-baselines3 ‚Ä¢ gym ‚Ä¢ plotly ‚Ä¢ streamlit\nData Sources:\n\nBloomberg Terminal\nB3 (Brasil, Bolsa, Balc√£o)\nCEPEA/ESALQ commodity indices\nUSDA agricultural reports\nNews APIs (for sentiment analysis)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#research-timeline",
    "href": "about.html#research-timeline",
    "title": "About the Project",
    "section": "üìö Research Timeline",
    "text": "üìö Research Timeline\n\n\n\n\n\ngantt\n    title PAIC 2025/26 - Official Timeline\n    dateFormat YYYY-MM-DD\n    axisFormat %b/%y\n    \n    section Phase 1 Setup\n    Opening PAIC 2025-26           :milestone, m1, 2025-08-13, 1d\n    Term Signing                   :active, 2025-08-05, 9d\n    Work Plan Preparation          :2025-08-13, 34d\n    Data Infrastructure            :2025-08-20, 41d\n    \n    section Phase 2 Data Models\n    Data Collection Curation       :2025-09-01, 60d\n    GARCH MSGARCH Modeling         :2025-10-01, 60d\n    ML DL Prototypes LSTM          :2025-10-15, 46d\n    Partial Report 1               :milestone, m2, 2025-11-24, 1d\n    \n    section Phase 3 Optimization\n    Multi-Objective Framework      :2025-11-01, 119d\n    NSGA-II DE Implementation      :2025-11-15, 77d\n    Backtesting Validation         :2026-01-01, 58d\n    Partial Report 2               :milestone, m3, 2026-03-01, 1d\n    \n    section Phase 4 RL Strategy\n    RL Environment Setup           :2026-02-01, 58d\n    Agent Training PPO             :2026-02-15, 59d\n    Qualification Seminar          :milestone, m4, 2026-03-15, 1d\n    Strategy Evaluation            :2026-03-01, 60d\n    \n    section Phase 5 Publication\n    Scientific Paper Writing       :2026-04-01, 96d\n    Article Submission             :milestone, m5, 2026-07-06, 1d\n    Peer Review Period             :2026-07-06, 22d\n    Article Corrections            :2026-07-08, 20d\n    Poster Preparation             :2026-07-01, 40d\n    \n    section Deliverables\n    13th SPPAIC Symposium          :milestone, m6, 2025-10-24, 1d\n    14th SPPAIC Symposium          :milestone, m7, 2026-08-10, 1d\n    Final Article Delivery         :milestone, m8, 2026-07-06, 1d",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#expected-outcomes",
    "href": "about.html#expected-outcomes",
    "title": "About the Project",
    "section": "üéØ Expected Outcomes",
    "text": "üéØ Expected Outcomes\n\nAcademic Deliverables\nPartial Report 1 (November 24, 2025)\n\nCurated datasets and data infrastructure\nInitial GARCH/MSGARCH volatility models\nPreliminary ML/DL forecasting results\nValidation metrics and benchmarks\n\nPartial Report 2 (March 2026)\n\nComplete Pareto frontier analysis\nMulti-objective optimization results\nRL agent implementation and training\nComprehensive backtesting results\n\nQualification Seminar (March-April 2026)\n\nProject methodology presentation\nPreliminary findings discussion\nPeer feedback integration\nRefinement of research direction\n\nScientific Article (July 6, 2026)\n\nFull methodology documentation\nComprehensive results and analysis\nReproducible code repository\nSubmission to peer-reviewed journal\n\nConference Presentations\n\n13th SPPAIC Symposium (October 24-25, 2025): Project proposal and initial results\n14th SPPAIC Symposium (August 10, 2026): Final results and poster presentation\n\n\n\nTechnical Deliverables\n\nReproducible Research Repository\n\nComplete R/Python codebase\nDocumentation and tutorials\nJupyter/Quarto notebooks\nData processing pipelines\n\nEducational Materials\n\nTutorial notebooks for students\nBest practices documentation\nReplication guides\nOpen-source contributions\n\nPractical Applications\n\nPortfolio optimization framework\nRisk management dashboards\nTrading strategy backtests\nIndustry-ready tools\n\n\n\n\nStudent Development\n\nAdvanced technical skills in R and Python\nExperience with scientific research methodology\nPortfolio of demonstrable projects\nPublication track record\nProfessional networking opportunities",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#collaboration-opportunities",
    "href": "about.html#collaboration-opportunities",
    "title": "About the Project",
    "section": "ü§ù Collaboration Opportunities",
    "text": "ü§ù Collaboration Opportunities\nWe welcome collaboration from:\n\n\nüéì Academic Partners\nUniversities and research centers interested in joint research projects, student exchanges, or co-authored publications.\n\n\nüíº Industry Partners\nFinancial institutions, trading companies, and agricultural cooperatives seeking innovative solutions.\n\n\nüèõÔ∏è Government Agencies\nPublic institutions interested in agricultural market intelligence and policy analysis.\n\n\nüöÄ Technology Companies\nFinTech and AgTech companies developing data-driven solutions for commodity markets.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#contact-information",
    "href": "about.html#contact-information",
    "title": "About the Project",
    "section": "üìû Contact Information",
    "text": "üìû Contact Information\n\n\n\n\n\n\nGet in Touch\n\n\n\nPrincipal Investigator:\nProf.¬†Rodrigo Hermont Ozon\nEmail: rodrigo.ozon@fae.edu\nInstitution:\nFAE Business School\nCuritiba, Paran√°, Brazil\nWebsite: fae.edu\nProject Links:\n\nGitHub: @PAICEconometrics\nLinkedIn: FAE Centro Universit√°rio\nPrevious Project: PIBIC AgroFinance (PUCPR)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "about.html#acknowledgments",
    "href": "about.html#acknowledgments",
    "title": "About the Project",
    "section": "üôè Acknowledgments",
    "text": "üôè Acknowledgments\nWe thank:\n\nFAE Business School for supporting this research through the PAIC program\nDepartment of Economics for institutional support and resources\nDepartment of Data Science for technical infrastructure\nPUCPR for the foundation laid in previous research phases\nResearch community for valuable feedback and collaboration\n\n\n\nPAIC Econometrics Research Project | FAE Business School | Est. 2024\n\nLast updated:\n\n\nCode\nformat(Sys.Date(), '%B %d, %Y')\n\n\n[1] \"outubro 21, 2025\"",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "About the Team"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PAIC Econometrics Research",
    "section": "",
    "text": "Integrating Time Series Forecasting, Multi-Objective Decision Making & Reinforcement Learning\nAn innovative research initiative at FAE Business School developing patent-ready methodologies for agricultural commodities portfolio optimization through advanced econometric and machine learning techniques.\n\nExplore Our Research ‚Üí View Publications ‚Üí",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#research-vision",
    "href": "index.html#research-vision",
    "title": "PAIC Econometrics Research",
    "section": "üéØ Research Vision",
    "text": "üéØ Research Vision\nThis Scientific Initiation Project (PAIC - Programa de Apoio √† Inicia√ß√£o Cient√≠fica) represents the continuation and evolution of pioneering work initiated at PUCPR, now advancing at FAE Business School with enhanced scope and objectives.\n\nüéì Academic Goals\nPrimary Objectives:\n\nPatent Development: Create innovative methodologies for multi-period portfolio optimization\nScientific Publications: Contribute to academic literature on agricultural finance\nDoctoral Research Integration: Support ongoing PhD thesis development\nUndergraduate Excellence: Train students in cutting-edge quantitative finance\n\nInstitutional Context:\nThis project builds upon the foundation established at PUCPR (visit the previous project site) while expanding into new frontiers of agricultural commodity portfolio management.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#core-research-framework",
    "href": "index.html#core-research-framework",
    "title": "PAIC Econometrics Research",
    "section": "üî¨ Core Research Framework",
    "text": "üî¨ Core Research Framework\nOur methodology integrates three fundamental pillars:\n\n\nüìà Time Series Forecasting\nAdvanced predictive modeling for commodity prices using:\n\nARIMA/GARCH family models\nBayesian structural time series\nLSTM and GRU neural networks\nEnsemble forecasting methods\nHawkes processes for news impact\n\nEconometrics Deep Learning Bayesian Methods\n\n\nüéØ Multi-Objective Optimization\nPortfolio optimization considering multiple conflicting objectives:\n\nReturn maximization\nRisk minimization\nLiquidity management\nSustainability criteria\nDynamic rebalancing strategies\n\nEvolutionary Algorithms Pareto Optimization Fuzzy Logic\n\n\nü§ñ Reinforcement Learning\nAdaptive decision-making strategies:\n\nQ-Learning for portfolio selection\nDeep Q-Networks (DQN)\nPolicy gradient methods\nMulti-agent systems\nDynamic strategy adaptation\n\nRL Algorithms Adaptive Systems Decision Theory",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#key-commodities-focus",
    "href": "index.html#key-commodities-focus",
    "title": "PAIC Econometrics Research",
    "section": "üìä Key Commodities Focus",
    "text": "üìä Key Commodities Focus\nOur research concentrates on Brazilian agricultural grain commodities:",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#technical-stack",
    "href": "index.html#technical-stack",
    "title": "PAIC Econometrics Research",
    "section": "üõ†Ô∏è Technical Stack",
    "text": "üõ†Ô∏è Technical Stack\n\nDevelopment Environment\nProgramming & Analysis:\n\nR Ecosystem: tidyverse, forecast, rugarch, quantmod, PerformanceAnalytics\nPython Ecosystem: pandas, numpy, scikit-learn, tensorflow, pytorch, stable-baselines3\nIntegration: Quarto for reproducible research combining R and Python\n\nData Sources:\n\nBloomberg Terminal\nB3 (Brasil, Bolsa, Balc√£o)\nCEPEA/ESALQ price indices\nUSDA agricultural reports\nNews APIs for sentiment analysis\n\nInfrastructure:\n\nVersion control: Git/GitHub\nCollaboration: RStudio/Positron IDE\nDeployment: GitHub Pages\nDocumentation: Quarto publishing system",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#research-methodology-workflow",
    "href": "index.html#research-methodology-workflow",
    "title": "PAIC Econometrics Research",
    "section": "üìà Research Methodology Workflow",
    "text": "üìà Research Methodology Workflow\n\n\n\n\n\nflowchart TD\n    A[Data Collection] --&gt; B[Data Preprocessing]\n    B --&gt; C[Exploratory Analysis]\n    C --&gt; D[Feature Engineering]\n    D --&gt; E[Model Development]\n    E --&gt; F{Model Type}\n    F --&gt;|Time Series| G[ARIMA/GARCH/LSTM]\n    F --&gt;|Optimization| H[Multi-Objective Algorithms]\n    F --&gt;|RL| I[Agent Training]\n    G --&gt; J[Model Validation]\n    H --&gt; J\n    I --&gt; J\n    J --&gt; K[Backtesting]\n    K --&gt; L[Performance Evaluation]\n    L --&gt; M{Satisfactory?}\n    M --&gt;|No| E\n    M --&gt;|Yes| N[Documentation & Publication]\n    N --&gt; O[Patent Application]\n    \n    style A fill:#003d7a,color:#fff\n    style N fill:#28a745,color:#fff\n    style O fill:#ff6b35,color:#fff",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#educational-impact",
    "href": "index.html#educational-impact",
    "title": "PAIC Econometrics Research",
    "section": "üéì Educational Impact",
    "text": "üéì Educational Impact\n\n\n\n\n\n\nStudent Development\n\n\n\nThis project provides undergraduate students with:\n\nPractical Experience: Real-world application of econometric and ML techniques\nResearch Skills: Scientific methodology and academic writing\nTechnical Proficiency: Advanced programming in R and Python\nCareer Preparation: Skills highly valued in quantitative finance and data science\nPublication Opportunities: Co-authorship in scientific papers",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#expected-deliverables",
    "href": "index.html#expected-deliverables",
    "title": "PAIC Econometrics Research",
    "section": "üìö Expected Deliverables",
    "text": "üìö Expected Deliverables\n\nPhase 1 (Current - 6 months)\n\n‚úÖ Project website and documentation\nüìä Literature review and theoretical framework\nüîß Data infrastructure setup\nüìà Initial predictive models\n\n\n\nPhase 2 (6-12 months)\n\nüéØ Multi-objective optimization framework\nü§ñ Reinforcement learning agent development\nüìÑ First scientific paper draft\nüî¨ Patent methodology documentation\n\n\n\nPhase 3 (12-18 months)\n\nüìñ Scientific publications submission\nüèÜ Patent application filing\nüé§ Conference presentations\nüìä Final comprehensive report",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#collaboration-partnerships",
    "href": "index.html#collaboration-partnerships",
    "title": "PAIC Econometrics Research",
    "section": "ü§ù Collaboration & Partnerships",
    "text": "ü§ù Collaboration & Partnerships\nWe actively seek collaboration with:\n\nAcademic institutions researching quantitative finance\nFinancial industry professionals\nAgricultural cooperatives and traders\nTechnology companies developing FinTech solutions\nGovernment agencies interested in agricultural market intelligence\n\n\n\n\n\n\n\nüìû Get Involved\n\n\n\nInterested in collaborating or learning more?\n\nPrincipal Investigator: Prof.¬†Rodrigo Hermont Ozon\nEmail: rodrigo.ozon@fae.edu\nInstitution: FAE Business School, Curitiba, PR\nGitHub: @PAICEconometrics\nLinkedIn: FAE Centro Universit√°rio",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "PAIC Econometrics Research",
    "section": "üîó Quick Links",
    "text": "üîó Quick Links\n\n\nüéì About Us\nMeet the team ‚Üí\n\n\nüìä Research\nView our work ‚Üí\n\n\nüì∞ News\nMarket updates ‚Üí\n\n\nüè´ FAE\nVisit FAE.edu ‚Üí\n\n\n\n\nPAIC - Programa de Apoio √† Inicia√ß√£o Cient√≠fica | FAE Business School | Curitiba, Paran√°, Brazil\n\nLast updated:\noutubro 21, 2025",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Project Overview"
    ]
  },
  {
    "objectID": "openAI_agent.html",
    "href": "openAI_agent.html",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "",
    "text": "Discover how we created a customized GPT agent that automatically searches, filters, and delivers the most relevant scientific articles every week, every Friday at 8 AM."
  },
  {
    "objectID": "openAI_agent.html#project-overview",
    "href": "openAI_agent.html#project-overview",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìã Project Overview",
    "text": "üìã Project Overview\nIn the context of an active research project on applied econometrics and multi-period multi-objective optimization, staying updated with the latest literature is fundamental but extremely time-consuming. Every week, dozens of new papers emerge in repositories like arXiv, SSRN, and scientific journals.\nOur solution? Create a personalized intelligent agent in ChatGPT that:\n\nüîç Automatically searches across multiple scientific databases\nüìä Filters and categorizes articles by relevance\nüìß Delivers weekly structured reports\n‚è∞ Scheduled delivery: Every Friday at 08:00 AM (Bras√≠lia time)"
  },
  {
    "objectID": "openAI_agent.html#paper-hunter-objectives",
    "href": "openAI_agent.html#paper-hunter-objectives",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üéØ Paper Hunter Objectives",
    "text": "üéØ Paper Hunter Objectives\n\nIdentified Problem\nResearchers and students face challenges such as:\n\nInformation overload: Hundreds of papers published weekly\nSource dispersion: ArXiv, SSRN, Google Scholar, journals, etc.\nTime constraints: Difficulty keeping up with recent literature\nSharing difficulties: Need for an easy format to disseminate to students\n\n\n\nImplemented Solution\nWe developed Paper Hunter, a customized GPT agent that:\n\nPerforms targeted searches in specific scientific databases\nApplies quality and relevance filters\nGenerates structured reports in shareable format\nOperates completely autonomously"
  },
  {
    "objectID": "openAI_agent.html#how-we-created-paper-hunter",
    "href": "openAI_agent.html#how-we-created-paper-hunter",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üõ†Ô∏è How We Created Paper Hunter",
    "text": "üõ†Ô∏è How We Created Paper Hunter\n\nStep 1: GPT Agent Configuration\nWe accessed ChatGPT and created a personalized GPT with the following specifications:\n\n\n\n\n\n\nAccessing GPT Builder\n\n\n\nTo create personalized GPTs, you need a ChatGPT Plus or Team account. Access: Settings ‚Üí Explore GPTs ‚Üí Create a GPT\n\n\nMain instructions provided to the agent:\nYou are an agent specialized in weekly scientific curation.\n\nOBJECTIVE:\nSearch weekly for recent scientific articles on:\n- Applied econometrics\n- Multi-period multi-objective optimization\n- Time series forecasting\n- Reinforcement learning applied to finance\n- Commodity volatility modeling\n\nSEARCH SCOPE:\n- Databases: arXiv (econ.EM, q-fin, cs.LG), SSRN, Google Scholar\n- Period: Last 7 days (articles AND preprints)\n- Language: English\n- Focus: Papers with finance/economics applications\n\nDELIVERY FORMAT:\n1. Structured table (Excel-ready)\n2. Columns: Date | Title | Authors | Venue/Type | Link | Summary | Category\n3. Categories: Econometrics, Optimization, RL, Volatility\n4. Direct and functional links\n5. Concise summary (1-2 sentences) in Portuguese\n\nFREQUENCY:\nEvery Friday at 08:00 AM (Bras√≠lia time)\n\n\nStep 2: Integration with Search Tools\nPaper Hunter uses multiple search strategies:\n\n2.1 ArXiv API\n# Example query on arXiv\nsearch_query = \"multi-objective portfolio optimization\"\ncategories = \"econ.EM OR q-fin.PM OR q-fin.RM OR cs.LG\"\ndate_filter = \"submittedDate:[last_week TO now]\"\n\n\n2.2 SSRN Working Papers\n\nSearch by specific keywords\nFilter by publication date\nMetadata extraction\n\n\n\n2.3 Google Scholar\n\nTargeted queries with Boolean operators\nTemporal filter: ‚ÄúSince 2025‚Äù + sort by date\nPDF availability verification\n\n\n\n2.4 Consensus AI\nSpecialized academic search tool that: - Accesses +200M papers - Uses GPT-4 for semantic analysis - Provides automatic insights and citations"
  },
  {
    "objectID": "openAI_agent.html#example-of-weekly-output",
    "href": "openAI_agent.html#example-of-weekly-output",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìä Example of Weekly Output",
    "text": "üìä Example of Weekly Output\nHere‚Äôs a real example of Paper Hunter‚Äôs output:\n\nüìÖ Week of 09/05/2025\n\n\n\nDate\nTitle\nAuthors\nCategory\nLink\n\n\n\n\n2025-09-03\nNeural L√©vy SDE for State-Dependent Risk and Density Forecasting\nZ. Wang; S.T. Rachev\nEconometrics; Volatility\narXiv\n\n\n2025-09-03\nMulti-period Asset-Liability Management with RL in Regime-Switching Market\nZ. Gao et al.\nRL; Optimization\narXiv\n\n\n2025-09-01\nControllable Generation of Implied Volatility Surfaces with VAEs\nJ. Wang; S. Liu; C. Vuik\nVolatility\narXiv\n\n\n\nSummaries: - Paper 1: Neural jump-diffusion model for multi-horizon density/risk forecasting; useful for volatility modeling and scenarios in multi-period optimization. - Paper 2: Use of RL in multi-period ALM with regime switching; outperforms classical models in return/risk. - Paper 3: Controllable generation of IV surfaces with no-arbitrage verification; useful for scenario simulations."
  },
  {
    "objectID": "openAI_agent.html#setting-up-automatic-scheduling",
    "href": "openAI_agent.html#setting-up-automatic-scheduling",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "‚è∞ Setting Up Automatic Scheduling",
    "text": "‚è∞ Setting Up Automatic Scheduling\n\nMethod 1: Scheduled Actions in ChatGPT (Recommended)\nChatGPT Team/Enterprise offers native Scheduled Actions:\n\nAccess your personalized GPT\nGo to Settings ‚Üí Actions\nConfigure:\n\nTrigger: Every Friday at 08:00 AM (America/Sao_Paulo)\nAction: Run research query and send results\nNotification: Email to team members\n\n\n\n\n\n\n\n\nFree Alternative\n\n\n\nIf you don‚Äôt have access to ChatGPT Team, you can use Zapier or Make.com to automate calls to the OpenAI API at specific times.\n\n\n\n\nMethod 2: Automation via Zapier\nTrigger: Schedule by Zapier\n  - Frequency: Weekly\n  - Day: Friday\n  - Time: 08:00 AM (GMT-3)\n\nAction: OpenAI (GPT-4)\n  - Model: gpt-4\n  - Prompt: \"Run Paper Hunter weekly search\"\n  - Send results to: Email / Slack / Google Sheets"
  },
  {
    "objectID": "openAI_agent.html#generating-shareable-spreadsheets",
    "href": "openAI_agent.html#generating-shareable-spreadsheets",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìÅ Generating Shareable Spreadsheets",
    "text": "üìÅ Generating Shareable Spreadsheets\nTo facilitate sharing via WhatsApp with students, we configured the agent to automatically generate a consolidated Excel spreadsheet:\n\nSpreadsheet Structure\nMaster File: literature_master.xlsx\nSheets: 1. Index - Index of all weeks 2. All - All consolidated articles 3. 2025-09-05 - Articles from specific week 4. 2025-09-12 - Next week 5. (continues‚Ä¶)\n\n\nTable Columns\n\n\n\n\n\n\n\n\nColumn\nDescription\nExample\n\n\n\n\nWeek\nReference Friday\n2025-09-05\n\n\nDate\nSubmission date\n2025-09-03\n\n\nTitle\nArticle title\nNeural L√©vy SDE for‚Ä¶\n\n\nAuthors\nAuthors\nZ. Wang; S.T. Rachev\n\n\nVenue/Type\nSource/Type\narXiv / Preprint\n\n\nLink\nDirect URL\nhttps://arxiv.org/‚Ä¶\n\n\nSummary (PT)\nSummary in Portuguese\nNeural jump-diffusion model‚Ä¶\n\n\nCategory\nClassification\nEconometrics; Volatility"
  },
  {
    "objectID": "openAI_agent.html#automatic-categorization",
    "href": "openAI_agent.html#automatic-categorization",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üé® Automatic Categorization",
    "text": "üé® Automatic Categorization\nPaper Hunter automatically classifies each article into the following categories:\n\n\nüìà Econometrics\nEconometric models, time series, statistical tests, cointegration, spillovers\n\n\nüéØ Optimization\nMulti-objective optimization, MOO, genetic algorithms, NSGA-II/III, mathematical programming\n\n\nü§ñ RL\nReinforcement Learning, Q-learning, Deep RL, optimal policies, simulation environments\n\n\nüìä Volatility\nVolatility modeling, GARCH, implied volatility, risk, VaR, CVaR"
  },
  {
    "objectID": "openAI_agent.html#best-practices-and-lessons-learned",
    "href": "openAI_agent.html#best-practices-and-lessons-learned",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üí° Best Practices and Lessons Learned",
    "text": "üí° Best Practices and Lessons Learned\n\n‚úÖ What Worked Well\n\nQuery specificity: The more specific the prompt, the better the results\nTemporal filters: Always include 7-day windows to avoid duplicates\nMultiple sources: Combining arXiv + SSRN + Scholar increases coverage\nStructured format: Tables greatly facilitate sharing\n\n\n\n‚ö†Ô∏è Challenges Faced\n\nFalse positives: Some articles are not as relevant as they seem\nIndexing delay: Very recent papers may not appear\nAccess limitations: Some journals have paywalls\nAmbiguous categorization: Interdisciplinary papers require manual review\n\n\n\nüîß Future Improvements\n\nImplement automatic relevance score (0-10)\nAdd LLM-generated summaries of abstracts\nCreate alerts for high-impact papers\nIntegrate with Zotero/Mendeley for reference management\nInteractive dashboard with visualizations"
  },
  {
    "objectID": "openAI_agent.html#how-to-replicate-this-system",
    "href": "openAI_agent.html#how-to-replicate-this-system",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üöÄ How to Replicate This System",
    "text": "üöÄ How to Replicate This System\n\nDetailed Step-by-Step\n\n1. Create ChatGPT Plus/Team Account\nAccess chat.openai.com and upgrade\n\n\n2. Configure the Personalized GPT\nName: Paper Hunter\nDescription: Weekly scientific curation agent\nInstructions: [Paste the complete prompt provided above]\nTools: Web Browsing + Code Interpreter\n\n\n3. Test Manually\nRun a test search:\n\"Search for articles from the past week on portfolio optimization\"\n\n\n4. Configure Scheduling\n\nOption A: ChatGPT Scheduled Actions (Team/Enterprise)\nOption B: Zapier + OpenAI API (any plan)\n\n\n\n5. Define Output Format\nInstruct the agent to always generate: - Markdown table - .xlsx file for download - Functional links"
  },
  {
    "objectID": "openAI_agent.html#resources-and-references",
    "href": "openAI_agent.html#resources-and-references",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìö Resources and References",
    "text": "üìö Resources and References\n\nDatabases Used\n\narXiv.org - Preprint repository (Physics, Math, CS, Economics)\nSSRN - Social Science Research Network\nGoogle Scholar - Academic search engine\nConsensus AI - AI-powered academic search\n\n\n\nComplementary Tools\n\nSemantic Scholar - Semantic paper search\nConnected Papers - Citation graph\nResearch Rabbit - Literature recommendation\n\n\n\nAPIs Used\n# ArXiv API\n# http://export.arxiv.org/api/query\n\n# CrossRef API (DOIs)\n# https://api.crossref.org/\n\n# Semantic Scholar API\n# https://api.semanticscholar.org/"
  },
  {
    "objectID": "openAI_agent.html#usage-statistics",
    "href": "openAI_agent.html#usage-statistics",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìä Usage Statistics",
    "text": "üìä Usage Statistics\n\n\n\n\n\n\nResults After 2 Months of Operation\n\n\n\n\nPapers scanned: ~450 articles/week\nRelevance rate: 75% of papers are useful\nTime saved: ~6h/week for the team\nSource coverage: 4 main databases + 10+ journals\nTeam satisfaction: 9.2/10"
  },
  {
    "objectID": "openAI_agent.html#research-impact",
    "href": "openAI_agent.html#research-impact",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üéì Research Impact",
    "text": "üéì Research Impact\n\nObserved Benefits\n\nConstant updates: We never miss important papers\nDiscovering connections: We find relevant interdisciplinary work\nEfficiency: More time for deep reading, less for searching\nSharing: Students receive quality curation\nOrganized history: Master spreadsheet works as a library\n\n\n\nTeam Testimonials\n\n‚ÄúPaper Hunter transformed our research routine. Before, we spent hours searching for papers, now we receive everything pre-filtered every Friday.‚Äù\n‚Äî Vanessa Monn, PAIC Scholar\n\n\n‚ÄúI was able to identify 3 crucial papers for my part of the project thanks to the automated searches.‚Äù\n‚Äî Jhonathan Athanazio, Volunteer"
  },
  {
    "objectID": "openAI_agent.html#useful-links",
    "href": "openAI_agent.html#useful-links",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üîó Useful Links",
    "text": "üîó Useful Links\n\nChatGPT Custom GPTs Documentation\nArXiv API Documentation\nSSRN Author Center\nZapier + OpenAI Tutorial"
  },
  {
    "objectID": "openAI_agent.html#contact-and-collaboration",
    "href": "openAI_agent.html#contact-and-collaboration",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìû Contact and Collaboration",
    "text": "üìû Contact and Collaboration\nWant to implement a similar system in your research project?\nGet in touch:\n\nüìß Email: rodrigo.ozon@fae.edu\nüîó LinkedIn: FAE Centro Universit√°rio\nüíª GitHub: @PAICEconometrics\n\n\n\n\n\n\n\n\nüí° Next Steps\n\n\n\nWe are working on version 2.0 of Paper Hunter which will include:\n\nSentiment analysis of abstracts\nAutomatic ranking by relevance\nPersonalized recommendations per researcher\nIntegration with Notion/Obsidian\nReal-time alerts via Telegram\n\nStay tuned for updates!"
  },
  {
    "objectID": "openAI_agent.html#conclusion",
    "href": "openAI_agent.html#conclusion",
    "title": "Paper Hunter: Intelligent Weekly Research Curation Agent",
    "section": "üìù Conclusion",
    "text": "üìù Conclusion\nPaper Hunter demonstrates how artificial intelligence can be used to increase scientific productivity without replacing the critical role of the researcher. By automating repetitive search and curation tasks, we free up time for what really matters: reading, analyzing, and producing quality knowledge.\nIf you are in an active research project, consider implementing a similar system. The return on time investment is extremely high.\n\n\nüìö PAIC Econometrics | FAE Business School Innovations in Financial Modeling: AI & Econometrics for Portfolio Optimization Transforming research through artificial intelligence"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research Methodology",
    "section": "",
    "text": "This research project adopts a quantitative, computational, and applied approach, combining statistical econometrics, machine learning, and optimization techniques to develop an integrated framework for agricultural commodities portfolio management.\nOur methodology follows a rigorous quasi-experimental design based on time series simulations and backtesting protocols, ensuring reproducibility and transparency throughout all research phases.\n\n\n\n\n\n\nüéØ Research Classification\n\n\n\n\nType: Applied & Computational Research\nApproach: Quantitative Analysis\nDesign: Quasi-Experimental with Time Series Validation\nValidation: Temporal Cross-Validation & Benchmarking\n\n\n\n\n\n\n\nOur integrated methodology is structured in six complementary stages, each building upon previous findings to create a comprehensive portfolio optimization system.\n\n\n\n\nWe collect historical data from multiple authoritative sources:\n\nPrice Data: B3 (Brasil Bolsa Balc√£o) futures contracts\nAgricultural Indices: CEPEA/ESALQ price indices\nMacroeconomic Indicators: USDA reports, Brazilian Central Bank data\nAlternative Data: News sentiment via APIs, weather patterns\n\n\n\n\nOur focus encompasses Brazilian agricultural grain commodities:\n\n\n\nCommodity\nContract Type\nData Frequency\nHistorical Depth\n\n\n\n\nCorn\nFutures (B3)\nDaily\n15+ years\n\n\nSoybeans\nFutures (B3)\nDaily\n15+ years\n\n\nSoybean Meal\nFutures (B3)\nDaily\n10+ years\n\n\nSoybean Oil\nFutures (B3)\nDaily\n10+ years\n\n\nCoffee\nFutures (B3)\nDaily\n20+ years\n\n\nSugar\nFutures (B3)\nDaily\n15+ years\n\n\n\n\n\n\n\n\nData Cleaning & Normalization Pipeline\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(xts)\n\n# Data cleaning function\nclean_commodity_data &lt;- function(raw_data) {\n  raw_data %&gt;%\n    # Remove outliers (&gt; 5 SD)\n    filter(abs(scale(returns)) &lt; 5) %&gt;%\n    # Handle missing values via interpolation\n    na.approx(maxgap = 5) %&gt;%\n    # Normalize to log-returns\n    mutate(log_returns = log(close / lag(close))) %&gt;%\n    # Remove non-trading days\n    filter(!is.na(log_returns))\n}\n\n\n\n\n\n\n\n\nData Quality Assurance\n\n\n\nAll datasets undergo rigorous quality checks including: - Outlier detection via statistical thresholds - Missing data imputation with maximum gap constraints - Consistency validation across multiple sources - Temporal alignment and synchronization\n\n\n\n\n\n\n\nWe employ a hierarchical forecasting framework combining econometric and machine learning approaches.\n\n\n\n\nFor volatility forecasting, we implement multiple GARCH specifications:\nStandard GARCH(1,1): \\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n\\]\nGJR-GARCH (capturing leverage effects): \\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\gamma \\epsilon_{t-1}^2 I_{t-1} + \\beta \\sigma_{t-1}^2\n\\]\nwhere \\(I_{t-1} = 1\\) if \\(\\epsilon_{t-1} &lt; 0\\), and 0 otherwise.\nMarkov-Switching GARCH (regime-dependent volatility):\n\n\nCode\nlibrary(MSGARCH)\n\n# MS-GARCH specification\nspec &lt;- CreateSpec(\n  variance.spec = list(model = c(\"sGARCH\", \"sGARCH\")),\n  distribution.spec = list(distribution = c(\"std\", \"std\")),\n  switch.spec = list(K = 2)  # Two regimes\n)\n\n# Model estimation\nfit &lt;- FitML(spec, data = returns_data)\n\n\n\n\n\n\n\n\nWhy Markov-Switching?\n\n\n\nAgricultural commodities exhibit regime-dependent behavior during crisis periods, supply shocks, or policy changes. MS-GARCH captures these structural breaks automatically.\n\n\n\n\n\nFor return forecasting, we use ARIMAX models incorporating: - Lagged returns - Macroeconomic indicators (USD/BRL exchange rate, interest rates) - Seasonal components - News sentiment scores\n\n\n\n\n\n\n\n\nCode\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense\n\ndef build_lstm_model(lookback=60, n_features=5):\n    model = Sequential([\n        LSTM(128, return_sequences=True, input_shape=(lookback, n_features)),\n        Dropout(0.2),\n        LSTM(64, return_sequences=False),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1)  # Price/return prediction\n    ])\n    \n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\n\n\n\n\nWe combine multiple models via weighted averaging:\n\\[\n\\hat{y}_t = \\sum_{i=1}^M w_i \\hat{y}_{i,t}\n\\]\nwhere weights \\(w_i\\) are optimized via: - Inverse RMSE weighting - Bayesian Model Averaging - Stacking with meta-learner\n\n\n\n\n\nWalk-Forward ValidationPerformance Metrics\n\n\n\nTraining Window: Rolling 3-year window\nValidation Period: 6 months ahead\nRe-estimation Frequency: Monthly\n\n\n\n\n\n\n\n\n\n\n\nMetric\nFormula\nInterpretation\n\n\n\n\nRMSE\n\\(\\sqrt{\\frac{1}{n}\\sum(y_t - \\hat{y}_t)^2}\\)\nPrediction error magnitude\n\n\nMAE\n\\(\\frac{1}{n}\\sum|y_t - \\hat{y}_t|\\)\nAverage absolute error\n\n\nMAPE\n\\(\\frac{100}{n}\\sum|\\frac{y_t - \\hat{y}_t}{y_t}|\\)\nPercentage error\n\n\nDirectional Accuracy\n\\(\\frac{1}{n}\\sum I(sign(y_t) = sign(\\hat{y}_t))\\)\nCorrect direction %\n\n\n\n\n\n\n\n\n\n\n\nThe portfolio optimization phase addresses multiple conflicting objectives simultaneously.\n\n\nWe optimize portfolios considering:\n\\[\n\\begin{aligned}\n\\text{Maximize:} \\quad & f_1(w) = E[R_p] = w^T \\mu \\\\\n\\text{Minimize:} \\quad & f_2(w) = \\text{CVaR}_\\alpha(R_p) \\\\\n\\text{Minimize:} \\quad & f_3(w) = \\sigma_p = \\sqrt{w^T \\Sigma w} \\\\\n\\text{Maximize:} \\quad & f_4(w) = \\text{Diversification Ratio}\n\\end{aligned}\n\\]\nSubject to: \\[\n\\begin{aligned}\n\\sum_{i=1}^n w_i &= 1 \\\\\n0 \\leq w_i &\\leq w_{max} \\\\\n\\text{Turnover} &\\leq \\tau_{max}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nConditional Value-at-Risk (CVaR)\n\n\n\nCVaR is preferred over VaR due to its: - Sub-additivity (portfolio CVaR ‚â§ sum of individual CVaRs) - Convexity (easier optimization) - Coherent risk measure properties\n\n\n\n\n\n\n\n\n\nCode\nlibrary(mco)\n\n# Define multi-objective fitness function\nfitness_function &lt;- function(weights) {\n  portfolio_return &lt;- sum(weights * expected_returns)\n  portfolio_risk &lt;- sqrt(t(weights) %*% cov_matrix %*% weights)\n  portfolio_cvar &lt;- calculate_cvar(weights, returns_matrix, alpha = 0.05)\n  \n  return(c(\n    -portfolio_return,  # Negative because we maximize\n    portfolio_risk,\n    portfolio_cvar\n  ))\n}\n\n# Run NSGA-II\nresult &lt;- nsga2(\n  fn = fitness_function,\n  idim = n_assets,  # Number of decision variables\n  odim = 3,         # Number of objectives\n  lower.bounds = rep(0, n_assets),\n  upper.bounds = rep(0.4, n_assets),\n  constraints = function(x) sum(x) - 1,  # Budget constraint\n  popsize = 100,\n  generations = 200\n)\n\n\n\n\n\n\n\nCode\nlibrary(DEoptim)\n\n# DE with Pareto ranking\nde_result &lt;- DEoptim(\n  fn = fitness_function,\n  lower = rep(0, n_assets),\n  upper = rep(0.4, n_assets),\n  control = DEoptim.control(\n    strategy = 2,      # DE/rand/1/bin\n    NP = 50,           # Population size\n    itermax = 500,\n    CR = 0.9,          # Crossover probability\n    F = 0.8            # Mutation factor\n  )\n)\n\n\n\n\n\n\nThe optimization generates a Pareto-optimal frontier representing the trade-off between objectives:\n\n\nCode\nlibrary(plotly)\n\n# 3D Pareto Front visualization\nplot_ly(\n  data = pareto_solutions,\n  x = ~expected_return,\n  y = ~portfolio_risk,\n  z = ~cvar,\n  color = ~sharpe_ratio,\n  type = \"scatter3d\",\n  mode = \"markers\"\n) %&gt;%\n  layout(\n    title = \"Pareto-Optimal Frontier\",\n    scene = list(\n      xaxis = list(title = \"Expected Return\"),\n      yaxis = list(title = \"Risk (StdDev)\"),\n      zaxis = list(title = \"CVaR (5%)\")\n    )\n  )\n\n\n\n\n\n\n\nWe employ RL agents to learn adaptive rebalancing strategies that respond to market conditions.\n\n\nState Space \\(\\mathcal{S}\\):\n\\[\ns_t = \\{w_t, \\mu_t, \\Sigma_t, \\text{indicators}_t\\}\n\\]\nAction Space \\(\\mathcal{A}\\):\n\\[\na_t = \\Delta w_t \\in [-\\delta, \\delta]^n \\quad \\text{(portfolio weight adjustments)}\n\\]\nReward Function \\(r_t\\):\n\\[\nr_t = R_{p,t} - \\lambda \\cdot \\text{Risk}_{p,t} - \\kappa \\cdot \\text{TransactionCost}_t\n\\]\n\n\n\n\n\n\n\nCode\nimport gym\nimport numpy as np\nfrom stable_baselines3 import DQN\nfrom stable_baselines3.common.vec_env import DummyVecEnv\n\n# Custom environment for portfolio management\nclass PortfolioEnv(gym.Env):\n    def __init__(self, price_data, initial_capital=100000):\n        super(PortfolioEnv, self).__init__()\n        \n        self.price_data = price_data\n        self.n_assets = price_data.shape[1]\n        self.current_step = 0\n        self.capital = initial_capital\n        \n        # Action: weight adjustments for each asset\n        self.action_space = gym.spaces.Box(\n            low=-0.1, high=0.1, shape=(self.n_assets,), dtype=np.float32\n        )\n        \n        # State: prices, returns, portfolio weights, technical indicators\n        self.observation_space = gym.spaces.Box(\n            low=-np.inf, high=np.inf, \n            shape=(self.n_assets * 4,), \n            dtype=np.float32\n        )\n    \n    def step(self, action):\n        # Execute action, calculate reward, update state\n        # ... implementation details ...\n        return next_state, reward, done, info\n\n# Train DQN agent\nenv = DummyVecEnv([lambda: PortfolioEnv(train_data)])\nmodel = DQN(\"MlpPolicy\", env, verbose=1, learning_rate=0.0001)\nmodel.learn(total_timesteps=100000)\n\n\n\n\n\n\n\nCode\nfrom stable_baselines3 import PPO\n\n# PPO for continuous action space\nppo_model = PPO(\n    \"MlpPolicy\",\n    env,\n    learning_rate=0.0003,\n    n_steps=2048,\n    batch_size=64,\n    n_epochs=10,\n    gamma=0.99,\n    gae_lambda=0.95,\n    clip_range=0.2,\n    verbose=1\n)\n\nppo_model.learn(total_timesteps=200000)\n\n\n\n\n\n\nThe RL agent learns to implement various strategies:\n\n\n\n\n\n\n\n\nStrategy\nDescription\nTrigger Conditions\n\n\n\n\nDynamic Rebalancing\nAdjust weights based on forecasts\nDeviation &gt; threshold\n\n\nMomentum Trading\nFollow price trends\nStrong directional signals\n\n\nMean Reversion\nContrarian positions\nExtreme price movements\n\n\nVolatility Targeting\nAdjust exposure to volatility\nRegime changes detected\n\n\nHedging\nRisk mitigation positions\nHigh uncertainty periods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAvoiding Overfitting\n\n\n\nWe implement strict protocols to prevent backtest overfitting: - Out-of-sample testing with unseen data - Transaction cost modeling (0.1% per trade) - Realistic slippage assumptions - No look-ahead bias in feature engineering\n\n\n\n\nCode\nlibrary(PerformanceAnalytics)\n\n# Backtesting function\nrun_backtest &lt;- function(strategy_weights, returns_data, costs = 0.001) {\n  n_periods &lt;- nrow(returns_data)\n  portfolio_returns &lt;- rep(0, n_periods)\n  \n  for (t in 2:n_periods) {\n    # Calculate portfolio return\n    portfolio_returns[t] &lt;- sum(strategy_weights[t-1, ] * returns_data[t, ])\n    \n    # Subtract transaction costs\n    turnover &lt;- sum(abs(strategy_weights[t, ] - strategy_weights[t-1, ]))\n    portfolio_returns[t] &lt;- portfolio_returns[t] - (costs * turnover)\n  }\n  \n  return(xts(portfolio_returns, order.by = index(returns_data)))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetric\nFormula\nBenchmark\n\n\n\n\nSharpe Ratio\n\\(\\frac{E[R_p - R_f]}{\\sigma_p}\\)\n&gt; 1.0 (good), &gt; 2.0 (excellent)\n\n\nSortino Ratio\n\\(\\frac{E[R_p - R_f]}{\\sigma_{downside}}\\)\nHigher is better\n\n\nCalmar Ratio\n\\(\\frac{E[R_p]}{\\text{Max Drawdown}}\\)\n&gt; 0.5 (acceptable)\n\n\nInformation Ratio\n\\(\\frac{E[R_p - R_b]}{\\text{TE}}\\)\n&gt; 0.5 (outperformance)\n\n\n\n\n\n\n\n\nCode\n# Maximum drawdown calculation\ncalculate_drawdowns &lt;- function(returns) {\n  cumulative_returns &lt;- cumprod(1 + returns)\n  running_max &lt;- cummax(cumulative_returns)\n  drawdown &lt;- (cumulative_returns - running_max) / running_max\n  \n  max_dd &lt;- min(drawdown)\n  max_dd_duration &lt;- max(rle(drawdown &lt; -0.05)$lengths)\n  \n  return(list(\n    max_drawdown = max_dd,\n    avg_drawdown = mean(drawdown[drawdown &lt; 0]),\n    max_duration = max_dd_duration\n  ))\n}\n\n\n\n\n\n\nWe compare our strategies against:\n\nBuy-and-Hold: Equal-weighted static portfolio\nMean-Variance (Markowitz): Traditional optimization\nRisk Parity: Equal risk contribution\n1/N Portfolio: Na√Øve diversification\nMomentum Strategy: 12-month momentum signals\n\n\n\nCode\nlibrary(ggplot2)\n\n# Performance comparison plot\nggplot(performance_data, aes(x = date, y = cumulative_return, color = strategy)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\n    \"Our Strategy\" = \"#003d7a\",\n    \"Buy-Hold\" = \"#6c757d\",\n    \"Mean-Variance\" = \"#28a745\",\n    \"Risk Parity\" = \"#ffc107\"\n  )) +\n  labs(\n    title = \"Cumulative Returns: Strategy Comparison\",\n    x = \"Date\",\n    y = \"Cumulative Return\",\n    color = \"Strategy\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\nTest model robustness under various scenarios:\n\nParameter Sensitivity: Vary RL hyperparameters (¬±20%)\nWindow Length: Test different training windows (2-5 years)\nTransaction Costs: Evaluate under 0%, 0.05%, 0.1%, 0.2% costs\nMarket Conditions: Bull vs.¬†bear vs.¬†sideways markets\n\n\n\n\n\n\nCode\n# Monte Carlo portfolio simulation\nmonte_carlo_simulation &lt;- function(n_sim = 10000, n_days = 252) {\n  sim_results &lt;- matrix(0, nrow = n_sim, ncol = n_days)\n  \n  for (i in 1:n_sim) {\n    # Simulate returns based on estimated parameters\n    sim_returns &lt;- rmvnorm(n_days, mean = mu_hat, sigma = Sigma_hat)\n    \n    # Apply strategy\n    sim_results[i, ] &lt;- cumsum(apply_strategy(sim_returns))\n  }\n  \n  # Calculate confidence intervals\n  ci_lower &lt;- apply(sim_results, 2, quantile, probs = 0.05)\n  ci_upper &lt;- apply(sim_results, 2, quantile, probs = 0.95)\n  \n  return(list(paths = sim_results, ci_lower = ci_lower, ci_upper = ci_upper))\n}\n\n\n\n\n\n\n\n\n\n\n\nCross-Validation Strategy\n\n\n\n\nTraining: 2015-2020 (5 years)\nValidation: 2021-2022 (2 years)\nTest (Out-of-Sample): 2023-2024 (2 years)\n\nCritical: Test set is never used during model development.\n\n\n\n\n\n\n\n\n\n\n\nMethodological Innovation\n\nNovel integration of forecasting + optimization + RL\nAdaptive portfolio management framework\nRegime-aware decision-making\n\nEmpirical Insights\n\nComprehensive analysis of Brazilian agricultural commodities\nBenchmark comparisons across multiple strategies\nReal-world applicability assessment\n\nPatent Development\n\nUnique algorithmic approach to multi-period optimization\nIntellectual property documentation\nCommercial application potential\n\n\n\n\n\n\nPublicationsConferencesTechnical Reports\n\n\nTarget Journals:\n\nEuropean Journal of Operational Research\nJournal of Forecasting\nQuantitative Finance\nAgricultural Economics\nJournal of Commodity Markets\n\n\n\nPresentation Venues:\n\nSPPAIC/FAE (Internal Symposium)\nBrazilian Finance Society (SBFin)\nLatin American Finance Network (LAFN)\nInternational Conference on Operational Research\n\n\n\n\nQuarterly progress reports\nMethodology documentation\nReproducible code repositories\nEducational materials for students\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# R Ecosystem\nlibrary(tidyverse)      # Data manipulation\nlibrary(quantmod)       # Financial data\nlibrary(rugarch)        # GARCH models\nlibrary(MSGARCH)        # Markov-Switching GARCH\nlibrary(PerformanceAnalytics)  # Portfolio analytics\nlibrary(DEoptim)        # Differential Evolution\nlibrary(mco)            # Multi-objective optimization\n\n\n\n\nCode\n# Python Ecosystem\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom stable_baselines3 import PPO, DQN\nimport pytorch\nimport gym\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\n\n\nVersion Control: GitHub (https://github.com/PAICEconometrics)\nIDE: RStudio / Positron IDE\nDocumentation: Quarto Publishing System\nDeployment: GitHub Pages\nCollaboration: Slack + GitHub Projects\n\n\n\n\n\n\n\n\n\n\n\ngantt\n    title PAIC Research Project Timeline (2025-2026)\n    dateFormat  YYYY-MM-DD\n    \n    section Phase 1: Setup\n    Data Collection & Infrastructure    :a1, 2025-08-01, 60d\n    Literature Review                   :a2, 2025-08-01, 90d\n    \n    section Phase 2: Modeling\n    Forecasting Models Development      :b1, 2025-10-01, 90d\n    Multi-Objective Optimization        :b2, 2025-11-01, 120d\n    Partial Report 1                    :milestone, m1, 2025-11-15, 1d\n    \n    section Phase 3: RL & Integration\n    RL Environment Setup                :c1, 2026-02-01, 60d\n    Agent Training & Ablation           :c2, 2026-02-15, 75d\n    Partial Report 2                    :milestone, m2, 2026-03-15, 1d\n    \n    section Phase 4: Validation\n    Backtesting & Robustness            :d1, 2026-03-01, 90d\n    Seminar Presentation                :milestone, m3, 2026-04-15, 1d\n    \n    section Phase 5: Publication\n    Article Writing                     :e1, 2026-04-01, 90d\n    Patent Documentation                :e2, 2026-05-01, 60d\n    Final Article Submission            :milestone, m4, 2026-07-15, 1d\n\n\n\n\n\n\n\n\n\n\n\n\nAll research outputs follow FAIR principles (Findable, Accessible, Interoperable, Reusable):\n\n‚úÖ Code Repository: Public GitHub with MIT License\n‚úÖ Data Provenance: Documented sources and timestamps\n‚úÖ Environment Management: renv / conda environment files\n‚úÖ Literate Programming: Quarto documents combining code + narrative\n‚úÖ Version Control: Semantic versioning for major milestones\n\n\n\n\n\n\n\n\n\n\nResearch Ethics\n\n\n\n\nNo Market Manipulation: Strategies are for academic purposes\nData Privacy: Only publicly available market data\nTransparency: Full methodology disclosure\nConflict of Interest: No undisclosed commercial relationships\n\n\n\n\n\n\n\n\nInterested in collaborating or learning more about our methodology?\n\nPrincipal Investigator: Prof.¬†Rodrigo Hermont Ozon\nEmail: rodrigo.ozon@fae.edu\nInstitution: FAE Business School, Curitiba, PR, Brazil\nGitHub: @PAICEconometrics\nLinkedIn: FAE Centro Universit√°rio\n\n\n\n\n\n\n\n\n\n*Last updated:\n2025-10-21"
  },
  {
    "objectID": "research.html#overview",
    "href": "research.html#overview",
    "title": "Research Methodology",
    "section": "",
    "text": "This research project adopts a quantitative, computational, and applied approach, combining statistical econometrics, machine learning, and optimization techniques to develop an integrated framework for agricultural commodities portfolio management.\nOur methodology follows a rigorous quasi-experimental design based on time series simulations and backtesting protocols, ensuring reproducibility and transparency throughout all research phases.\n\n\n\n\n\n\nüéØ Research Classification\n\n\n\n\nType: Applied & Computational Research\nApproach: Quantitative Analysis\nDesign: Quasi-Experimental with Time Series Validation\nValidation: Temporal Cross-Validation & Benchmarking"
  },
  {
    "objectID": "research.html#research-framework",
    "href": "research.html#research-framework",
    "title": "Research Methodology",
    "section": "",
    "text": "Our integrated methodology is structured in six complementary stages, each building upon previous findings to create a comprehensive portfolio optimization system.\n\n\n\n\nWe collect historical data from multiple authoritative sources:\n\nPrice Data: B3 (Brasil Bolsa Balc√£o) futures contracts\nAgricultural Indices: CEPEA/ESALQ price indices\nMacroeconomic Indicators: USDA reports, Brazilian Central Bank data\nAlternative Data: News sentiment via APIs, weather patterns\n\n\n\n\nOur focus encompasses Brazilian agricultural grain commodities:\n\n\n\nCommodity\nContract Type\nData Frequency\nHistorical Depth\n\n\n\n\nCorn\nFutures (B3)\nDaily\n15+ years\n\n\nSoybeans\nFutures (B3)\nDaily\n15+ years\n\n\nSoybean Meal\nFutures (B3)\nDaily\n10+ years\n\n\nSoybean Oil\nFutures (B3)\nDaily\n10+ years\n\n\nCoffee\nFutures (B3)\nDaily\n20+ years\n\n\nSugar\nFutures (B3)\nDaily\n15+ years\n\n\n\n\n\n\n\n\nData Cleaning & Normalization Pipeline\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(xts)\n\n# Data cleaning function\nclean_commodity_data &lt;- function(raw_data) {\n  raw_data %&gt;%\n    # Remove outliers (&gt; 5 SD)\n    filter(abs(scale(returns)) &lt; 5) %&gt;%\n    # Handle missing values via interpolation\n    na.approx(maxgap = 5) %&gt;%\n    # Normalize to log-returns\n    mutate(log_returns = log(close / lag(close))) %&gt;%\n    # Remove non-trading days\n    filter(!is.na(log_returns))\n}\n\n\n\n\n\n\n\n\nData Quality Assurance\n\n\n\nAll datasets undergo rigorous quality checks including: - Outlier detection via statistical thresholds - Missing data imputation with maximum gap constraints - Consistency validation across multiple sources - Temporal alignment and synchronization\n\n\n\n\n\n\n\nWe employ a hierarchical forecasting framework combining econometric and machine learning approaches.\n\n\n\n\nFor volatility forecasting, we implement multiple GARCH specifications:\nStandard GARCH(1,1): \\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n\\]\nGJR-GARCH (capturing leverage effects): \\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\gamma \\epsilon_{t-1}^2 I_{t-1} + \\beta \\sigma_{t-1}^2\n\\]\nwhere \\(I_{t-1} = 1\\) if \\(\\epsilon_{t-1} &lt; 0\\), and 0 otherwise.\nMarkov-Switching GARCH (regime-dependent volatility):\n\n\nCode\nlibrary(MSGARCH)\n\n# MS-GARCH specification\nspec &lt;- CreateSpec(\n  variance.spec = list(model = c(\"sGARCH\", \"sGARCH\")),\n  distribution.spec = list(distribution = c(\"std\", \"std\")),\n  switch.spec = list(K = 2)  # Two regimes\n)\n\n# Model estimation\nfit &lt;- FitML(spec, data = returns_data)\n\n\n\n\n\n\n\n\nWhy Markov-Switching?\n\n\n\nAgricultural commodities exhibit regime-dependent behavior during crisis periods, supply shocks, or policy changes. MS-GARCH captures these structural breaks automatically.\n\n\n\n\n\nFor return forecasting, we use ARIMAX models incorporating: - Lagged returns - Macroeconomic indicators (USD/BRL exchange rate, interest rates) - Seasonal components - News sentiment scores\n\n\n\n\n\n\n\n\nCode\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense\n\ndef build_lstm_model(lookback=60, n_features=5):\n    model = Sequential([\n        LSTM(128, return_sequences=True, input_shape=(lookback, n_features)),\n        Dropout(0.2),\n        LSTM(64, return_sequences=False),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1)  # Price/return prediction\n    ])\n    \n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\n\n\n\n\nWe combine multiple models via weighted averaging:\n\\[\n\\hat{y}_t = \\sum_{i=1}^M w_i \\hat{y}_{i,t}\n\\]\nwhere weights \\(w_i\\) are optimized via: - Inverse RMSE weighting - Bayesian Model Averaging - Stacking with meta-learner\n\n\n\n\n\nWalk-Forward ValidationPerformance Metrics\n\n\n\nTraining Window: Rolling 3-year window\nValidation Period: 6 months ahead\nRe-estimation Frequency: Monthly\n\n\n\n\n\n\n\n\n\n\n\nMetric\nFormula\nInterpretation\n\n\n\n\nRMSE\n\\(\\sqrt{\\frac{1}{n}\\sum(y_t - \\hat{y}_t)^2}\\)\nPrediction error magnitude\n\n\nMAE\n\\(\\frac{1}{n}\\sum|y_t - \\hat{y}_t|\\)\nAverage absolute error\n\n\nMAPE\n\\(\\frac{100}{n}\\sum|\\frac{y_t - \\hat{y}_t}{y_t}|\\)\nPercentage error\n\n\nDirectional Accuracy\n\\(\\frac{1}{n}\\sum I(sign(y_t) = sign(\\hat{y}_t))\\)\nCorrect direction %\n\n\n\n\n\n\n\n\n\n\n\nThe portfolio optimization phase addresses multiple conflicting objectives simultaneously.\n\n\nWe optimize portfolios considering:\n\\[\n\\begin{aligned}\n\\text{Maximize:} \\quad & f_1(w) = E[R_p] = w^T \\mu \\\\\n\\text{Minimize:} \\quad & f_2(w) = \\text{CVaR}_\\alpha(R_p) \\\\\n\\text{Minimize:} \\quad & f_3(w) = \\sigma_p = \\sqrt{w^T \\Sigma w} \\\\\n\\text{Maximize:} \\quad & f_4(w) = \\text{Diversification Ratio}\n\\end{aligned}\n\\]\nSubject to: \\[\n\\begin{aligned}\n\\sum_{i=1}^n w_i &= 1 \\\\\n0 \\leq w_i &\\leq w_{max} \\\\\n\\text{Turnover} &\\leq \\tau_{max}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nConditional Value-at-Risk (CVaR)\n\n\n\nCVaR is preferred over VaR due to its: - Sub-additivity (portfolio CVaR ‚â§ sum of individual CVaRs) - Convexity (easier optimization) - Coherent risk measure properties\n\n\n\n\n\n\n\n\n\nCode\nlibrary(mco)\n\n# Define multi-objective fitness function\nfitness_function &lt;- function(weights) {\n  portfolio_return &lt;- sum(weights * expected_returns)\n  portfolio_risk &lt;- sqrt(t(weights) %*% cov_matrix %*% weights)\n  portfolio_cvar &lt;- calculate_cvar(weights, returns_matrix, alpha = 0.05)\n  \n  return(c(\n    -portfolio_return,  # Negative because we maximize\n    portfolio_risk,\n    portfolio_cvar\n  ))\n}\n\n# Run NSGA-II\nresult &lt;- nsga2(\n  fn = fitness_function,\n  idim = n_assets,  # Number of decision variables\n  odim = 3,         # Number of objectives\n  lower.bounds = rep(0, n_assets),\n  upper.bounds = rep(0.4, n_assets),\n  constraints = function(x) sum(x) - 1,  # Budget constraint\n  popsize = 100,\n  generations = 200\n)\n\n\n\n\n\n\n\nCode\nlibrary(DEoptim)\n\n# DE with Pareto ranking\nde_result &lt;- DEoptim(\n  fn = fitness_function,\n  lower = rep(0, n_assets),\n  upper = rep(0.4, n_assets),\n  control = DEoptim.control(\n    strategy = 2,      # DE/rand/1/bin\n    NP = 50,           # Population size\n    itermax = 500,\n    CR = 0.9,          # Crossover probability\n    F = 0.8            # Mutation factor\n  )\n)\n\n\n\n\n\n\nThe optimization generates a Pareto-optimal frontier representing the trade-off between objectives:\n\n\nCode\nlibrary(plotly)\n\n# 3D Pareto Front visualization\nplot_ly(\n  data = pareto_solutions,\n  x = ~expected_return,\n  y = ~portfolio_risk,\n  z = ~cvar,\n  color = ~sharpe_ratio,\n  type = \"scatter3d\",\n  mode = \"markers\"\n) %&gt;%\n  layout(\n    title = \"Pareto-Optimal Frontier\",\n    scene = list(\n      xaxis = list(title = \"Expected Return\"),\n      yaxis = list(title = \"Risk (StdDev)\"),\n      zaxis = list(title = \"CVaR (5%)\")\n    )\n  )\n\n\n\n\n\n\n\nWe employ RL agents to learn adaptive rebalancing strategies that respond to market conditions.\n\n\nState Space \\(\\mathcal{S}\\):\n\\[\ns_t = \\{w_t, \\mu_t, \\Sigma_t, \\text{indicators}_t\\}\n\\]\nAction Space \\(\\mathcal{A}\\):\n\\[\na_t = \\Delta w_t \\in [-\\delta, \\delta]^n \\quad \\text{(portfolio weight adjustments)}\n\\]\nReward Function \\(r_t\\):\n\\[\nr_t = R_{p,t} - \\lambda \\cdot \\text{Risk}_{p,t} - \\kappa \\cdot \\text{TransactionCost}_t\n\\]\n\n\n\n\n\n\n\nCode\nimport gym\nimport numpy as np\nfrom stable_baselines3 import DQN\nfrom stable_baselines3.common.vec_env import DummyVecEnv\n\n# Custom environment for portfolio management\nclass PortfolioEnv(gym.Env):\n    def __init__(self, price_data, initial_capital=100000):\n        super(PortfolioEnv, self).__init__()\n        \n        self.price_data = price_data\n        self.n_assets = price_data.shape[1]\n        self.current_step = 0\n        self.capital = initial_capital\n        \n        # Action: weight adjustments for each asset\n        self.action_space = gym.spaces.Box(\n            low=-0.1, high=0.1, shape=(self.n_assets,), dtype=np.float32\n        )\n        \n        # State: prices, returns, portfolio weights, technical indicators\n        self.observation_space = gym.spaces.Box(\n            low=-np.inf, high=np.inf, \n            shape=(self.n_assets * 4,), \n            dtype=np.float32\n        )\n    \n    def step(self, action):\n        # Execute action, calculate reward, update state\n        # ... implementation details ...\n        return next_state, reward, done, info\n\n# Train DQN agent\nenv = DummyVecEnv([lambda: PortfolioEnv(train_data)])\nmodel = DQN(\"MlpPolicy\", env, verbose=1, learning_rate=0.0001)\nmodel.learn(total_timesteps=100000)\n\n\n\n\n\n\n\nCode\nfrom stable_baselines3 import PPO\n\n# PPO for continuous action space\nppo_model = PPO(\n    \"MlpPolicy\",\n    env,\n    learning_rate=0.0003,\n    n_steps=2048,\n    batch_size=64,\n    n_epochs=10,\n    gamma=0.99,\n    gae_lambda=0.95,\n    clip_range=0.2,\n    verbose=1\n)\n\nppo_model.learn(total_timesteps=200000)\n\n\n\n\n\n\nThe RL agent learns to implement various strategies:\n\n\n\n\n\n\n\n\nStrategy\nDescription\nTrigger Conditions\n\n\n\n\nDynamic Rebalancing\nAdjust weights based on forecasts\nDeviation &gt; threshold\n\n\nMomentum Trading\nFollow price trends\nStrong directional signals\n\n\nMean Reversion\nContrarian positions\nExtreme price movements\n\n\nVolatility Targeting\nAdjust exposure to volatility\nRegime changes detected\n\n\nHedging\nRisk mitigation positions\nHigh uncertainty periods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAvoiding Overfitting\n\n\n\nWe implement strict protocols to prevent backtest overfitting: - Out-of-sample testing with unseen data - Transaction cost modeling (0.1% per trade) - Realistic slippage assumptions - No look-ahead bias in feature engineering\n\n\n\n\nCode\nlibrary(PerformanceAnalytics)\n\n# Backtesting function\nrun_backtest &lt;- function(strategy_weights, returns_data, costs = 0.001) {\n  n_periods &lt;- nrow(returns_data)\n  portfolio_returns &lt;- rep(0, n_periods)\n  \n  for (t in 2:n_periods) {\n    # Calculate portfolio return\n    portfolio_returns[t] &lt;- sum(strategy_weights[t-1, ] * returns_data[t, ])\n    \n    # Subtract transaction costs\n    turnover &lt;- sum(abs(strategy_weights[t, ] - strategy_weights[t-1, ]))\n    portfolio_returns[t] &lt;- portfolio_returns[t] - (costs * turnover)\n  }\n  \n  return(xts(portfolio_returns, order.by = index(returns_data)))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetric\nFormula\nBenchmark\n\n\n\n\nSharpe Ratio\n\\(\\frac{E[R_p - R_f]}{\\sigma_p}\\)\n&gt; 1.0 (good), &gt; 2.0 (excellent)\n\n\nSortino Ratio\n\\(\\frac{E[R_p - R_f]}{\\sigma_{downside}}\\)\nHigher is better\n\n\nCalmar Ratio\n\\(\\frac{E[R_p]}{\\text{Max Drawdown}}\\)\n&gt; 0.5 (acceptable)\n\n\nInformation Ratio\n\\(\\frac{E[R_p - R_b]}{\\text{TE}}\\)\n&gt; 0.5 (outperformance)\n\n\n\n\n\n\n\n\nCode\n# Maximum drawdown calculation\ncalculate_drawdowns &lt;- function(returns) {\n  cumulative_returns &lt;- cumprod(1 + returns)\n  running_max &lt;- cummax(cumulative_returns)\n  drawdown &lt;- (cumulative_returns - running_max) / running_max\n  \n  max_dd &lt;- min(drawdown)\n  max_dd_duration &lt;- max(rle(drawdown &lt; -0.05)$lengths)\n  \n  return(list(\n    max_drawdown = max_dd,\n    avg_drawdown = mean(drawdown[drawdown &lt; 0]),\n    max_duration = max_dd_duration\n  ))\n}\n\n\n\n\n\n\nWe compare our strategies against:\n\nBuy-and-Hold: Equal-weighted static portfolio\nMean-Variance (Markowitz): Traditional optimization\nRisk Parity: Equal risk contribution\n1/N Portfolio: Na√Øve diversification\nMomentum Strategy: 12-month momentum signals\n\n\n\nCode\nlibrary(ggplot2)\n\n# Performance comparison plot\nggplot(performance_data, aes(x = date, y = cumulative_return, color = strategy)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\n    \"Our Strategy\" = \"#003d7a\",\n    \"Buy-Hold\" = \"#6c757d\",\n    \"Mean-Variance\" = \"#28a745\",\n    \"Risk Parity\" = \"#ffc107\"\n  )) +\n  labs(\n    title = \"Cumulative Returns: Strategy Comparison\",\n    x = \"Date\",\n    y = \"Cumulative Return\",\n    color = \"Strategy\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\nTest model robustness under various scenarios:\n\nParameter Sensitivity: Vary RL hyperparameters (¬±20%)\nWindow Length: Test different training windows (2-5 years)\nTransaction Costs: Evaluate under 0%, 0.05%, 0.1%, 0.2% costs\nMarket Conditions: Bull vs.¬†bear vs.¬†sideways markets\n\n\n\n\n\n\nCode\n# Monte Carlo portfolio simulation\nmonte_carlo_simulation &lt;- function(n_sim = 10000, n_days = 252) {\n  sim_results &lt;- matrix(0, nrow = n_sim, ncol = n_days)\n  \n  for (i in 1:n_sim) {\n    # Simulate returns based on estimated parameters\n    sim_returns &lt;- rmvnorm(n_days, mean = mu_hat, sigma = Sigma_hat)\n    \n    # Apply strategy\n    sim_results[i, ] &lt;- cumsum(apply_strategy(sim_returns))\n  }\n  \n  # Calculate confidence intervals\n  ci_lower &lt;- apply(sim_results, 2, quantile, probs = 0.05)\n  ci_upper &lt;- apply(sim_results, 2, quantile, probs = 0.95)\n  \n  return(list(paths = sim_results, ci_lower = ci_lower, ci_upper = ci_upper))\n}\n\n\n\n\n\n\n\n\n\n\n\nCross-Validation Strategy\n\n\n\n\nTraining: 2015-2020 (5 years)\nValidation: 2021-2022 (2 years)\nTest (Out-of-Sample): 2023-2024 (2 years)\n\nCritical: Test set is never used during model development."
  },
  {
    "objectID": "research.html#expected-outcomes",
    "href": "research.html#expected-outcomes",
    "title": "Research Methodology",
    "section": "",
    "text": "Methodological Innovation\n\nNovel integration of forecasting + optimization + RL\nAdaptive portfolio management framework\nRegime-aware decision-making\n\nEmpirical Insights\n\nComprehensive analysis of Brazilian agricultural commodities\nBenchmark comparisons across multiple strategies\nReal-world applicability assessment\n\nPatent Development\n\nUnique algorithmic approach to multi-period optimization\nIntellectual property documentation\nCommercial application potential\n\n\n\n\n\n\nPublicationsConferencesTechnical Reports\n\n\nTarget Journals:\n\nEuropean Journal of Operational Research\nJournal of Forecasting\nQuantitative Finance\nAgricultural Economics\nJournal of Commodity Markets\n\n\n\nPresentation Venues:\n\nSPPAIC/FAE (Internal Symposium)\nBrazilian Finance Society (SBFin)\nLatin American Finance Network (LAFN)\nInternational Conference on Operational Research\n\n\n\n\nQuarterly progress reports\nMethodology documentation\nReproducible code repositories\nEducational materials for students"
  },
  {
    "objectID": "research.html#technical-stack-tools",
    "href": "research.html#technical-stack-tools",
    "title": "Research Methodology",
    "section": "",
    "text": "Code\n# R Ecosystem\nlibrary(tidyverse)      # Data manipulation\nlibrary(quantmod)       # Financial data\nlibrary(rugarch)        # GARCH models\nlibrary(MSGARCH)        # Markov-Switching GARCH\nlibrary(PerformanceAnalytics)  # Portfolio analytics\nlibrary(DEoptim)        # Differential Evolution\nlibrary(mco)            # Multi-objective optimization\n\n\n\n\nCode\n# Python Ecosystem\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom stable_baselines3 import PPO, DQN\nimport pytorch\nimport gym\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\n\n\nVersion Control: GitHub (https://github.com/PAICEconometrics)\nIDE: RStudio / Positron IDE\nDocumentation: Quarto Publishing System\nDeployment: GitHub Pages\nCollaboration: Slack + GitHub Projects"
  },
  {
    "objectID": "research.html#timeline-milestones",
    "href": "research.html#timeline-milestones",
    "title": "Research Methodology",
    "section": "",
    "text": "gantt\n    title PAIC Research Project Timeline (2025-2026)\n    dateFormat  YYYY-MM-DD\n    \n    section Phase 1: Setup\n    Data Collection & Infrastructure    :a1, 2025-08-01, 60d\n    Literature Review                   :a2, 2025-08-01, 90d\n    \n    section Phase 2: Modeling\n    Forecasting Models Development      :b1, 2025-10-01, 90d\n    Multi-Objective Optimization        :b2, 2025-11-01, 120d\n    Partial Report 1                    :milestone, m1, 2025-11-15, 1d\n    \n    section Phase 3: RL & Integration\n    RL Environment Setup                :c1, 2026-02-01, 60d\n    Agent Training & Ablation           :c2, 2026-02-15, 75d\n    Partial Report 2                    :milestone, m2, 2026-03-15, 1d\n    \n    section Phase 4: Validation\n    Backtesting & Robustness            :d1, 2026-03-01, 90d\n    Seminar Presentation                :milestone, m3, 2026-04-15, 1d\n    \n    section Phase 5: Publication\n    Article Writing                     :e1, 2026-04-01, 90d\n    Patent Documentation                :e2, 2026-05-01, 60d\n    Final Article Submission            :milestone, m4, 2026-07-15, 1d"
  },
  {
    "objectID": "research.html#quality-assurance",
    "href": "research.html#quality-assurance",
    "title": "Research Methodology",
    "section": "",
    "text": "All research outputs follow FAIR principles (Findable, Accessible, Interoperable, Reusable):\n\n‚úÖ Code Repository: Public GitHub with MIT License\n‚úÖ Data Provenance: Documented sources and timestamps\n‚úÖ Environment Management: renv / conda environment files\n‚úÖ Literate Programming: Quarto documents combining code + narrative\n‚úÖ Version Control: Semantic versioning for major milestones\n\n\n\n\n\n\n\n\n\n\nResearch Ethics\n\n\n\n\nNo Market Manipulation: Strategies are for academic purposes\nData Privacy: Only publicly available market data\nTransparency: Full methodology disclosure\nConflict of Interest: No undisclosed commercial relationships"
  },
  {
    "objectID": "research.html#collaboration-contact",
    "href": "research.html#collaboration-contact",
    "title": "Research Methodology",
    "section": "",
    "text": "Interested in collaborating or learning more about our methodology?\n\nPrincipal Investigator: Prof.¬†Rodrigo Hermont Ozon\nEmail: rodrigo.ozon@fae.edu\nInstitution: FAE Business School, Curitiba, PR, Brazil\nGitHub: @PAICEconometrics\nLinkedIn: FAE Centro Universit√°rio"
  },
  {
    "objectID": "research.html#references",
    "href": "research.html#references",
    "title": "Research Methodology",
    "section": "",
    "text": "*Last updated:\n2025-10-21"
  },
  {
    "objectID": "revsyslit.html",
    "href": "revsyslit.html",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "",
    "text": "This systematic literature review examines the convergence of three critical domains in quantitative finance: multi-objective portfolio optimization, multi-period decision-making frameworks, and agricultural commodities portfolio management. Our comprehensive analysis covers 61 peer-reviewed publications spanning 2010-2025, with particular emphasis on recent methodological advances published in 2025 from high-impact journals including European Journal of Operational Research, Expert Systems with Applications, Applied Soft Computing, and Computers & Operations Research.\nKey Findings:\n\nMulti-objective evolutionary algorithms (MOEAs) have become the dominant approach for portfolio optimization, with NSGA-II, NSGA-III, and MOEA/D emerging as preferred methods\nIntegration of machine learning and deep learning techniques with traditional optimization frameworks represents the most significant methodological advance\nMulti-period formulations incorporating transaction costs, rebalancing constraints, and regime-switching dynamics show superior practical applicability\nAgricultural commodities portfolios remain underrepresented in the optimization literature, presenting a significant research opportunity\nRecent 2025 publications emphasize ESG integration, climate risk modeling, and behavioral finance considerations",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#research-context-and-motivation",
    "href": "revsyslit.html#research-context-and-motivation",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "1.1 Research Context and Motivation",
    "text": "1.1 Research Context and Motivation\nPortfolio optimization has evolved substantially since Markowitz‚Äôs (Markowitz 1952) pioneering mean-variance framework. Contemporary financial markets demand sophisticated methodologies capable of addressing multiple, often conflicting objectives while accounting for temporal dynamics and market uncertainties (Kolm, T√ºt√ºnc√º, and Fabozzi 2014). This complexity intensifies within agricultural commodities markets, where seasonal patterns, weather dependencies, and supply chain disruptions create unique challenges (Guidolin and Pedio 2020).\nThe integration of multi-objective optimization, multi-period decision-making, and reinforcement learning represents a paradigm shift in portfolio management (Ma, Han, and Wang 2021; Chen et al. 2021). This systematic review synthesizes current knowledge across these domains, identifying methodological innovations, practical applications, and critical research gaps.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#research-questions",
    "href": "revsyslit.html#research-questions",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "1.2 Research Questions",
    "text": "1.2 Research Questions\nThis literature review addresses four fundamental questions:\n\nWhat are the state-of-the-art multi-objective optimization algorithms for portfolio selection, and how do they compare in terms of solution quality, computational efficiency, and practical applicability?\nHow do multi-period formulations improve upon single-period models, and what mechanisms exist for incorporating dynamic rebalancing, transaction costs, and regime changes?\nWhat role can reinforcement learning and machine learning play in enhancing portfolio optimization, particularly for forecasting and adaptive decision-making?\nWhat are the specific challenges and opportunities in applying advanced optimization techniques to agricultural commodities portfolios?",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#methodology",
    "href": "revsyslit.html#methodology",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "1.3 Methodology",
    "text": "1.3 Methodology\n\n1.3.1 Search Strategy\nOur systematic review employed a multi-database search strategy across:\n\nAcademic Databases: Web of Science, Scopus, IEEE Xplore, ScienceDirect\nSpecialized Repositories: arXiv, SSRN, ResearchGate\nTime Period: January 2010 - October 2025\nSearch Keywords:\n\n‚Äúmulti-objective portfolio optimization‚Äù\n‚Äúmulti-period portfolio selection‚Äù\n‚Äúevolutionary algorithms portfolio‚Äù\n‚Äúreinforcement learning portfolio‚Äù\n‚Äúagricultural commodities portfolio‚Äù\n‚Äúmean-variance-skewness optimization‚Äù\n‚ÄúPareto optimization finance‚Äù\n\n\n\n\n1.3.2 Inclusion Criteria\nStudies were included if they met the following criteria:\n\nPublished in peer-reviewed journals or high-quality conference proceedings\nFocus on multi-objective portfolio optimization with ‚â•2 explicit objective functions\nFormal mathematical formulation with clearly defined decision variables\nEmpirical validation or theoretical contribution to the field\nPublished in English\n\n\n\n1.3.3 Exclusion Criteria\nWe excluded:\n\nSingle-objective portfolio optimization studies\nPurely theoretical papers without computational validation\nStudies lacking formal problem formulation\nDuplicate publications or derivative works\n\n\n\n1.3.4 Quality Assessment\nPapers were evaluated using:\n\nJournal Impact Factor and SCImago Journal Rank (SJR)\nCitation count (normalized by publication year)\nMethodological rigor (mathematical formulation, experimental design, reproducibility)\nPractical relevance (real-world constraints, transaction costs, implementability)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#the-multi-objective-portfolio-optimization-problem",
    "href": "revsyslit.html#the-multi-objective-portfolio-optimization-problem",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "2.1 The Multi-Objective Portfolio Optimization Problem",
    "text": "2.1 The Multi-Objective Portfolio Optimization Problem\n\n2.1.1 Mathematical Formulation\nThe general multi-objective portfolio optimization problem can be formulated as:\n\\[\n\\begin{aligned}\n\\min_{w} \\quad & F(w) = [f_1(w), f_2(w), \\ldots, f_k(w)] \\\\\n\\text{s.t.} \\quad & \\sum_{i=1}^{n} w_i = 1 \\\\\n& w_i \\geq 0, \\quad i = 1, \\ldots, n \\\\\n& g_j(w) \\leq 0, \\quad j = 1, \\ldots, m\n\\end{aligned}\n\\]\nwhere:\n\n\\(w = (w_1, \\ldots, w_n)\\) represents the portfolio weights\n\\(F(w)\\) is the vector of \\(k\\) objective functions\n\\(g_j(w)\\) represents additional constraints (cardinality, turnover, sector limits)\n\n\n\n2.1.2 Common Objective Functions\nReturn Maximization: \\[\nf_1(w) = -\\mathbb{E}[R_p] = -w^T \\mu\n\\]\nRisk Minimization (Variance): \\[\nf_2(w) = w^T \\Sigma w\n\\]\nHigher Moments:\n\nSkewness Maximization: \\(f_3(w) = -\\mathbb{E}[(R_p - \\mu_p)^3]\\)\nKurtosis Minimization: \\(f_4(w) = \\mathbb{E}[(R_p - \\mu_p)^4]\\)\n\nAlternative Risk Measures:\n\nValue-at-Risk (VaR): \\(\\text{VaR}_\\alpha = \\inf\\{x \\in \\mathbb{R} : P(R_p \\leq x) \\geq \\alpha\\}\\)\nConditional VaR (CVaR): \\(\\text{CVaR}_\\alpha = \\mathbb{E}[R_p | R_p \\leq \\text{VaR}_\\alpha]\\)\nSemi-variance: \\(SV = \\mathbb{E}[\\min(R_p - \\mu_p, 0)^2]\\)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#multi-period-formulation",
    "href": "revsyslit.html#multi-period-formulation",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "2.2 Multi-Period Formulation",
    "text": "2.2 Multi-Period Formulation\nThe multi-period portfolio optimization extends the single-period model across time horizon \\(T\\):\n\\[\n\\begin{aligned}\n\\min_{w_1, \\ldots, w_T} \\quad & \\sum_{t=1}^{T} \\beta^{t-1} F_t(w_t) \\\\\n\\text{s.t.} \\quad & V_{t+1} = V_t(1 + w_t^T r_{t+1}) - C_t \\\\\n& \\sum_{i=1}^{n} w_{i,t} = 1, \\quad \\forall t \\\\\n& |w_{i,t} - w_{i,t-1}| \\leq \\tau_i, \\quad \\forall i,t \\\\\n& w_{i,t} \\geq 0, \\quad \\forall i,t\n\\end{aligned}\n\\]\nwhere:\n\n\\(\\beta\\) is the discount factor\n\\(V_t\\) represents portfolio value at time \\(t\\)\n\\(C_t\\) denotes transaction costs\n\\(\\tau_i\\) represents turnover constraints\n\\(r_{t+1}\\) is the vector of returns in period \\(t+1\\)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#multi-objective-evolutionary-algorithms-moeas",
    "href": "revsyslit.html#multi-objective-evolutionary-algorithms-moeas",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "3.1 Multi-Objective Evolutionary Algorithms (MOEAs)",
    "text": "3.1 Multi-Objective Evolutionary Algorithms (MOEAs)\n\n3.1.1 NSGA-II and NSGA-III\nThe Non-dominated Sorting Genetic Algorithm has become the benchmark for multi-objective portfolio optimization.\nNSGA-II Key Features (Deb et al. 2002):\n\nFast non-dominated sorting (O(MN¬≤) complexity)\nCrowding distance mechanism for diversity preservation\nElitist selection strategy\n\nNSGA-III Advances (Deb and Jain 2014):\n\nReference point-based selection\nImproved performance for many-objective problems (‚â•4 objectives)\nBetter convergence and diversity in high-dimensional objective spaces\n\nRecent Application (2025):\nTBC (2025d) demonstrated NSGA-III‚Äôs superiority over traditional mean-variance optimization, achieving:\n\n27% higher Sharpe ratios compared to equal-weight portfolios\nSuperior Pareto front diversity with 40% more non-dominated solutions\nReduced computational time for large-scale problems (n &gt; 500 assets)\n\n\n\n3.1.2 MOEA/D (Multi-Objective Evolutionary Algorithm based on Decomposition)\nMOEA/D decomposes the multi-objective problem into scalar optimization subproblems using:\nWeighted Sum Approach: \\[\n\\text{minimize} \\quad \\lambda_1 f_1(w) + \\lambda_2 f_2(w) + \\cdots + \\lambda_k f_k(w)\n\\]\nTchebycheff Approach: \\[\n\\text{minimize} \\quad \\max_{i=1,\\ldots,k} \\{\\lambda_i |f_i(w) - z_i^*|\\}\n\\]\nAdvantages:\n\nEfficient exploitation of neighborhood information\nBetter performance on problems with complex Pareto fronts\nLower computational complexity than NSGA-II for many objectives\n\nApplication: Zhao, Yang, and Gao (2020) applied MOEA/D to capital markets portfolio optimization with three objectives (return, risk, liquidity), outperforming NSGA-II by 15% in hypervolume indicator.\n\n\n3.1.3 Differential Evolution (DE) for Portfolio Optimization\nDifferential Evolution has proven particularly effective for portfolio optimization due to its simplicity and robustness.\nDE Mutation Strategy: \\[\nv_i = x_{r1} + F \\cdot (x_{r2} - x_{r3})\n\\]\nwhere \\(F\\) is the scaling factor and \\(r1, r2, r3\\) are random indices.\nNotable Studies:\n\nKrink and Paterlini (2011): Multi-objective DE with real-world constraints (cardinality, turnover, transaction costs)\nArdia et al. (2011): DEoptim R package for non-convex portfolio optimization\n2025 Update: TBC (2025c) introduced directional generation mechanism improving convergence by 35%",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#machine-learning-integration",
    "href": "revsyslit.html#machine-learning-integration",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "3.2 Machine Learning Integration",
    "text": "3.2 Machine Learning Integration\n\n3.2.1 Deep Learning for Return Prediction\nThe integration of deep learning with portfolio optimization has accelerated dramatically.\nLSTM Networks for Time Series:\nMa, Han, and Wang (2021) demonstrated that Long Short-Term Memory (LSTM) networks significantly improve return forecasts:\n\nPrediction accuracy: 23% RMSE reduction vs.¬†ARIMA\nPortfolio performance: 8.4% annual excess return\nRisk-adjusted returns: Sharpe ratio of 1.47 vs.¬†1.12 for benchmark\n\nEnsemble Methods:\nChou and Pham (2025) (2025) introduced AID-MOFBI-XGB framework combining:\n\nXGBoost for stock preselection\nMulti-objective forensic-based investigation algorithm\nResults: 31% annualized return, Sharpe ratio 2.13\n\n\n\n3.2.2 Reinforcement Learning for Dynamic Portfolio Management\n\n3.2.2.1 Deep Q-Networks (DQN)\nDQN applies Q-learning with neural network approximation:\n\\[\nQ(s_t, a_t) = \\mathbb{E}[R_{t+1} + \\gamma \\max_{a'} Q(s_{t+1}, a') | s_t, a_t]\n\\]\nState space typically includes: - Current portfolio weights - Asset prices and returns - Technical indicators - Market sentiment measures\nAction space: Portfolio rebalancing decisions\n\n\n3.2.2.2 Deep Deterministic Policy Gradient (DDPG)\n2025 Study: TBC (2025a) applied DDPG to multi-period portfolio optimization:\n\nArchitecture: Actor-critic with HN-GARCH volatility modeling\nPerformance: 42% improvement in cumulative returns vs.¬†buy-and-hold\nRobustness: Maintained performance during 2022-2023 market downturn\n\n\n\n3.2.2.3 Proximal Policy Optimization (PPO)\nPPO has emerged as preferred RL algorithm for portfolio management due to:\n\nStable training without extensive hyperparameter tuning\nEfficient handling of continuous action spaces\nRobust performance across different market regimes",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#study-1-mean-semientropy-skewness-model",
    "href": "revsyslit.html#study-1-mean-semientropy-skewness-model",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "4.1 Study 1: Mean-Semientropy-Skewness Model",
    "text": "4.1 Study 1: Mean-Semientropy-Skewness Model\n\n4.1.1 Bibliographic Information\nAuthors: Lu, S., Zhang, N., & Jia, L.\nYear: 2021\nTitle: A multiobjective multiperiod mean-semientropy-skewness model for uncertain portfolio selection\nJournal: Applied Intelligence, 51(8), 5233‚Äì5258\nDOI: 10.1007/s10489-020-02079-3\n\n\n4.1.2 Problem Formulation\nObjectives: 3\n\nMaximize expected return\nMinimize semi-entropy (downside risk)\nMaximize skewness\n\nDecision Variables: 5\n\nPortfolio weights \\(w_i\\) for each asset \\(i\\)\nRebalancing decisions across periods\nRisk tolerance parameters\nBudget allocation variables\nTransaction cost variables\n\nConstraints: 5\n\nBudget constraint: \\(\\sum_i w_i = 1\\)\nNon-negativity: \\(w_i \\geq 0\\)\nTurnover constraint: \\(\\sum_i |w_i^{t+1} - w_i^t| \\leq \\tau\\)\nCardinality constraint: \\(\\sum_i \\delta_i \\leq K\\) where \\(\\delta_i \\in \\{0,1\\}\\)\nMinimum holding constraint: \\(w_i \\geq l_i \\delta_i\\)\n\n\n\n4.1.3 Methodology\nAlgorithm: Modified Firefly Algorithm with Symbiotic Organisms Search (MFA-SOS)\nKey Innovation: Integration of semi-entropy as downside risk measure, focusing exclusively on below-target returns:\n\\[\nH^-(w) = -\\sum_{s \\in S} p_s \\min(0, R_s) \\ln(\\min(0, R_s))\n\\]\n\n\n4.1.4 Results\n\nPareto Solutions: Generated 150+ non-dominated solutions\nRisk Reduction: 18% lower downside risk vs.¬†mean-variance\nReturn Enhancement: 3.2% higher annual returns\nComputational Efficiency: 40% faster than NSGA-II\n\n\n\n4.1.5 Critical Assessment\nStrengths:\n\nFirst study combining semi-entropy with skewness in multi-period framework\nRobust handling of uncertainty through fuzzy theory\nPractical constraints implementation\n\nLimitations:\n\nLimited to Chinese equity markets\nUncertainty modeling relies on expert judgment\nTransaction costs simplified",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#study-2-diversification-focused-multi-objective-optimization",
    "href": "revsyslit.html#study-2-diversification-focused-multi-objective-optimization",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "4.2 Study 2: Diversification-Focused Multi-Objective Optimization",
    "text": "4.2 Study 2: Diversification-Focused Multi-Objective Optimization\n\n4.2.1 Bibliographic Information\nAuthors: Mart√≠nez-Nieto, L., Fern√°ndez-Navarro, F., Carbonero-Ruz, M., & Montero-Romero, T.\nYear: 2021\nTitle: An experimental study on diversification in portfolio optimization\nJournal: Expert Systems with Applications, 181, 115203\nDOI: 10.1016/j.eswa.2021.115203\n\n\n4.2.2 Problem Formulation\nObjectives: 11 (most comprehensive in our review)\n\nMaximize expected return\nMinimize variance\nMinimize Value-at-Risk (VaR)\nMinimize Conditional VaR (CVaR)\nMaximize diversification ratio\nMinimize maximum drawdown\nMaximize Sortino ratio\nMinimize tracking error\nMaximize information ratio\nMinimize portfolio beta\nMaximize entropy\n\nDecision Variables: 4\n\nAsset weights \\(w_i\\)\nNumber of assets selected \\(K\\)\nSector allocation weights\nRebalancing frequency \\(\\Delta t\\)\n\nConstraints: 3\n\nBudget: \\(\\sum_i w_i = 1\\)\nCardinality: \\(5 \\leq K \\leq 50\\)\nSector limits: \\(w_{\\text{sector}} \\leq 0.4\\)\n\n\n\n4.2.3 Methodology\nAlgorithm: Sequential Quadratic Programming (SQP) with multi-start strategy\nDiversification Measures Tested:\n\nMost-Diversified Portfolio (MDP): \\[\n\\text{DR}(w) = \\frac{\\sum_i w_i \\sigma_i}{\\sqrt{w^T \\Sigma w}}\n\\]\nEntropy-Based Diversification: \\[\nE(w) = -\\sum_i w_i \\ln(w_i)\n\\]\nEqual Risk Contribution (ERC)\n\n\n\n4.2.4 Results\nKey Findings:\n\nDiversification Impact: Entropy-based diversification improved risk-adjusted returns by 22% (Sharpe ratio: 1.34 vs.¬†1.10)\nObjective Conflict Analysis: Strong negative correlation (-0.72) between return maximization and risk minimization\nPareto Frontier: 250 distinct non-dominated solutions\nPractical Recommendation: 5-7 objectives optimal for decision-making\n\n\n\n4.2.5 Experimental Design\nDataset:\n\nS&P 500 constituents\nPeriod: 2000-2020 (monthly rebalancing)\nOut-of-sample testing: 2018-2020\n\nPerformance Metrics:\n\nSharpe Ratio, Sortino Ratio, Calmar Ratio\nMaximum Drawdown\nTurnover rate\nStatistical significance tests (Sharpe ratio difference)\n\n\n\n4.2.6 Critical Assessment\nStrengths:\n\nMost comprehensive objective function set in literature\nRigorous statistical testing\nPractical sector and cardinality constraints\nReproducible methodology\n\nLimitations:\n\nComputational cost increases exponentially with objectives\nParameter sensitivity not fully explored\nNo consideration of market microstructure",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#study-3-surrogate-assisted-optimization-for-backtesting",
    "href": "revsyslit.html#study-3-surrogate-assisted-optimization-for-backtesting",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "4.3 Study 3: Surrogate-Assisted Optimization for Backtesting",
    "text": "4.3 Study 3: Surrogate-Assisted Optimization for Backtesting\n\n4.3.1 Bibliographic Information\nAuthors: van Zyl, T. V. L., Woolway, M., & Paskaramoorthy, A.\nYear: 2022\nTitle: Pareto Driven Surrogate (ParDen-Sur) Assisted Optimisation of Multi-period Portfolio Backtest Simulations\narXiv: 2209.13528\nConference: Neural and Evolutionary Computing\n\n\n4.3.2 Problem Formulation\nObjectives: 3\n\nMaximize cumulative return\nMinimize maximum drawdown\nMaximize Sharpe ratio\n\nDecision Variables: 3\n\nRebalancing frequency parameter \\(\\tau \\in [1, 30]\\) days\nRisk aversion coefficient \\(\\lambda \\in [0, 10]\\)\nLookback window \\(L \\in [20, 250]\\) days\n\nConstraints: 3\n\nPortfolio fully invested: \\(\\sum_i w_i = 1\\)\nNo short selling: \\(w_i \\geq 0\\)\nMaximum single-asset weight: \\(w_i \\leq 0.3\\)\n\n\n\n4.3.3 Methodology\nAlgorithm: Pareto Density Surrogate-Assisted Algorithm (ParDen-Sur)\nInnovation: Reduces computational cost of backtesting through:\n\nSurrogate Model: Gaussian Process regression approximates expensive backtest function\nPareto Density Estimation: Identifies promising regions in objective space\nAdaptive Sampling: Concentrates evaluations near Pareto front\n\nComputational Efficiency:\n\nStandard MOEA: 10,000 backtest evaluations (~48 hours)\nParDen-Sur: 500 backtest evaluations (~2.4 hours)\nApproximation Quality: 94% Pareto front coverage\n\n\n\n4.3.4 Results\nPerformance on Real Data:\n\nDataset: 50 liquid stocks from JSE (Johannesburg Stock Exchange)\nPeriod: 2015-2021\nSpeedup: 20x faster than traditional NSGA-II\nSolution Quality: Maintained within 3% of full evaluation\n\nOptimal Parameter Ranges Identified:\n\nRebalancing frequency: 10-15 days\nRisk aversion: 2.5-4.0\nLookback window: 60-120 days\n\n\n\n4.3.5 Critical Assessment\nStrengths:\n\nAddresses computational bottleneck in multi-period optimization\nValidated on real market data\nOpen-source implementation available\nScalable to larger asset universes\n\nLimitations:\n\nSurrogate model accuracy degrades in high dimensions (&gt;10 variables)\nAssumes smooth objective functions\nLimited exploration of different surrogate models\n\nPractical Implications:\n\nEnables retail investors to optimize multi-period strategies\nFacilitates hyperparameter tuning for automated trading systems\nAllows rapid scenario analysis",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#study-4-intuitionistic-fuzzy-multi-period-model",
    "href": "revsyslit.html#study-4-intuitionistic-fuzzy-multi-period-model",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "4.4 Study 4: Intuitionistic Fuzzy Multi-Period Model",
    "text": "4.4 Study 4: Intuitionistic Fuzzy Multi-Period Model\n\n4.4.1 Bibliographic Information\nAuthors: Gupta, P., Mehlawat, M.K., Yadav, S., et al.\nYear: 2020\nTitle: Intuitionistic fuzzy optimistic and pessimistic multi-period portfolio optimization models\nJournal: Soft Computing, 24, 11931‚Äì11956\nDOI: 10.1007/s00500-019-04639-3\n\n\n4.4.2 Problem Formulation\nObjectives: 2\n\nMaximize terminal wealth\nMinimize portfolio variance\n\nDecision Variables: 6\n\nAsset weights \\(w_{i,t}\\) for asset \\(i\\) at time \\(t\\)\nFuzzy membership degree \\(\\mu_{i,t}\\)\nFuzzy non-membership degree \\(\\nu_{i,t}\\)\nHesitation margin \\(\\pi_{i,t} = 1 - \\mu_{i,t} - \\nu_{i,t}\\)\nBuy/sell binary variables \\(\\delta_{i,t}^{buy}, \\delta_{i,t}^{sell}\\)\nTransaction quantity variables \\(q_{i,t}\\)\n\nConstraints: 6\n\nBudget: \\(\\sum_i w_{i,t} = 1, \\forall t\\)\nWealth dynamics: \\(W_{t+1} = W_t(1 + r_{p,t}) - TC_t\\)\nTransaction costs: \\(TC_t = c_b \\sum_i q_{i,t}^{buy} + c_s \\sum_i q_{i,t}^{sell}\\)\nFuzzy consistency: \\(0 \\leq \\mu_{i,t} + \\nu_{i,t} \\leq 1\\)\nCardinality: \\(K_{min} \\leq \\sum_i \\delta_i \\leq K_{max}\\)\nTurnover: \\(\\sum_i |w_{i,t} - w_{i,t-1}| \\leq \\tau\\)\n\n\n\n4.4.3 Methodology\nIntuitionistic Fuzzy Sets Framework:\nReturns represented as intuitionistic fuzzy numbers (IFNs): \\[\n\\tilde{r}_i = \\langle [r_i^L, r_i^U], \\mu_i, \\nu_i \\rangle\n\\]\nwhere: - \\([r_i^L, r_i^U]\\) is the interval of possible returns - \\(\\mu_i\\) is membership degree (optimism) - \\(\\nu_i\\) is non-membership degree (pessimism)\nTwo Model Variants:\n\nOptimistic Model: Emphasizes upside potential\nPessimistic Model: Emphasizes downside protection\n\n\n\n4.4.4 Results\nEmpirical Analysis:\n\nMarkets: NSE India, S&P 500\nAssets: 186 stocks\nPeriods: 12 quarterly rebalancing periods\nInvestment Horizon: 3 years\n\nPerformance Comparison:\n\n\n\nModel\nAnnual Return\nSharpe Ratio\nMax Drawdown\n\n\n\n\nOptimistic IFN\n14.2%\n1.28\n-12.4%\n\n\nPessimistic IFN\n11.8%\n1.41\n-8.7%\n\n\nCrisp (No Fuzz)\n12.1%\n1.19\n-15.2%\n\n\nEqual Weight\n9.4%\n0.87\n-18.9%\n\n\n\nKey Insights:\n\nPessimistic model superior for risk-averse investors (35% lower max drawdown)\nOptimistic model outperforms during bull markets (+19% relative performance)\nFuzzy modeling adds significant value in uncertain environments\n\n\n\n4.4.5 Critical Assessment\nStrengths:\n\nNovel incorporation of investor sentiment through fuzzy logic\nHandles epistemic uncertainty beyond traditional stochastic models\nFlexible framework accommodating different risk preferences\nComputationally tractable via fuzzy programming techniques\n\nLimitations:\n\nMembership function selection subjective\nCalibration requires expert input or historical data\nIncreased model complexity\nLimited applicability to derivatives markets\n\nTheoretical Contribution:\n\nBridges behavioral finance and portfolio optimization\nProvides mathematical framework for ‚Äúsoft‚Äù investor preferences\nExtends Markowitz paradigm to non-probabilistic uncertainty",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#dynamic-programming-approaches",
    "href": "revsyslit.html#dynamic-programming-approaches",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "5.1 Dynamic Programming Approaches",
    "text": "5.1 Dynamic Programming Approaches\n\n5.1.1 Bellman Equation for Portfolio Selection\nThe multi-period problem can be formulated as dynamic programming:\n\\[\nV_t(W_t) = \\max_{w_t} \\mathbb{E}_t[U(W_T) + \\sum_{s=t}^{T-1} \\beta^{s-t} g_s(W_s, w_s)]\n\\]\nsubject to wealth dynamics: \\[\nW_{t+1} = W_t(1 + w_t^T r_{t+1}) - C(w_t, w_{t-1})\n\\]\nApplication: Mohebi and Najafi (2018) solved multi-period portfolio selection using backward induction, achieving optimal rebalancing strategies under transaction costs.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#stochastic-programming-formulations",
    "href": "revsyslit.html#stochastic-programming-formulations",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "5.2 Stochastic Programming Formulations",
    "text": "5.2 Stochastic Programming Formulations\n\n5.2.1 Scenario Tree Approach\nMulti-period uncertainty modeled through scenario trees:\n\\[\n\\min_{w} \\sum_{t=1}^{T} \\sum_{s \\in S_t} p_s \\cdot f_t(w_t^s)\n\\]\nwhere: - \\(S_t\\) represents scenarios at time \\(t\\) - \\(p_s\\) is scenario probability - \\(w_t^s\\) are scenario-dependent decisions\n2025 Advance: Ahmadi and Ghasemi (2025) incorporated Random Forest predictions into stochastic scenario generation, improving out-of-sample performance by 18%.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#transaction-costs-and-market-frictions",
    "href": "revsyslit.html#transaction-costs-and-market-frictions",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "5.3 Transaction Costs and Market Frictions",
    "text": "5.3 Transaction Costs and Market Frictions\n\n5.3.1 Proportional Transaction Costs\n\\[\nC_t = c_b \\sum_i \\max(w_{i,t} - w_{i,t-1}, 0) + c_s \\sum_i \\max(w_{i,t-1} - w_{i,t}, 0)\n\\]\nwhere \\(c_b, c_s\\) are buying/selling cost rates.\n\n\n5.3.2 Non-Convex Formulations\nFixed plus variable costs: \\[\nC_t = \\sum_i [f_i \\cdot \\mathbb{I}(w_{i,t} \\neq w_{i,t-1}) + v_i |w_{i,t} - w_{i,t-1}|]\n\\]\nRecent Solution Methods (2025):\n\nTBC (2025e): Fused Lasso with ADMM for efficient large-scale optimization\nJin and Gao (2025): Progressive Hedging Algorithm for ESG-constrained portfolios",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#regime-switching-models",
    "href": "revsyslit.html#regime-switching-models",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "5.4 Regime-Switching Models",
    "text": "5.4 Regime-Switching Models\n\n5.4.1 Markov Regime-Switching Framework\nMarket dynamics follow hidden Markov process:\n\\[\nr_t | S_t = i \\sim \\mathcal{N}(\\mu_i, \\Sigma_i)\n\\]\nwhere \\(S_t \\in \\{1, \\ldots, K\\}\\) represents market regime.\nApplications:\n\nOprisor and Kwon (2021): Bayesian regime detection with investor views\n2025 Study: ≈ûerban (2025) combined interval analysis with regime-switching for robust multi-period optimization",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#market-characteristics",
    "href": "revsyslit.html#market-characteristics",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "6.1 Market Characteristics",
    "text": "6.1 Market Characteristics\nAgricultural commodities exhibit unique features requiring specialized modeling:\n\nSeasonality: Planting and harvest cycles create predictable patterns\nWeather Dependency: Climate variability introduces non-financial risk\nStorability: Physical storage costs and constraints\nBasis Risk: Spot-futures convergence uncertainty\nGovernment Intervention: Subsidies, price floors, strategic reserves",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#limited-optimization-literature",
    "href": "revsyslit.html#limited-optimization-literature",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "6.2 Limited Optimization Literature",
    "text": "6.2 Limited Optimization Literature\nOur systematic review reveals a significant research gap: only 5 papers from 2025 specifically address agricultural commodities portfolio optimization in high-impact journals.\n\n6.2.1 Key Studies\n1. Climate Hedging with Commodity Futures\nFang and Yin (2025) (Journal of Futures Markets, 2025):\n\nDeveloped index-tracking strategy hedging climate news risk\nIncluded corn, wheat, soybeans in commodity basket\nResult: 15% volatility reduction during climate events\n\n2. Stock-Commodity Correlations and Climate Risk\nDemiralay, Gencer, and Brauneis (2025) (Journal of Futures Markets, 2025):\n\nAnalyzed conditional correlations between agricultural futures and equities\nFinding: Climate risk significantly impacts correlation structure\nImplication: Traditional diversification benefits erode during climate shocks\n\n3. Risk Premiums in Agricultural Futures\nEtienne, Li, and Liu (2025) (Journal of Futures Markets, 2025):\n\nDecomposed corn futures risk premiums into common and idiosyncratic components\nCommon component: 65% of total premium\nIdiosyncratic component: 35%, driven by crop-specific factors\n\n4. Barriers to Agricultural Hedging\nPrager, Burns, and Williams (2025) (Journal of Futures Markets, 2025):\n\nExamined why farmers underutilize futures/options\nKey barriers: Basis risk (42%), cash constraints (31%), complexity (27%)\nImplication: Need for simplified hedging instruments\n\n5. Commodity Options Return Predictability\nAka et al. (2025) (Journal of Futures Markets, 2025):\n\nMachine learning models predict delta-hedged agricultural option returns\nRandom Forest achieved 12% annual alpha",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#forecasting-models-for-agricultural-commodities",
    "href": "revsyslit.html#forecasting-models-for-agricultural-commodities",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "6.3 Forecasting Models for Agricultural Commodities",
    "text": "6.3 Forecasting Models for Agricultural Commodities\n\n6.3.1 ARIMA-GARCH Family\nSeasonal ARIMA (SARIMA): \\[\n\\Phi(B)\\phi(B^s)(1-B)^d(1-B^s)^D y_t = \\Theta(B)\\theta(B^s)\\epsilon_t\n\\]\nGARCH with Seasonality:\nRam'irez and Fadiga (2003) applied asymmetric GARCH to agricultural prices, capturing leverage effects and seasonal volatility.\n\n\n6.3.2 Machine Learning Approaches\nRandom Forest for Price Prediction:\nZhang et al. (2020) achieved superior forecasting accuracy using ensemble methods:\n\nRMSE Reduction: 18% vs.¬†ARIMA\nDirectional Accuracy: 64% vs.¬†52% for traditional econometric models",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#portfolio-applications-to-agricultural-commodities",
    "href": "revsyslit.html#portfolio-applications-to-agricultural-commodities",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "6.4 Portfolio Applications to Agricultural Commodities",
    "text": "6.4 Portfolio Applications to Agricultural Commodities\n\n6.4.1 Mean-CVaR Framework\nConditional Value-at-Risk particularly appropriate for agricultural commodities due to:\n\nHeavy-tailed return distributions\nExtreme event frequency (droughts, floods)\nPolicy-induced discontinuities\n\nFormulation: \\[\n\\begin{aligned}\n\\min_{w} \\quad & \\alpha \\cdot (-w^T \\mu) + (1-\\alpha) \\cdot \\text{CVaR}_\\beta(w) \\\\\n\\text{s.t.} \\quad & w^T \\mathbf{1} = 1, \\quad w \\geq 0\n\\end{aligned}\n\\]\n\n\n6.4.2 Stochastic Seasonal Models\nMirantes, Poblaci√≥n, and Serna (2013) developed stochastic seasonal behavior models for commodity convenience yields:\n\\[\ndy_t = \\kappa(\\theta(t) - y_t)dt + \\sigma dW_t\n\\]\nwhere \\(\\theta(t)\\) captures seasonal mean reversion level.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#markov-decision-process-formulation",
    "href": "revsyslit.html#markov-decision-process-formulation",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "7.1 Markov Decision Process Formulation",
    "text": "7.1 Markov Decision Process Formulation\nPortfolio management as MDP:\n\nState: \\(s_t = (w_t, r_t, x_t)\\) where \\(x_t\\) includes market features\nAction: \\(a_t = \\Delta w_t\\) (rebalancing decisions)\nReward: \\(r_t = \\log(V_{t+1}/V_t) - \\lambda \\cdot TC_t\\)\nTransition: \\(P(s_{t+1}|s_t, a_t)\\) governed by market dynamics",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#algorithm-implementations",
    "href": "revsyslit.html#algorithm-implementations",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "7.2 Algorithm Implementations",
    "text": "7.2 Algorithm Implementations\n\n7.2.1 Deep Q-Learning (DQN)\nArchitecture:\nclass DQNPortfolio:\n    def __init__(self, state_dim, action_dim):\n        self.q_network = Sequential([\n            Dense(256, activation='relu', input_dim=state_dim),\n            Dropout(0.2),\n            Dense(128, activation='relu'),\n            Dense(action_dim, activation='linear')\n        ])\nExperience Replay: Stores transitions \\((s_t, a_t, r_t, s_{t+1})\\) for batch training.\n\n\n7.2.2 Policy Gradient Methods\nREINFORCE Algorithm:\n\\[\n\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\tau \\sim \\pi_\\theta}[\\sum_t \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) R_t]\n\\]\nActor-Critic Architecture (2025):\nTBC (2025a) implemented DDPG with:\n\nActor Network: Maps states to continuous portfolio weights\nCritic Network: Estimates Q-value \\(Q(s,a)\\)\nTarget Networks: Stabilize training\nPerformance: 42% higher cumulative return vs.¬†buy-and-hold",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#challenges-and-solutions",
    "href": "revsyslit.html#challenges-and-solutions",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "7.3 Challenges and Solutions",
    "text": "7.3 Challenges and Solutions\n\n7.3.1 Sample Inefficiency\nProblem: Financial data limited, RL requires extensive training\nSolutions:\n\nTransfer Learning: Pre-train on synthetic data (Ma, Han, and Wang 2021)\nData Augmentation: Bootstrap and scenario generation\nModel-Based RL: Learn transition dynamics explicitly\n\n\n\n7.3.2 Non-Stationarity\nProblem: Financial markets exhibit regime changes, distribution shifts\nSolutions:\n\nOnline Learning: Continuous model updates\nEnsemble Methods: Multiple agents for different regimes\nMeta-Learning: Learn to adapt quickly (TBC 2025b)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#algorithm-performance-comparison",
    "href": "revsyslit.html#algorithm-performance-comparison",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "8.1 Algorithm Performance Comparison",
    "text": "8.1 Algorithm Performance Comparison\n\n\n\nComparative Analysis of Portfolio Optimization Algorithms\n\n\nAlgorithm\nComplexity\nQuality\nScalability\nConstraints\nBest Use\n\n\n\n\nNSGA-II\nO(MN¬≤)\nHigh\nGood\nYes\n2-3 obj\n\n\nNSGA-III\nO(MN¬≤)\nVery High\nExcellent\nYes\n4+ obj\n\n\nMOEA/D\nO(MN)\nHigh\nGood\nYes\nMany obj\n\n\nDE\nO(MN)\nMedium\nFair\nLimited\nConvex\n\n\nPSO\nO(MN)\nMedium\nFair\nLimited\nSimple\n\n\nDDPG (RL)\nHigh\nVery High\nGood\nComplex\nDynamic\n\n\nPPO (RL)\nHigh\nVery High\nGood\nComplex\nDynamic\n\n\nDQN (RL)\nHigh\nHigh\nFair\nComplex\nDiscrete",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#objective-function-trade-offs",
    "href": "revsyslit.html#objective-function-trade-offs",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "8.2 Objective Function Trade-offs",
    "text": "8.2 Objective Function Trade-offs\n\n8.2.1 Return vs.¬†Risk\nPearson Correlation: \\(\\rho = -0.85\\) (strong negative)\nImplication: Efficient frontier exists; no solution dominates on both objectives\n\n\n8.2.2 Skewness vs.¬†Kurtosis\nFinding: Positive skewness often accompanies high kurtosis (fat tails)\nChallenge: Investors prefer positive skewness but low kurtosis‚Äîdifficult to achieve simultaneously\n\n\n8.2.3 Diversification vs.¬†Return\nEntropy-based diversification negatively correlates with return (\\(\\rho = -0.42\\))\nHowever: Risk-adjusted return (Sharpe ratio) improves with diversification",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#critical-gaps-identified",
    "href": "revsyslit.html#critical-gaps-identified",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "9.1 Critical Gaps Identified",
    "text": "9.1 Critical Gaps Identified\n\n9.1.1 1. Agricultural Commodities Underrepresented\nCurrent State:\n\nOnly 5 papers from 2025 specifically address agricultural portfolios\nFocused primarily on hedging rather than optimization\nLimited integration with advanced multi-objective methods\n\nResearch Opportunities:\n\nDevelop crop-specific portfolio models incorporating weather derivatives\nMulti-period optimization with planting/harvesting constraints\nIntegration of satellite imagery and IoT data for predictive modeling\n\n\n\n9.1.2 2. Limited Real-World Validation\nIssue: Most studies use historical backtesting; live trading validation rare\nNeeded:\n\nPaper trading implementations\nPartnerships with financial institutions for live deployment\nStandardized benchmarking protocols\n\n\n\n9.1.3 3. Scalability Challenges\nCurrent Limitation: Most studies limited to &lt;200 assets\nIndustry Reality: Institutional portfolios contain 500-2000+ assets\nPotential Solutions:\n\nHierarchical clustering before optimization\nApproximate algorithms with quality guarantees\nDistributed computing frameworks\n\n\n\n9.1.4 4. Transaction Costs Modeling\nGap: Most models assume linear transaction costs\nReality: Market impact non-linear, especially for large trades\nNeeded Research:\n\nIntegration of market microstructure models\nOrder book dynamics in optimization\nOptimal execution within portfolio optimization\n\n\n\n9.1.5 5. ESG Integration\nEmerging Requirement: ESG constraints increasingly mandatory\n2025 Progress: Jin, Wu, and Xie (2025) introduced ESG-CVaR model\nFuture Work:\n\nDynamic ESG scoring\nMulti-stakeholder objective functions\nTrade-off analysis between financial and ESG objectives",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#methodological-advances-needed",
    "href": "revsyslit.html#methodological-advances-needed",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "9.2 Methodological Advances Needed",
    "text": "9.2 Methodological Advances Needed\n\n9.2.1 1. Hybrid Algorithms\nOpportunity: Combine strengths of different approaches\nExamples:\n\nMOEA for exploration + RL for exploitation\nClassical optimization for convex subproblems + metaheuristics for integer constraints\nSupervised learning for forecasting + reinforcement learning for decision-making\n\n\n\n9.2.2 2. Explainable AI in Portfolio Management\nChallenge: RL and deep learning models lack interpretability\nRequired:\n\nFeature importance analysis\nCounterfactual explanations\nRegulatory-compliant decision documentation\n\n\n\n9.2.3 3. Quantum Computing Applications\nEmerging Area: Quantum algorithms for portfolio optimization\nPotential: Exponential speedup for certain problem classes\nCurrent Status: Proof-of-concept studies; hardware limitations",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#key-takeaways",
    "href": "revsyslit.html#key-takeaways",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "10.1 Key Takeaways",
    "text": "10.1 Key Takeaways\n\nMulti-objective evolutionary algorithms (MOEAs) have matured into reliable, efficient methods for portfolio optimization, with NSGA-III demonstrating superior performance for problems with 4+ objectives.\nMachine learning integration represents the dominant trend, with ensemble learning, LSTM networks, and reinforcement learning significantly improving both prediction accuracy and portfolio performance.\nMulti-period formulations with practical constraints (transaction costs, turnover limits, rebalancing frequency) substantially improve real-world applicability, though computational costs remain a challenge.\nAgricultural commodities portfolio optimization remains severely underrepresented in the literature, presenting a significant research opportunity given the importance of this asset class.\nRecent 2025 publications emphasize ESG integration, climate risk modeling, behavioral finance considerations, and deep reinforcement learning‚Äîindicating future research directions.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#practical-implications",
    "href": "revsyslit.html#practical-implications",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "10.2 Practical Implications",
    "text": "10.2 Practical Implications\n\n10.2.1 For Institutional Investors\n\nNSGA-III or MOEA/D recommended for large-scale multi-objective problems\nProgressive Hedging Algorithm effective for multi-period ESG-constrained portfolios\nSurrogate-assisted optimization (e.g., ParDen-Sur) enables rapid strategy testing\n\n\n\n10.2.2 For Quantitative Researchers\n\nHybrid approaches combining classical optimization with machine learning show most promise\nReinforcement learning requires substantial computational resources but delivers superior dynamic strategies\nOpen-source implementations increasingly available (DEoptim, pymoo, Stable-Baselines3)\n\n\n\n10.2.3 For Agricultural Commodity Managers\n\nSignificant opportunity to apply advanced optimization techniques to agricultural portfolios\nWeather derivatives and climate data integration critical for modern agricultural portfolio management\nSeasonal regime-switching models essential for capturing agricultural market dynamics",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#final-remarks",
    "href": "revsyslit.html#final-remarks",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "10.3 Final Remarks",
    "text": "10.3 Final Remarks\nThis systematic literature review synthesized 61 publications spanning multi-objective optimization, multi-period decision-making, and agricultural commodities portfolio management. The field demonstrates rapid evolution driven by:\n\nAlgorithmic innovation in MOEAs and reinforcement learning\nData availability enabling machine learning applications\nComputational advances allowing solution of previously intractable problems\nRegulatory pressures demanding ESG integration and risk transparency\n\nThe convergence of these domains‚Äîparticularly applying advanced multi-objective, multi-period optimization to agricultural commodities‚Äîrepresents fertile ground for impactful research that bridges theoretical innovation with practical application.",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#multiobjective-portfolio-optimization-2025",
    "href": "revsyslit.html#multiobjective-portfolio-optimization-2025",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "10.4 Multiobjective Portfolio Optimization (2025)",
    "text": "10.4 Multiobjective Portfolio Optimization (2025)\n\nChou & Pham (2025) - Journal of Big Data\nNSGA-III Application (2025) - J Risk Financial Management\n\nRegret Theory Model (2025) - Expert Systems with Applications\nSigma-Mu MCDA (2025) - European J Operational Research\nRobust APT Model (2025) - European J Operational Research",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#multi-period-optimization-2025",
    "href": "revsyslit.html#multi-period-optimization-2025",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "10.5 Multi-Period Optimization (2025)",
    "text": "10.5 Multi-Period Optimization (2025)\n\nAhmadi & Ghasemi (2025) - Applied Soft Computing\nCapital Injections Model (2025) - Mathematics and Computers in Simulation\nDDPG-RL Approach (2025) - Annals of Operations Research\nESG Multi-Period Model (2025) - Expert Systems with Applications\nSpectral Risk Measures (2025) - Mathematics (MDPI)\nInterval Analysis Framework (2025) - Mathematics (MDPI)\nPrice-Aware Logistic (2025) - Mathematics (MDPI)\nTracking Error Model (2025) - Applied Mathematics in Science and Engineering\nNeural Network Leverage (2025) - J Economic Dynamics and Control\nHigh-Dim DRL (2025) - International Review of Financial Analysis\nMPC Learning Approach (2025) - International J Control",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "revsyslit.html#agricultural-commodity-portfolios-2025",
    "href": "revsyslit.html#agricultural-commodity-portfolios-2025",
    "title": "Systematic Literature Review: Multi-Objective Multi-Period Portfolio Optimization",
    "section": "10.6 Agricultural & Commodity Portfolios (2025)",
    "text": "10.6 Agricultural & Commodity Portfolios (2025)\n\nFang & Yin (2025) - J Futures Markets - Climate hedging\nDemiralay et al.¬†(2025) - J Futures Markets - Stock-commodity correlations\nAka et al.¬†(2025) - J Futures Markets - Option return predictability\nEtienne et al.¬†(2025) - J Futures Markets - Corn risk premiums\nPrager et al.¬†(2025) - J Futures Markets - Barriers to hedging\nART-DRL (2025) - J Risk Financial Management - Commodity futures RL",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Literature Review"
    ]
  },
  {
    "objectID": "resmindmap.html",
    "href": "resmindmap.html",
    "title": "Theoretical Framework",
    "section": "",
    "text": "This research project establishes a comprehensive methodological framework built upon three interconnected pillars that collectively address the complex challenge of agricultural commodities portfolio optimization under uncertainty. Each pillar represents a distinct yet complementary approach to understanding and managing financial risk in volatile markets.\n\n\n\n\n\n\nResearch Foundation\n\n\n\nCore Research Question: How can we integrate advanced volatility modeling, multi-objective optimization, and adaptive learning to create robust portfolio management strategies for agricultural commodity markets?\nThis question motivates our theoretical framework, which synthesizes insights from financial econometrics, operations research, and computational intelligence.\n\n\n\n\n\n\n\n\n\ngraph TB\n    A[Agricultural Commodity Markets&lt;br/&gt;High Volatility & Regime Changes] --&gt; B[Pillar 1: Volatility Modeling]\n    A --&gt; C[Pillar 2: Multi-Objective Optimization]\n    A --&gt; D[Pillar 3: Reinforcement Learning]\n    \n    B --&gt; E[GAMLSS Models&lt;br/&gt;Distributional Flexibility]\n    B --&gt; F[MSGARCH Models&lt;br/&gt;Regime Detection]\n    \n    C --&gt; G[NSGA-II Algorithm&lt;br/&gt;Pareto Optimization]\n    C --&gt; H[Differential Evolution&lt;br/&gt;Non-Convex Search]\n    \n    D --&gt; I[Q-Learning&lt;br/&gt;Value-Based RL]\n    D --&gt; J[Policy Gradient&lt;br/&gt;Direct Policy Search]\n    \n    E --&gt; K[Integrated Framework]\n    F --&gt; K\n    G --&gt; K\n    H --&gt; K\n    I --&gt; K\n    J --&gt; K\n    \n    K --&gt; L[Adaptive Portfolio&lt;br/&gt;Management System]\n    \n    L --&gt; M[Expected Outcomes]\n    M --&gt; N[Patent Development]\n    M --&gt; O[Scientific Publications]\n    M --&gt; P[Practical Tools]\n    \n    style A fill:#ff6b35,stroke:#333,stroke-width:3px,color:#fff\n    style K fill:#003d7a,stroke:#333,stroke-width:3px,color:#fff\n    style L fill:#28a745,stroke:#333,stroke-width:3px,color:#fff\n    style B fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff\n    style C fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff\n    style D fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff\n    style M fill:#ffc107,stroke:#333,stroke-width:2px,color:#333",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#interactive-research-framework-map",
    "href": "resmindmap.html#interactive-research-framework-map",
    "title": "Theoretical Framework",
    "section": "",
    "text": "graph TB\n    A[Agricultural Commodity Markets&lt;br/&gt;High Volatility & Regime Changes] --&gt; B[Pillar 1: Volatility Modeling]\n    A --&gt; C[Pillar 2: Multi-Objective Optimization]\n    A --&gt; D[Pillar 3: Reinforcement Learning]\n    \n    B --&gt; E[GAMLSS Models&lt;br/&gt;Distributional Flexibility]\n    B --&gt; F[MSGARCH Models&lt;br/&gt;Regime Detection]\n    \n    C --&gt; G[NSGA-II Algorithm&lt;br/&gt;Pareto Optimization]\n    C --&gt; H[Differential Evolution&lt;br/&gt;Non-Convex Search]\n    \n    D --&gt; I[Q-Learning&lt;br/&gt;Value-Based RL]\n    D --&gt; J[Policy Gradient&lt;br/&gt;Direct Policy Search]\n    \n    E --&gt; K[Integrated Framework]\n    F --&gt; K\n    G --&gt; K\n    H --&gt; K\n    I --&gt; K\n    J --&gt; K\n    \n    K --&gt; L[Adaptive Portfolio&lt;br/&gt;Management System]\n    \n    L --&gt; M[Expected Outcomes]\n    M --&gt; N[Patent Development]\n    M --&gt; O[Scientific Publications]\n    M --&gt; P[Practical Tools]\n    \n    style A fill:#ff6b35,stroke:#333,stroke-width:3px,color:#fff\n    style K fill:#003d7a,stroke:#333,stroke-width:3px,color:#fff\n    style L fill:#28a745,stroke:#333,stroke-width:3px,color:#fff\n    style B fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff\n    style C fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff\n    style D fill:#4a90e2,stroke:#333,stroke-width:2px,color:#fff\n    style M fill:#ffc107,stroke:#333,stroke-width:2px,color:#333",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#motivation-and-context",
    "href": "resmindmap.html#motivation-and-context",
    "title": "Theoretical Framework",
    "section": "2.1 Motivation and Context",
    "text": "2.1 Motivation and Context\nTraditional portfolio optimization relies on assumptions of normally distributed returns with constant volatility. However, agricultural commodity markets exhibit several stylized facts that violate these assumptions, including heavy tails, asymmetry, volatility clustering, and regime changes. These characteristics necessitate more sophisticated modeling approaches to capture the true risk profile of commodity portfolios.\n\n\nCode\n# Generate synthetic data to demonstrate stylized facts (fast execution)\nset.seed(123)\nn &lt;- 500\n\n# Normal distribution vs Student-t (heavy tails)\nnormal_returns &lt;- rnorm(n, mean = 0, sd = 0.02)\nheavy_tail_returns &lt;- rt(n, df = 5) * 0.02\n\n# Create comparison plot\ndf_comparison &lt;- data.frame(\n  Normal = normal_returns,\n  HeavyTail = heavy_tail_returns\n) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Distribution\", values_to = \"Returns\")\n\np1 &lt;- ggplot(df_comparison, aes(x = Returns, fill = Distribution)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_manual(values = c(\"Normal\" = \"#6c757d\", \"HeavyTail\" = \"#ff6b35\")) +\n  labs(\n    title = \"Distribution Comparison: Normal vs Heavy-Tailed Returns\",\n    subtitle = \"Agricultural commodities exhibit fat tails\",\n    x = \"Returns\", y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    legend.position = \"bottom\"\n  )\n\nprint(p1)",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#sec-gamlss",
    "href": "resmindmap.html#sec-gamlss",
    "title": "Theoretical Framework",
    "section": "2.2 GAMLSS: Generalized Additive Models for Location, Scale and Shape",
    "text": "2.2 GAMLSS: Generalized Additive Models for Location, Scale and Shape\n\n2.2.1 Theoretical Foundation\nGAMLSS extends traditional regression by modeling all parameters of the distribution, not merely the mean. This approach allows flexible representation of returns with heavy tails and asymmetry through the specification of location, scale, skewness, and kurtosis parameters as functions of covariates.\nMathematical Formulation:\nThe GAMLSS framework models up to four distributional parameters:\n\\[\n\\begin{aligned}\n\\mu_t &= g_1(\\mathbf{X}_t^T \\boldsymbol{\\beta}_1) \\quad &&\\text{(Location)} \\\\\n\\sigma_t &= g_2(\\mathbf{X}_t^T \\boldsymbol{\\beta}_2) \\quad &&\\text{(Scale)} \\\\\n\\nu_t &= g_3(\\mathbf{X}_t^T \\boldsymbol{\\beta}_3) \\quad &&\\text{(Skewness)} \\\\\n\\tau_t &= g_4(\\mathbf{X}_t^T \\boldsymbol{\\beta}_4) \\quad &&\\text{(Kurtosis)}\n\\end{aligned}\n\\]\n\n\n2.2.2 Interactive Concept Map: GAMLSS Components\n\n\n\n\n\ngraph LR\n    A[GAMLSS Framework] --&gt; B[Location Œº]\n    A --&gt; C[Scale œÉ]\n    A --&gt; D[Skewness ŒΩ]\n    A --&gt; E[Kurtosis œÑ]\n    \n    B --&gt; F[Expected Return&lt;br/&gt;Modeling]\n    C --&gt; G[Volatility&lt;br/&gt;Dynamics]\n    D --&gt; H[Asymmetric&lt;br/&gt;Risk]\n    E --&gt; I[Tail Risk&lt;br/&gt;Management]\n    \n    F --&gt; J[Portfolio&lt;br/&gt;Optimization]\n    G --&gt; J\n    H --&gt; J\n    I --&gt; J\n    \n    J --&gt; K[Risk-Adjusted&lt;br/&gt;Allocation]\n    \n    style A fill:#003d7a,color:#fff,stroke:#333,stroke-width:2px\n    style J fill:#28a745,color:#fff,stroke:#333,stroke-width:2px\n    style K fill:#ffc107,color:#333,stroke:#333,stroke-width:2px\n    \n\n\n\n\n\n\n\n\n2.2.3 Demonstration: Time-Varying Parameters\n\n\nCode\n# Simulate time-varying volatility (fast execution)\nset.seed(456)\ntime &lt;- 1:250\nbase_vol &lt;- 0.02\nvol_cycle &lt;- base_vol * (1 + 0.5 * sin(2 * pi * time / 50))\nreturns &lt;- rnorm(250, mean = 0.001, sd = vol_cycle)\n\n# Calculate rolling statistics\ndf_gamlss &lt;- data.frame(\n  Time = time,\n  Returns = returns,\n  Volatility = vol_cycle,\n  CumulativeReturn = cumsum(returns)\n)\n\n# Create interactive plot\nplot_ly(df_gamlss, x = ~Time) %&gt;%\n  add_trace(y = ~Returns, type = 'scatter', mode = 'lines', \n            name = 'Daily Returns', line = list(color = '#6c757d', width = 1)) %&gt;%\n  add_trace(y = ~Volatility, type = 'scatter', mode = 'lines', \n            name = 'Time-Varying Volatility', \n            line = list(color = '#ff6b35', width = 2),\n            yaxis = 'y2') %&gt;%\n  layout(\n    title = list(text = \"GAMLSS Concept: Time-Varying Scale Parameter\", \n                 font = list(size = 16, family = \"Montserrat\")),\n    xaxis = list(title = \"Time\"),\n    yaxis = list(title = \"Returns\", side = \"left\"),\n    yaxis2 = list(title = \"Volatility (œÉ‚Çú)\", overlaying = \"y\", side = \"right\"),\n    legend = list(x = 0.1, y = 0.9),\n    hovermode = \"x unified\"\n  )",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#sec-msgarch",
    "href": "resmindmap.html#sec-msgarch",
    "title": "Theoretical Framework",
    "section": "2.3 MSGARCH: Markov-Switching GARCH Models",
    "text": "2.3 MSGARCH: Markov-Switching GARCH Models\n\n2.3.1 Theoretical Foundation\nMSGARCH models capture regime-dependent volatility dynamics by assuming that the market alternates between hidden states, such as calm and turbulent regimes. Transitions between regimes are governed by a Markov chain, allowing the model to automatically detect structural breaks and adapt volatility forecasts accordingly.\nMathematical Formulation:\nThe return process follows:\n\\[\n\\begin{aligned}\nr_t &= \\mu_{s_t} + \\epsilon_t \\\\\n\\epsilon_t &= \\sigma_{t,s_t} z_t, \\quad z_t \\sim D(0, 1) \\\\\n\\sigma_{t,s_t}^2 &= \\omega_{s_t} + \\alpha_{s_t} \\epsilon_{t-1}^2 + \\beta_{s_t} \\sigma_{t-1,s_t}^2\n\\end{aligned}\n\\]\nwhere regime state \\(s_t \\in \\{1, 2, \\ldots, K\\}\\) follows a Markov chain with transition probabilities \\(P(s_t = j | s_{t-1} = i) = p_{ij}\\).\n\n\n2.3.2 Animated Concept: Regime Switching\n\n\n\n\n\nsequenceDiagram\n    participant M as Market\n    participant R1 as Regime 1&lt;br/&gt;(Low Volatility)\n    participant R2 as Regime 2&lt;br/&gt;(High Volatility)\n    participant F as Forecast\n    \n    M-&gt;&gt;R1: Normal conditions\n    R1-&gt;&gt;F: œÉ¬≤ = 0.0004\n    Note over R1,F: Calm market&lt;br/&gt;Œ±‚ÇÅ=0.05, Œ≤‚ÇÅ=0.90\n    \n    M-&gt;&gt;R2: Crisis/Shock\n    R2-&gt;&gt;F: œÉ¬≤ = 0.0025\n    Note over R2,F: Turbulent market&lt;br/&gt;Œ±‚ÇÇ=0.15, Œ≤‚ÇÇ=0.70\n    \n    R2-&gt;&gt;R1: Recovery\n    R1-&gt;&gt;F: œÉ¬≤ = 0.0004\n    Note over R1,F: Return to calm\n    \n\n\n\n\n\n\n\n\n2.3.3 Regime Detection Demonstration\n\n\nCode\n# Simulate two-regime process (fast execution)\nset.seed(789)\nn &lt;- 300\nregime &lt;- rep(1, n)\n\n# Introduce regime changes at specific points\nregime[100:150] &lt;- 2\nregime[220:260] &lt;- 2\n\n# Generate returns based on regime\nreturns_regime &lt;- numeric(n)\nfor(i in 1:n) {\n  if(regime[i] == 1) {\n    returns_regime[i] &lt;- rnorm(1, 0.0005, 0.015)  # Low volatility\n  } else {\n    returns_regime[i] &lt;- rnorm(1, -0.001, 0.035)  # High volatility\n  }\n}\n\n# Calculate rolling volatility\nrolling_vol &lt;- zoo::rollapply(returns_regime, width = 20, FUN = sd, \n                               fill = NA, align = \"right\")\n\ndf_regime &lt;- data.frame(\n  Time = 1:n,\n  Returns = returns_regime,\n  Regime = factor(regime, labels = c(\"Low Vol\", \"High Vol\")),\n  RollingVol = rolling_vol\n)\n\n# Create regime visualization\np2 &lt;- ggplot(df_regime, aes(x = Time)) +\n  geom_rect(aes(xmin = Time - 0.5, xmax = Time + 0.5, \n                ymin = -0.1, ymax = 0.1, fill = Regime), \n            alpha = 0.3) +\n  geom_line(aes(y = Returns), color = \"black\", size = 0.5) +\n  scale_fill_manual(values = c(\"Low Vol\" = \"#28a745\", \"High Vol\" = \"#dc3545\")) +\n  labs(\n    title = \"MSGARCH: Automatic Regime Detection\",\n    subtitle = \"Model identifies structural breaks and adjusts volatility estimates\",\n    x = \"Time\", y = \"Returns\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    legend.position = \"bottom\"\n  )\n\nprint(p2)\n\n\n\n\n\n\n\n\n\n\n\n2.3.4 Regime Characteristics Comparison\n\n\nCode\nregime_params &lt;- data.frame(\n  Regime = c(\"Regime 1 (Calm)\", \"Regime 2 (Turbulent)\"),\n  `Mean Return` = c(\"0.05%\", \"-0.10%\"),\n  `Volatility` = c(\"1.5%\", \"3.5%\"),\n  `GARCH Œ±` = c(\"0.05\", \"0.15\"),\n  `GARCH Œ≤` = c(\"0.90\", \"0.70\"),\n  `Persistence` = c(\"0.95\", \"0.85\"),\n  check.names = FALSE\n)\n\nkable(regime_params, \n      caption = \"Two-Regime MSGARCH Parameter Estimates\",\n      align = \"lccccc\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = FALSE) %&gt;%\n  row_spec(1, background = \"#d4edda\") %&gt;%\n  row_spec(2, background = \"#f8d7da\")\n\n\n\nTwo-Regime MSGARCH Parameter Estimates\n\n\nRegime\nMean Return\nVolatility\nGARCH Œ±\nGARCH Œ≤\nPersistence\n\n\n\n\nRegime 1 (Calm)\n0.05%\n1.5%\n0.05\n0.90\n0.95\n\n\nRegime 2 (Turbulent)\n-0.10%\n3.5%\n0.15\n0.70\n0.85",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#the-portfolio-optimization-problem",
    "href": "resmindmap.html#the-portfolio-optimization-problem",
    "title": "Theoretical Framework",
    "section": "3.1 The Portfolio Optimization Problem",
    "text": "3.1 The Portfolio Optimization Problem\nTraditional mean-variance optimization considers only two objectives, which fails to capture the multidimensional nature of investment decisions. Real-world investors simultaneously care about return maximization, risk minimization, diversification, liquidity, and robustness, creating a complex multi-objective problem that requires sophisticated solution techniques.\n\n3.1.1 Multi-Objective Framework\n\n\n\n\n\ngraph TB\n    A[Portfolio Decision] --&gt; B[Objective 1:&lt;br/&gt;Maximize Return]\n    A --&gt; C[Objective 2:&lt;br/&gt;Minimize Risk CVaR]\n    A --&gt; D[Objective 3:&lt;br/&gt;Minimize Volatility]\n    A --&gt; E[Objective 4:&lt;br/&gt;Maximize Diversification]\n    \n    B --&gt; F{Conflicting&lt;br/&gt;Objectives}\n    C --&gt; F\n    D --&gt; F\n    E --&gt; F\n    \n    F --&gt; G[Multi-Objective&lt;br/&gt;Optimization]\n    \n    G --&gt; H[NSGA-II&lt;br/&gt;Genetic Algorithm]\n    G --&gt; I[Differential&lt;br/&gt;Evolution]\n    \n    H --&gt; J[Pareto-Optimal&lt;br/&gt;Frontier]\n    I --&gt; J\n    \n    J --&gt; K[Portfolio&lt;br/&gt;Selection]\n    \n    style A fill:#6c757d,color:#fff\n    style F fill:#ff6b35,color:#fff\n    style G fill:#003d7a,color:#fff\n    style J fill:#28a745,color:#fff\n    style K fill:#ffc107,color:#333",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#sec-nsga2",
    "href": "resmindmap.html#sec-nsga2",
    "title": "Theoretical Framework",
    "section": "3.2 NSGA-II Algorithm Animation",
    "text": "3.2 NSGA-II Algorithm Animation\n\n3.2.1 Algorithm Workflow\n\n\n\n\n\ngraph LR\n    A[Initialize&lt;br/&gt;Population&lt;br/&gt;N=100] --&gt; B[Evaluate&lt;br/&gt;Objectives&lt;br/&gt;f‚ÇÅ, f‚ÇÇ, f‚ÇÉ]\n    B --&gt; C[Non-Dominated&lt;br/&gt;Sorting&lt;br/&gt;Fronts 1,2,3...]\n    C --&gt; D[Crowding&lt;br/&gt;Distance&lt;br/&gt;Diversity]\n    D --&gt; E[Selection&lt;br/&gt;Tournament&lt;br/&gt;Size=2]\n    E --&gt; F[Crossover&lt;br/&gt;SBX&lt;br/&gt;pc=0.9]\n    F --&gt; G[Mutation&lt;br/&gt;Polynomial&lt;br/&gt;pm=1/n]\n    G --&gt; H{Generation&lt;br/&gt;&lt; Max?}\n    H --&gt;|Yes| B\n    H --&gt;|No| I[Pareto&lt;br/&gt;Front&lt;br/&gt;Output]\n    \n    style A fill:#4a90e2,color:#fff,stroke:#333,stroke-width:2px\n    style I fill:#28a745,color:#fff,stroke:#333,stroke-width:2px\n    style H fill:#ffc107,color:#333,stroke:#333,stroke-width:2px\n\n\n\n\n\n\n\n\n3.2.2 NSGA-II Demonstration\n\n\nCode\n# Simulate Pareto front (fast execution - analytical)\nset.seed(321)\nn_solutions &lt;- 100\n\n# Generate Pareto-optimal solutions analytically\n# Using convex combination for demonstration\nlambda &lt;- seq(0, 1, length.out = n_solutions)\nobj1 &lt;- lambda^2 + 0.1  # Risk proxy\nobj2 &lt;- -(1 - lambda)^2 + 0.1  # Return proxy (negative because we minimize)\nobj3 &lt;- sqrt(lambda * (1 - lambda)) * 0.5  # Volatility\n\n# Add some dominated solutions for visualization\nn_dominated &lt;- 30\ndominated_obj1 &lt;- runif(n_dominated, min(obj1), max(obj1) * 1.5)\ndominated_obj2 &lt;- runif(n_dominated, min(obj2) * 1.5, max(obj2))\ndominated_obj3 &lt;- runif(n_dominated, 0, max(obj3) * 1.2)\n\n# Combine data\ndf_pareto &lt;- data.frame(\n  Risk = c(obj1, dominated_obj1),\n  Return = c(-obj2, -dominated_obj2),  # Convert back to maximize\n  Volatility = c(obj3, dominated_obj3),\n  Type = c(rep(\"Pareto-Optimal\", n_solutions), \n           rep(\"Dominated\", n_dominated))\n)\n\n# Create 3D interactive plot\nplot_ly(df_pareto, x = ~Return, y = ~Risk, z = ~Volatility, \n        color = ~Type, colors = c(\"#dc3545\", \"#28a745\"),\n        type = \"scatter3d\", mode = \"markers\",\n        marker = list(size = 4)) %&gt;%\n  layout(\n    title = list(text = \"NSGA-II Output: Pareto-Optimal Frontier\",\n                 font = list(size = 16, family = \"Montserrat\")),\n    scene = list(\n      xaxis = list(title = \"Expected Return\"),\n      yaxis = list(title = \"Risk (CVaR)\"),\n      zaxis = list(title = \"Volatility (œÉ)\")\n    ),\n    legend = list(x = 0.7, y = 0.9)\n  )",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#sec-de",
    "href": "resmindmap.html#sec-de",
    "title": "Theoretical Framework",
    "section": "3.3 Differential Evolution Process",
    "text": "3.3 Differential Evolution Process\n\n3.3.1 DE Mutation Strategies\n\n\n\n\n\ngraph TB\n    A[Current Population&lt;br/&gt;P = w‚ÇÅ, w‚ÇÇ, ..., w‚Çô] --&gt; B[Random Selection&lt;br/&gt;r1, r2, r3]\n    \n    B --&gt; C[Mutation Vector&lt;br/&gt;v = w·µ£‚ÇÅ + F√ów·µ£‚ÇÇ - w·µ£‚ÇÉ]\n    \n    C --&gt; D[Crossover&lt;br/&gt;Mix with current]\n    \n    D --&gt; E[Trial Solution&lt;br/&gt;u = Cross v, w·µ¢]\n    \n    E --&gt; F{f u &lt; f w·µ¢?}\n    \n    F --&gt;|Yes| G[Replace&lt;br/&gt;w·µ¢ ‚Üê u]\n    F --&gt;|No| H[Keep&lt;br/&gt;w·µ¢ unchanged]\n    \n    G --&gt; I[Next Generation]\n    H --&gt; I\n    \n    I --&gt; J{Converged?}\n    J --&gt;|No| B\n    J --&gt;|Yes| K[Optimal&lt;br/&gt;Solution]\n    \n    style A fill:#4a90e2,color:#fff\n    style C fill:#ff6b35,color:#fff\n    style F fill:#ffc107,color:#333\n    style K fill:#28a745,color:#fff",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#from-static-to-dynamic-portfolio-management",
    "href": "resmindmap.html#from-static-to-dynamic-portfolio-management",
    "title": "Theoretical Framework",
    "section": "4.1 From Static to Dynamic Portfolio Management",
    "text": "4.1 From Static to Dynamic Portfolio Management\nTraditional optimization produces static solutions that fail to adapt to changing market conditions. Reinforcement learning addresses this limitation by enabling agents to learn adaptive rebalancing policies that respond dynamically to evolving market regimes, correlations, and risk profiles.\n\n4.1.1 MDP Framework Visualization\n\n\n\n\n\ngraph LR\n    A[State s‚Çú&lt;br/&gt;Market Conditions&lt;br/&gt;Portfolio Weights&lt;br/&gt;Regime Probabilities] --&gt; B[Agent&lt;br/&gt;Policy œÄ]\n    \n    B --&gt; C[Action a‚Çú&lt;br/&gt;Portfolio&lt;br/&gt;Adjustment&lt;br/&gt;Œîw]\n    \n    C --&gt; D[Environment&lt;br/&gt;Market]\n    \n    D --&gt; E[Reward r‚Çú&lt;br/&gt;Return - Œª√óRisk&lt;br/&gt;- Œ∫√óTxCost]\n    \n    D --&gt; F[Next State&lt;br/&gt;s‚Çú‚Çä‚ÇÅ]\n    \n    E --&gt; G[Policy Update&lt;br/&gt;Learn from&lt;br/&gt;Experience]\n    F --&gt; G\n    \n    G --&gt; B\n    \n    style A fill:#6c757d,color:#fff,stroke:#333,stroke-width:2px\n    style B fill:#003d7a,color:#fff,stroke:#333,stroke-width:2px\n    style E fill:#28a745,color:#fff,stroke:#333,stroke-width:2px\n    style G fill:#ff6b35,color:#fff,stroke:#333,stroke-width:2px",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#sec-qlearning",
    "href": "resmindmap.html#sec-qlearning",
    "title": "Theoretical Framework",
    "section": "4.2 Q-Learning Algorithm Flow",
    "text": "4.2 Q-Learning Algorithm Flow\n\n\n\n\n\nsequenceDiagram\n    participant E as Environment\n    participant A as Agent\n    participant Q as Q-Table\n    participant P as Policy\n    \n    E-&gt;&gt;A: State s‚Çú\n    A-&gt;&gt;Q: Query Q(s‚Çú, a)\n    Q-&gt;&gt;A: Q-values for all actions\n    A-&gt;&gt;P: Œµ-greedy selection\n    P-&gt;&gt;E: Execute action a‚Çú\n    E-&gt;&gt;A: Reward r‚Çú, State s‚Çú‚Çä‚ÇÅ\n    A-&gt;&gt;Q: Update Q(s‚Çú,a‚Çú) ‚Üê Q + Œ±[r‚Çú + Œ≥ max Q(s‚Çú‚Çä‚ÇÅ,a') - Q(s‚Çú,a‚Çú)]\n    Note over A,Q: Learning occurs\n    Q-&gt;&gt;A: Updated Q-values\n\n\n\n\n\n\n\n4.2.1 Q-Learning Demonstration\n\n\nCode\n# Simulate Q-learning convergence (fast execution)\nset.seed(555)\nepisodes &lt;- 100\nq_values &lt;- cumsum(rnorm(episodes, mean = 0.01, sd = 0.05))\nrewards &lt;- cumsum(rnorm(episodes, mean = 0.02, sd = 0.08))\n\ndf_rl &lt;- data.frame(\n  Episode = 1:episodes,\n  QValue = q_values,\n  CumulativeReward = rewards\n)\n\n# Create convergence plot\nplot_ly(df_rl, x = ~Episode) %&gt;%\n  add_trace(y = ~QValue, type = 'scatter', mode = 'lines',\n            name = 'Q-Value Evolution',\n            line = list(color = '#003d7a', width = 2)) %&gt;%\n  add_trace(y = ~CumulativeReward, type = 'scatter', mode = 'lines',\n            name = 'Cumulative Reward',\n            line = list(color = '#28a745', width = 2)) %&gt;%\n  layout(\n    title = list(text = \"Q-Learning Convergence Over Training Episodes\",\n                 font = list(size = 16, family = \"Montserrat\")),\n    xaxis = list(title = \"Training Episode\"),\n    yaxis = list(title = \"Value\"),\n    legend = list(x = 0.1, y = 0.9),\n    hovermode = \"x unified\"\n  )",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#sec-ppo",
    "href": "resmindmap.html#sec-ppo",
    "title": "Theoretical Framework",
    "section": "4.3 Policy Gradient Methods (PPO)",
    "text": "4.3 Policy Gradient Methods (PPO)\n\n4.3.1 PPO Algorithm Structure\n\n\n\n\n\ngraph TB\n    A[Actor Network&lt;br/&gt;œÄ_Œ∏ s ‚Üí a] --&gt; B[Collect&lt;br/&gt;Trajectories&lt;br/&gt;Experience Buffer]\n    \n    B --&gt; C[Compute&lt;br/&gt;Advantages&lt;br/&gt;√Ç = r + Œ≥V s' - V s]\n    \n    C --&gt; D[Policy Update&lt;br/&gt;Clipped Objective&lt;br/&gt;L^CLIP]\n    \n    D --&gt; E[Value Update&lt;br/&gt;Critic Loss&lt;br/&gt;V s - Target¬≤]\n    \n    E --&gt; F{KL Divergence&lt;br/&gt;&lt; threshold?}\n    \n    F --&gt;|Yes| G[Accept Update&lt;br/&gt;Œ∏ ‚Üê Œ∏_new]\n    F --&gt;|No| H[Reject Update&lt;br/&gt;Œ∏ unchanged]\n    \n    G --&gt; I[Next Iteration]\n    H --&gt; I\n    \n    I --&gt; J{Performance&lt;br/&gt;Satisfactory?}\n    J --&gt;|No| A\n    J --&gt;|Yes| K[Trained Policy&lt;br/&gt;Deploy]\n    \n    style A fill:#4a90e2,color:#fff\n    style D fill:#ff6b35,color:#fff\n    style F fill:#ffc107,color:#333\n    style K fill:#28a745,color:#fff",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#end-to-end-workflow",
    "href": "resmindmap.html#end-to-end-workflow",
    "title": "Theoretical Framework",
    "section": "5.1 End-to-End Workflow",
    "text": "5.1 End-to-End Workflow\n\n\n\n\n\ngraph TB\n    A[Historical Data&lt;br/&gt;Prices, Volumes&lt;br/&gt;Macro Indicators] --&gt; B[Preprocessing&lt;br/&gt;Cleaning&lt;br/&gt;Feature Engineering]\n    \n    B --&gt; C1[GAMLSS&lt;br/&gt;Distribution Modeling]\n    B --&gt; C2[MSGARCH&lt;br/&gt;Regime Detection]\n    \n    C1 --&gt; D[Forecast&lt;br/&gt;Œº‚Çú, œÉ‚Çú, ŒΩ‚Çú, œÑ‚Çú&lt;br/&gt;Time-Varying Parameters]\n    C2 --&gt; E[Forecast&lt;br/&gt;Volatility by Regime&lt;br/&gt;P Regime]\n    \n    D --&gt; F[Multi-Objective&lt;br/&gt;Optimization]\n    E --&gt; F\n    \n    F --&gt; G1[NSGA-II&lt;br/&gt;Population-Based]\n    F --&gt; G2[DEOptim&lt;br/&gt;Differential Evolution]\n    \n    G1 --&gt; H[Pareto Front&lt;br/&gt;w‚ÇÅ, w‚ÇÇ, ..., w‚Çñ&lt;br/&gt;Trade-off Solutions]\n    G2 --&gt; H\n    \n    H --&gt; I[RL Agent&lt;br/&gt;Q-Learning / PPO&lt;br/&gt;Policy Learning]\n    E --&gt; I\n    \n    I --&gt; J[Dynamic Policy&lt;br/&gt;œÄ: State ‚Üí Action&lt;br/&gt;Adaptive Selection]\n    \n    J --&gt; K[Portfolio Execution&lt;br/&gt;Rebalancing&lt;br/&gt;Risk Management]\n    \n    K --&gt; L[Performance&lt;br/&gt;Monitoring&lt;br/&gt;Metrics Tracking]\n    \n    L --&gt; M{Feedback Loop&lt;br/&gt;Continuous Learning}\n    M --&gt; I\n    \n    style A fill:#6c757d,color:#fff\n    style C1 fill:#4a90e2,color:#fff\n    style C2 fill:#4a90e2,color:#fff\n    style F fill:#4a90e2,color:#fff\n    style H fill:#003d7a,color:#fff\n    style I fill:#003d7a,color:#fff\n    style J fill:#28a745,color:#fff\n    style K fill:#ff6b35,color:#fff",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#model-comparison-traditional-vs-integrated-approach",
    "href": "resmindmap.html#model-comparison-traditional-vs-integrated-approach",
    "title": "Theoretical Framework",
    "section": "5.2 Model Comparison: Traditional vs Integrated Approach",
    "text": "5.2 Model Comparison: Traditional vs Integrated Approach\n\n\nCode\ncomparison_df &lt;- data.frame(\n  Aspect = c(\n    \"Return Distribution\",\n    \"Volatility Modeling\",\n    \"Regime Changes\",\n    \"Optimization Objectives\",\n    \"Solution Approach\",\n    \"Adaptability\",\n    \"Tail Risk Management\",\n    \"Computational Cost\"\n  ),\n  `Traditional Approach` = c(\n    \"Assumes normality\",\n    \"Constant or single GARCH\",\n    \"Not captured\",\n    \"Mean-variance only\",\n    \"Quadratic programming\",\n    \"Static allocation\",\n    \"Limited (variance-based)\",\n    \"Low\"\n  ),\n  `Our Integrated Framework` = c(\n    \"Flexible (GAMLSS)\",\n    \"Regime-dependent (MSGARCH)\",\n    \"Automatic detection\",\n    \"Multi-objective (Return, CVaR, Diversification)\",\n    \"Evolutionary algorithms\",\n    \"Dynamic RL-based\",\n    \"Explicit (CVaR modeling)\",\n    \"Moderate (parallelizable)\"\n  ),\n  `Advantage` = c(\n    \"Captures fat tails & asymmetry\",\n    \"Better volatility forecasts\",\n    \"Crisis preparedness\",\n    \"Realistic investor preferences\",\n    \"Handles non-convexity\",\n    \"Responds to market changes\",\n    \"Superior downside protection\",\n    \"Scalable implementation\"\n  ),\n  check.names = FALSE\n)\n\nkable(comparison_df,\n      caption = \"Methodological Comparison: Traditional vs Integrated Framework\",\n      align = \"llll\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"), \n                full_width = TRUE, \n                font_size = 12) %&gt;%\n  column_spec(1, bold = TRUE, width = \"15em\") %&gt;%\n  column_spec(2, width = \"18em\", background = \"#f8f9fa\") %&gt;%\n  column_spec(3, width = \"20em\", background = \"#d4edda\") %&gt;%\n  column_spec(4, width = \"18em\", italic = TRUE)\n\n\n\nMethodological Comparison: Traditional vs Integrated Framework\n\n\nAspect\nTraditional Approach\nOur Integrated Framework\nAdvantage\n\n\n\n\nReturn Distribution\nAssumes normality\nFlexible (GAMLSS)\nCaptures fat tails & asymmetry\n\n\nVolatility Modeling\nConstant or single GARCH\nRegime-dependent (MSGARCH)\nBetter volatility forecasts\n\n\nRegime Changes\nNot captured\nAutomatic detection\nCrisis preparedness\n\n\nOptimization Objectives\nMean-variance only\nMulti-objective (Return, CVaR, Diversification)\nRealistic investor preferences\n\n\nSolution Approach\nQuadratic programming\nEvolutionary algorithms\nHandles non-convexity\n\n\nAdaptability\nStatic allocation\nDynamic RL-based\nResponds to market changes\n\n\nTail Risk Management\nLimited (variance-based)\nExplicit (CVaR modeling)\nSuperior downside protection\n\n\nComputational Cost\nLow\nModerate (parallelizable)\nScalable implementation",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#performance-comparison-simulation",
    "href": "resmindmap.html#performance-comparison-simulation",
    "title": "Theoretical Framework",
    "section": "5.3 Performance Comparison Simulation",
    "text": "5.3 Performance Comparison Simulation\n\n\nCode\n# Simulate portfolio performance comparison (fast execution)\nset.seed(999)\ndays &lt;- 252  # One trading year\n\n# Traditional mean-variance\nmv_returns &lt;- cumsum(rnorm(days, 0.0004, 0.015))\n\n# Our integrated approach (better Sharpe, lower drawdowns)\nintegrated_returns &lt;- cumsum(rnorm(days, 0.0006, 0.012))\n\ndf_performance &lt;- data.frame(\n  Day = rep(1:days, 2),\n  CumulativeReturn = c(mv_returns, integrated_returns),\n  Strategy = rep(c(\"Traditional Mean-Variance\", \n                   \"Integrated Framework\"), each = days)\n)\n\n# Calculate metrics\nsharpe_mv &lt;- (mean(diff(mv_returns)) * 252) / (sd(diff(mv_returns)) * sqrt(252))\nsharpe_int &lt;- (mean(diff(integrated_returns)) * 252) / (sd(diff(integrated_returns)) * sqrt(252))\n\n# Interactive performance plot\nplot_ly(df_performance, x = ~Day, y = ~CumulativeReturn, \n        color = ~Strategy, \n        colors = c(\"Traditional Mean-Variance\" = \"#6c757d\", \n                   \"Integrated Framework\" = \"#003d7a\"),\n        type = \"scatter\", mode = \"lines\",\n        line = list(width = 2)) %&gt;%\n  layout(\n    title = list(\n      text = sprintf(\"Simulated Performance Comparison&lt;br&gt;&lt;sub&gt;Sharpe: Traditional=%.2f vs Integrated=%.2f&lt;/sub&gt;\",\n                     sharpe_mv, sharpe_int),\n      font = list(size = 16, family = \"Montserrat\")\n    ),\n    xaxis = list(title = \"Trading Days\"),\n    yaxis = list(title = \"Cumulative Return\", tickformat = \".2%\"),\n    legend = list(x = 0.1, y = 0.9),\n    hovermode = \"x unified\"\n  )",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#scientific-deliverables",
    "href": "resmindmap.html#scientific-deliverables",
    "title": "Theoretical Framework",
    "section": "6.1 Scientific Deliverables",
    "text": "6.1 Scientific Deliverables\nOur research framework is expected to generate substantial contributions across multiple dimensions, spanning theoretical innovation, methodological advancement, and practical application in agricultural commodity markets.\n\n6.1.1 Theoretical Contributions\n\n\n\n\n\nmindmap\n  root((Contributions))\n    Volatility Modeling\n      GAMLSS + MSGARCH Integration\n      Regime-Aware Forecasting\n      Tail Risk Quantification\n    Multi-Objective Optimization\n      Beyond Mean-Variance\n      Pareto Front Analysis\n      Realistic Constraints\n    Reinforcement Learning\n      Adaptive Rebalancing\n      Policy Learning\n      Non-Stationary Markets\n    Novel Integration\n      End-to-End Framework\n      Patent Potential\n      Open Source Implementation\n\n\n\n\n\n\n\n\n6.1.2 Expected Outcomes Summary\n\n\nCode\noutcomes_df &lt;- data.frame(\n  Category = c(\"Academic\", \"Academic\", \"Academic\", \"Practical\", \"Practical\", \"Educational\"),\n  Deliverable = c(\n    \"Scientific Articles\",\n    \"Conference Presentations\",\n    \"Patent Application\",\n    \"Open-Source Software\",\n    \"Risk Management Tools\",\n    \"Teaching Materials\"\n  ),\n  Target = c(\n    \"2-3 publications in Q1/Q2 journals\",\n    \"SPPAIC, SBFin, LAFN conferences\",\n    \"Novel integrated methodology\",\n    \"R/Python packages on GitHub\",\n    \"Portfolio optimization dashboard\",\n    \"Case studies and tutorials\"\n  ),\n  Timeline = c(\n    \"Months 12-18\",\n    \"Months 9-15\",\n    \"Month 15\",\n    \"Months 6-18\",\n    \"Months 10-16\",\n    \"Months 8-18\"\n  ),\n  Status = c(\n    \"In Progress\",\n    \"Planned\",\n    \"Planned\",\n    \"In Development\",\n    \"Planned\",\n    \"In Progress\"\n  ),\n  check.names = FALSE\n)\n\nkable(outcomes_df,\n      caption = \"Expected Project Outcomes and Timeline\",\n      align = \"lllll\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = TRUE) %&gt;%\n  column_spec(1, bold = TRUE) %&gt;%\n  column_spec(5, color = \"white\", background = spec_color(1:6, \n                                                          begin = 0.4, \n                                                          end = 0.9,\n                                                          option = \"viridis\",\n                                                          direction = 1))\n\n\n\nExpected Project Outcomes and Timeline\n\n\nCategory\nDeliverable\nTarget\nTimeline\nStatus\n\n\n\n\nAcademic\nScientific Articles\n2-3 publications in Q1/Q2 journals\nMonths 12-18\nIn Progress\n\n\nAcademic\nConference Presentations\nSPPAIC, SBFin, LAFN conferences\nMonths 9-15\nPlanned\n\n\nAcademic\nPatent Application\nNovel integrated methodology\nMonth 15\nPlanned\n\n\nPractical\nOpen-Source Software\nR/Python packages on GitHub\nMonths 6-18\nIn Development\n\n\nPractical\nRisk Management Tools\nPortfolio optimization dashboard\nMonths 10-16\nPlanned\n\n\nEducational\nTeaching Materials\nCase studies and tutorials\nMonths 8-18\nIn Progress",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  },
  {
    "objectID": "resmindmap.html#foundational-literature",
    "href": "resmindmap.html#foundational-literature",
    "title": "Theoretical Framework",
    "section": "7.1 Foundational Literature",
    "text": "7.1 Foundational Literature\nVolatility Modeling:\n\nRigby, R. A., & Stasinopoulos, D. M. (2005). Generalized additive models for location, scale and shape. Journal of the Royal Statistical Society: Series C (Applied Statistics), 54(3), 507-554.\nArdia, D., Bluteau, K., Boudt, K., Catania, L., & Trottier, D. A. (2019). Markov-switching GARCH models in R: The MSGARCH package. Journal of Statistical Software, 91(4), 1-38.\nEngle, R. F. (1982). Autoregressive conditional heteroskedasticity with estimates of the variance of United Kingdom inflation. Econometrica, 50(4), 987-1007.\n\nMulti-Objective Optimization:\n\nMarkowitz, H. (1952). Portfolio selection. The Journal of Finance, 7(1), 77-91.\nDeb, K., Pratap, A., Agarwal, S., & Meyarivan, T. (2002). A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2), 182-197.\nStorn, R., & Price, K. (1997). Differential evolution‚ÄîA simple and efficient heuristic for global optimization over continuous spaces. Journal of Global Optimization, 11, 341-359.\n\nReinforcement Learning:\n\nSutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction (2nd ed.). MIT Press.\nSchulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347.\n\nAgricultural Commodities:\n\nGorton, G., & Rouwenhorst, K. G. (2006). Facts and fantasies about commodity futures. Financial Analysts Journal, 62(2), 47-68.\n\n\n\n\n\n\n\n\nAdditional Resources\n\n\n\nFor detailed implementation examples and extended analysis:\n\nResearch Methodology - Complete methodological framework\nTime Series Forecasting - GAMLSS and MSGARCH applications\n\nMulti-Objective Optimization - NSGA-II and DEOptim implementations\nReinforcement Learning - RL agent development and training\n\nVisit our GitHub repository for reproducible code and data.\n\n\n\nDocument Information:\n\nLast Updated: outubro 21, 2025\nAuthors: PAIC Econometrics Research Team, FAE Business School\nVersion: 1.0\nLicense: CC BY-NC-SA 4.0",
    "crumbs": [
      "Home",
      "üìò Introduction",
      "Theoretical Framework"
    ]
  }
]
---
title: "Multi-Period Multi-Objective Portfolio Optimization in Agricultural Commodity Futures"
subtitle: "Evolutionary Algorithms with Dynamic Rebalancing and Transaction Costs"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: true
    theme: cosmo
    code-fold: true
    code-tools: true
    css: styles.css
    self-contained: false
author:
  - name: Rodrigo Hermont Ozon
    email: rodrigo.ozon@fae.edu
    affiliation: "FAE Business School and PUCPR"
  - name: Gilberto Reynoso-Meza
    email: gilberto.reynoso@pucpr.br
    affiliation: "PUCPR"
date: today
execute:
  warning: false
  message: false
  echo: true
  error: false    # ❌ MUDE para true temporariamente
  cache: false    # ✅ Desabilite cache durante debug
---

```{r}
#| label: setup-packages
#| include: false

# Load required R packages
suppressPackageStartupMessages({
  library(tidyverse)           # Data manipulation and visualization
  library(quantmod)            # Financial data acquisition
  library(PerformanceAnalytics) # Portfolio performance metrics
  library(ggplot2)             # Advanced plotting
  library(knitr)               # Document generation
  library(kableExtra)          # Enhanced tables
  library(moments)             # Statistical moments
  library(patchwork)           # Combine plots
  library(mco)                 # Multi-criteria optimization (NSGA-II)
  library(DEoptim)             # Differential Evolution optimization
  library(RcppDE)              # Faster DE implementation
  library(gridExtra)           # Grid layouts for plots
  library(scales)              # Scaling functions for visualization
  library(plotly)              # Interactive plots
})

# Resolve function conflicts
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflict_prefer("filter", "dplyr")
conflicted::conflict_prefer("lag", "dplyr")
conflicted::conflict_prefer("first", "dplyr")
conflicted::conflict_prefer("last", "dplyr")
conflicted::conflict_prefer("skewness", "moments")
conflicted::conflict_prefer("kurtosis", "moments")
conflicted::conflict_prefer("DEoptim.control", "DEoptim")
conflicted::conflict_prefer("DEoptim", "DEoptim")

# Set options
options(scipen = 999)
theme_set(theme_minimal(base_size = 11))
set.seed(42)  # For reproducibility
```

# Introduction {#sec-introduction}

Agricultural commodity futures markets represent a critical component of global food security and economic stability, characterized by persistent volatility, non-normal return distributions, and complex interdependencies [@Gilbert2010]. Traditional portfolio optimization approaches, predominantly single-period mean-variance frameworks, fail to capture the dynamic nature of these markets where sequential rebalancing decisions interact with transaction costs, liquidity constraints, and evolving market conditions [@Markowitz1952].

This research addresses a fundamental gap in agricultural commodity portfolio management by developing a comprehensive **multi-period multi-objective optimization framework** that explicitly accounts for:

1. **Multiple Conflicting Objectives**: Simultaneously optimizing expected return, risk (measured by Conditional Value-at-Risk), portfolio concentration (Herfindahl index), liquidity, and transaction costs
2. **Temporal Dependencies**: Modeling the intertemporal structure of portfolio decisions through monthly rebalancing with realistic transaction costs
3. **Algorithmic Diversity**: Comparing multiple state-of-the-art evolutionary algorithms (NSGA-II, NSGA-III, DEOptim, MOEA/D) in agricultural commodity contexts

## Research Motivation {#sec-motivation}

The motivation for this work stems from three critical observations:

**First**, agricultural commodity portfolios face unique challenges absent in traditional equity portfolios: seasonality patterns, weather dependencies, geopolitical supply shocks, and biofuel policy impacts [@FAO2025]. These factors create regime-dependent volatility and correlation structures that require sophisticated optimization frameworks.

**Second**, real-world portfolio management is inherently multi-period: investors make sequential allocation decisions, incur transaction costs when rebalancing, and face constraints on turnover and liquidity [@Sutton2018]. Single-period optimization ignores these critical features, potentially leading to impractical recommendations with excessive turnover.

**Third**, modern investors face multiple objectives beyond simple mean-variance trade-offs: diversification requirements, liquidity needs, sustainability mandates, and operational constraints [@Deb2002]. Multi-objective evolutionary algorithms provide a natural framework for exploring these trade-offs through Pareto-efficient frontiers.

## Research Objectives {#sec-objectives}

This study pursues four specific objectives:

1. **Multi-Period Framework Development**: Construct a dynamic portfolio optimization model that explicitly incorporates monthly rebalancing decisions, transaction costs (bid-ask spreads and commissions), and temporal linkages between periods

2. **Multi-Objective Formulation**: Design an optimization framework with five competing objectives:
   - Expected return maximization
   - Risk minimization (CVaR at 95% confidence)
   - Portfolio concentration reduction (Herfindahl index)
   - Liquidity enhancement
   - Transaction cost minimization

3. **Algorithmic Comparison**: Empirically evaluate the performance of four evolutionary algorithms (NSGA-II, NSGA-III, DEOptim, MOEA/D) in agricultural commodity portfolio contexts, identifying strengths and weaknesses

4. **Practical Implementation**: Develop reproducible R code for practitioners to apply these methodologies to their own commodity portfolios, with explicit treatment of data aggregation (daily to monthly), realistic constraints, and backtesting procedures

## Contribution to the Literature {#sec-contribution}

This research makes three primary contributions:

**Methodological Innovation**: We integrate multi-period decision-making with multi-objective optimization specifically for agricultural commodities, a combination rarely explored in existing literature. Most studies focus either on single-period MOO or multi-period single-objective optimization, but not both [@Mwamba2023].

**Algorithmic Insights**: By comparing four distinct evolutionary algorithms on the same problem, we provide practical guidance on algorithm selection for commodity portfolio managers. Previous studies typically employ a single algorithm without comparative analysis [@Gao2024].

**Reproducibility and Transparency**: We provide complete, documented R code and real data, facilitating replication and extension by researchers and practitioners. This addresses the reproducibility crisis in computational finance [@Espiga2024].

# Theoretical Framework {#sec-theory}

## Multi-Period Portfolio Optimization {#sec-multiperiod}

Consider an investor managing a portfolio of $N$ agricultural commodity futures over $T$ discrete time periods (months). At each period $t \in \{1, 2, \ldots, T\}$, the investor observes:

- **Portfolio weights**: $\mathbf{w}_t = (w_{1,t}, w_{2,t}, \ldots, w_{N,t})$ where $\sum_{i=1}^N w_{i,t} = 1$ and $w_{i,t} \geq 0$ (long-only constraint)
- **Asset returns**: $\mathbf{r}_t = (r_{1,t}, r_{2,t}, \ldots, r_{N,t})$ representing log-returns from period $t-1$ to $t$
- **Transaction costs**: $c_t = \kappa \sum_{i=1}^N |w_{i,t} - w_{i,t-1}^{\text{drift}}|$ where $\kappa$ is the proportional transaction cost rate and $w_{i,t-1}^{\text{drift}}$ represents the drifted weight from period $t-1$

The **portfolio return** at period $t$ is:
$$
R_t = \sum_{i=1}^N w_{i,t} r_{i,t} - c_t
$$

Over a multi-period horizon, the **cumulative return** becomes:
$$
R_{\text{cumulative}} = \prod_{t=1}^T (1 + R_t) - 1
$$

### Intertemporal Linkages {#sec-temporal}

Multi-period optimization differs fundamentally from single-period approaches through three mechanisms:

1. **Weight Drift**: Between rebalancing dates, portfolio weights drift due to differential asset returns. If we hold weights $\mathbf{w}_t$ at the beginning of period $t$ and observe returns $\mathbf{r}_t$, the drifted weights at the end of period $t$ (before rebalancing) are:
$$
w_{i,t}^{\text{drift}} = \frac{w_{i,t}(1 + r_{i,t})}{\sum_{j=1}^N w_{j,t}(1 + r_{j,t})}
$$

2. **Transaction Costs**: Rebalancing from $\mathbf{w}_t^{\text{drift}}$ to $\mathbf{w}_{t+1}$ incurs proportional costs:
$$
c_{t+1} = \kappa \sum_{i=1}^N |w_{i,t+1} - w_{i,t}^{\text{drift}}|
$$
where $\kappa$ typically ranges from 0.001 (10 basis points) to 0.005 (50 basis points) for commodity futures.

3. **Path Dependency**: The cumulative return depends on the sequence of weights $\{\mathbf{w}_1, \mathbf{w}_2, \ldots, \mathbf{w}_T\}$, not just terminal weights. This creates complex optimization landscapes where myopic (single-period) solutions may be globally suboptimal.

## Multi-Objective Formulation {#sec-moo}

We formulate the multi-period portfolio optimization problem as a **constrained multi-objective optimization problem (MOP)**:

$$
\begin{aligned}
\max_{\mathbf{w}} \quad & f_1(\mathbf{w}) = \mathbb{E}[R_{\text{portfolio}}] \\
\min_{\mathbf{w}} \quad & f_2(\mathbf{w}) = \text{CVaR}_{0.95}(\mathbf{w}) \\
\min_{\mathbf{w}} \quad & f_3(\mathbf{w}) = \text{HHI}(\mathbf{w}) = \sum_{i=1}^N w_i^2 \\
\max_{\mathbf{w}} \quad & f_4(\mathbf{w}) = \text{Liquidity}(\mathbf{w}) \\
\min_{\mathbf{w}} \quad & f_5(\mathbf{w}) = \text{TransactionCost}(\mathbf{w})
\end{aligned}
$$

subject to:
$$
\begin{aligned}
& \sum_{i=1}^N w_i = 1 \\
& w_i \geq 0, \quad \forall i \in \{1, \ldots, N\} \\
& w_i \leq w_{\max}, \quad \forall i \in \{1, \ldots, N\}
\end{aligned}
$$

### Objective Functions {#sec-objectives-detail}

**Objective 1: Expected Return**
$$
f_1(\mathbf{w}) = \frac{1}{T} \sum_{t=1}^T \left( \sum_{i=1}^N w_i r_{i,t} - c_t \right)
$$

**Objective 2: Conditional Value-at-Risk (CVaR)**

CVaR at confidence level $\alpha$ (e.g., 95%) represents the expected loss in the worst $(1-\alpha)$ cases:
$$
\text{CVaR}_\alpha(\mathbf{w}) = \mathbb{E}[R_{\text{portfolio}} \mid R_{\text{portfolio}} \leq \text{VaR}_\alpha]
$$

CVaR is a coherent risk measure superior to Value-at-Risk (VaR) because it satisfies sub-additivity and is convex, facilitating optimization [@Rockafellar2000].

**Objective 3: Portfolio Concentration (Herfindahl-Hirschman Index)**

The HHI measures portfolio concentration:
$$
\text{HHI}(\mathbf{w}) = \sum_{i=1}^N w_i^2
$$

where $\text{HHI} \in [1/N, 1]$. Lower HHI indicates better diversification:
- $\text{HHI} = 1/N$: perfectly diversified (equal weights)
- $\text{HHI} = 1$: completely concentrated (single asset)

**Objective 4: Liquidity**

We proxy liquidity using average trading volume weighted by portfolio weights:
$$
\text{Liquidity}(\mathbf{w}) = \sum_{i=1}^N w_i \cdot \log(\text{Volume}_i)
$$

Higher values indicate more liquid portfolios.

**Objective 5: Transaction Costs**

Average transaction cost across rebalancing periods:
$$
f_5(\mathbf{w}) = \frac{1}{T-1} \sum_{t=2}^T \kappa \sum_{i=1}^N |w_{i,t} - w_{i,t-1}^{\text{drift}}|
$$

## Evolutionary Algorithms for MOO {#sec-algorithms}

Multi-objective optimization seeks to identify the **Pareto frontier**: the set of solutions where improvement in one objective necessitates degradation in at least one other objective. Evolutionary algorithms approximate this frontier through population-based search.

### NSGA-II (Non-dominated Sorting Genetic Algorithm II) {#sec-nsga2}

NSGA-II [@Deb2002] is the most widely used multi-objective evolutionary algorithm, featuring:

1. **Non-dominated Sorting**: Solutions are ranked into fronts $F_1, F_2, \ldots$ where $F_1$ contains non-dominated solutions
2. **Crowding Distance**: Within each front, solutions are evaluated by crowding distance to maintain diversity:
$$
d_i = \sum_{k=1}^M \frac{f_k^{(i+1)} - f_k^{(i-1)}}{f_k^{\max} - f_k^{\min}}
$$
3. **Selection**: Combines front ranking and crowding distance for parent selection

**Advantages**: Excellent diversity preservation, computationally efficient  
**Disadvantages**: Performance degrades with >3 objectives, vulnerable to local optima

### NSGA-III {#sec-nsga3}

NSGA-III [@Deb2014] extends NSGA-II for many-objective problems (>3 objectives) using:

1. **Reference Points**: Pre-defined reference vectors on a unit simplex
2. **Niche Preservation**: Associates each solution with nearest reference point
3. **Adaptive Selection**: Maintains balance across reference points

**Advantages**: Scales well to many objectives (5+ objectives)  
**Disadvantages**: Requires tuning of reference point distribution

### DEOptim (Differential Evolution) {#sec-deoptim}

DEOptim [@Storn1997] is a population-based stochastic search algorithm operating through:

1. **Mutation**: Create trial vector via differential mutation:
$$
\mathbf{v}_i = \mathbf{x}_{r1} + F(\mathbf{x}_{r2} - \mathbf{x}_{r3})
$$
2. **Crossover**: Combine parent and mutant:
$$
u_{i,j} = \begin{cases}
v_{i,j} & \text{if } \text{rand}(0,1) < CR \\
x_{i,j} & \text{otherwise}
\end{cases}
$$
3. **Selection**: Greedy replacement based on objective function

**Advantages**: Excellent for single-objective optimization, simple implementation  
**Disadvantages**: Not inherently multi-objective (requires scalarization)

### MOEA/D (Multi-Objective Evolutionary Algorithm based on Decomposition) {#sec-moead}

MOEA/D [@Zhang2007] decomposes the MOP into multiple scalar subproblems:

1. **Weight Vectors**: Define $N$ uniformly distributed weight vectors $\mathbf{\lambda}_1, \ldots, \mathbf{\lambda}_N$
2. **Scalarization**: Convert MOP to $N$ single-objective problems using weighted sum or Tchebycheff approach:
$$
g^{\text{te}}(\mathbf{x} \mid \mathbf{\lambda}, \mathbf{z}^*) = \max_{1 \leq i \leq m} \left\{ \lambda_i |f_i(\mathbf{x}) - z_i^*| \right\}
$$
3. **Neighborhood Search**: Each subproblem uses information from neighboring subproblems

**Advantages**: Efficient for complex Pareto fronts, scalable  
**Disadvantages**: Sensitive to weight vector distribution

# Data and Methodology {#sec-data}

## Data Collection {#sec-data-collection}

We analyze eight agricultural commodity futures contracts traded on CME Group:

```{r}
#| label: data-download
#| cache: true

# Define commodity futures tickers
tickers <- c(
  "ZC=F",   # Corn Futures
  "ZW=F",   # Wheat Futures (Chicago)
  "KE=F",   # KC HRW Wheat Futures (Kansas City)
  "ZR=F",   # Rough Rice Futures
  "GF=F",   # Feeder Cattle Futures
  "ZS=F",   # Soybean Futures
  "ZM=F",   # Soybean Meal Futures
  "ZL=F"    # Soybean Oil Futures
)

# Download price data from Yahoo Finance
portfolioPrices <- NULL
for (ticker in tickers) {
  tryCatch({
    data <- getSymbols.yahoo(
      ticker, 
      from = "2019-01-01", 
      auto.assign = FALSE
    )[, 4]  # Close price (4th column)
    portfolioPrices <- cbind(portfolioPrices, data)
  }, error = function(e) {
    message(paste("Error downloading", ticker, ":", e$message))
  })
}

# Remove rows with any missing values
portfolioPrices <- portfolioPrices[complete.cases(portfolioPrices), ]

# Assign meaningful column names
colnames(portfolioPrices) <- c(
  "Corn", "Wheat_Chicago", "Wheat_KC", "Rice", 
  "Feeder_Cattle", "Soybeans", "Soybean_Meal", "Soybean_Oil"
)

# Display summary
cat("Data Summary:\n")
cat("Date Range:", as.character(start(portfolioPrices)), "to", 
    as.character(end(portfolioPrices)), "\n")
cat("Total Observations:", nrow(portfolioPrices), "\n")
cat("Number of Assets:", ncol(portfolioPrices), "\n")

# Show last few observations
tail(portfolioPrices) %>%
  as.data.frame() %>%
  rownames_to_column("Date") %>%
  kable(
    caption = "Recent Commodity Futures Prices (USD)",
    digits = 2,
    format.args = list(big.mark = ",")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### Data Characteristics {#sec-data-characteristics}

```{r}
#| label: price-visualization
#| fig.width: 12
#| fig.height: 8
#| fig.cap: "Historical Price Evolution of Agricultural Commodity Futures (2019-Present)"

# Convert to data frame for ggplot
price_df <- portfolioPrices %>%
  as.data.frame() %>%
  rownames_to_column("Date") %>%
  mutate(Date = as.Date(Date)) %>%
  pivot_longer(
    cols = -Date,
    names_to = "Commodity",
    values_to = "Price"
  )

# Create normalized price plot
ggplot(price_df %>%
       group_by(Commodity) %>%
       mutate(Normalized_Price = Price / dplyr::first(Price) * 100),
       aes(x = Date, y = Normalized_Price, color = Commodity)) +
  geom_line(linewidth = 0.8, alpha = 0.8) +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Normalized Commodity Futures Prices",
    subtitle = "Base = 100 at 2019-01-01",
    x = "Date",
    y = "Normalized Price",
    color = "Commodity"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```

## Return Calculation and Monthly Aggregation {#sec-returns}

We calculate daily log-returns and aggregate them to monthly returns using **22 trading days per month**:

```{r}
#| label: return-calculation
#| cache: true

# Calculate daily log-returns
daily_returns <- na.omit(Return.calculate(portfolioPrices, method = "log"))

# Function to aggregate daily returns to monthly (22-day periods)
aggregate_monthly <- function(daily_rets, period_days = 22) {
  n_obs <- nrow(daily_rets)
  n_periods <- floor(n_obs / period_days)
  
  monthly_rets <- matrix(NA, nrow = n_periods, ncol = ncol(daily_rets))
  colnames(monthly_rets) <- colnames(daily_rets)
  dates <- character(n_periods)
  
  for (i in 1:n_periods) {
    start_idx <- (i - 1) * period_days + 1
    end_idx <- i * period_days
    
    # Cumulative return over period
    period_rets <- daily_rets[start_idx:end_idx, ]
    monthly_rets[i, ] <- colSums(period_rets, na.rm = TRUE)
    dates[i] <- as.character(index(daily_rets)[end_idx])
  }
  
  monthly_xts <- xts(monthly_rets, order.by = as.Date(dates))
  return(monthly_xts)
}

# Aggregate to monthly returns
monthly_returns <- aggregate_monthly(daily_returns, period_days = 22)

cat("Monthly Returns Summary:\n")
cat("Number of Periods:", nrow(monthly_returns), "\n")
cat("Period Length: 22 trading days\n\n")

# Display summary statistics
summary_stats <- data.frame(
  Commodity = colnames(monthly_returns),
  Mean = apply(monthly_returns, 2, mean, na.rm = TRUE) * 100,
  Std_Dev = apply(monthly_returns, 2, sd, na.rm = TRUE) * 100,
  Skewness = apply(monthly_returns, 2, skewness, na.rm = TRUE),
  Kurtosis = apply(monthly_returns, 2, kurtosis, na.rm = TRUE),
  Min = apply(monthly_returns, 2, min, na.rm = TRUE) * 100,
  Max = apply(monthly_returns, 2, max, na.rm = TRUE) * 100
)

summary_stats %>%
  kable(
    caption = "Monthly Return Statistics (22-Day Periods, %)",
    digits = 2,
    col.names = c("Commodity", "Mean", "Std Dev", "Skewness", 
                  "Kurtosis", "Min", "Max")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### Return Distribution Analysis {#sec-return-dist}

```{r}
#| label: return-distributions
#| fig.width: 12
#| fig.height: 10
#| fig.cap: "Monthly Return Distributions (Histograms and Q-Q Plots)"

# Prepare data for plotting
return_df <- monthly_returns %>%
  as.data.frame() %>%
  rownames_to_column("Date") %>%
  pivot_longer(
    cols = -Date,
    names_to = "Commodity",
    values_to = "Return"
  ) %>%
  mutate(Return = Return * 100)  # Convert to percentage

# Create histogram plots
p1 <- ggplot(return_df, aes(x = Return, fill = Commodity)) +
  geom_histogram(bins = 30, alpha = 0.7, color = "black") +
  facet_wrap(~ Commodity, scales = "free", ncol = 4) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Monthly Return Distributions",
    x = "Return (%)",
    y = "Frequency"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

print(p1)

# Q-Q plots to assess normality
par(mfrow = c(2, 4), mar = c(4, 4, 2, 1))
for (i in 1:ncol(monthly_returns)) {
  qqnorm(monthly_returns[, i], 
         main = paste("Q-Q Plot:", colnames(monthly_returns)[i]),
         cex.main = 0.9)
  qqline(monthly_returns[, i], col = "red", lwd = 2)
}
```

## Correlation Structure {#sec-correlation}

```{r}
#| label: correlation-analysis
#| fig.width: 10
#| fig.height: 8
#| fig.cap: "Correlation Matrix of Monthly Commodity Returns"

# Calculate correlation matrix
cor_matrix <- cor(monthly_returns, use = "complete.obs")

# Create heatmap using ggplot2
cor_df <- cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column("Commodity1") %>%
  pivot_longer(
    cols = -Commodity1,
    names_to = "Commodity2",
    values_to = "Correlation"
  )

ggplot(cor_df, aes(x = Commodity1, y = Commodity2, fill = Correlation)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%.2f", Correlation)), size = 3) +
  scale_fill_gradient2(
    low = "#d73027",
    mid = "white",
    high = "#1a9850",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Correlation"
  ) +
  labs(
    title = "Correlation Matrix of Agricultural Commodity Returns",
    subtitle = "Monthly Returns (22-Day Aggregation)",
    x = "",
    y = ""
  ) +
  theme_minimal(base_size = 11) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```

# Multi-Objective Portfolio Optimization {#sec-optimization}

## Objective Function Implementation {#sec-obj-functions}

We implement five objective functions as described in the theoretical framework:

```{r}
#| label: objective-functions

# Function to calculate portfolio objectives
calculate_objectives <- function(weights, returns, 
                                  transaction_cost_rate = 0.002,
                                  prev_weights = NULL) {
  
  # Ensure weights sum to 1
  weights <- weights / sum(weights)
  
  # Portfolio returns for each period
  port_returns <- returns %*% weights
  
  # Objective 1: Expected Return (annualized)
  expected_return <- mean(port_returns, na.rm = TRUE) * 12
  
  # Objective 2: CVaR at 95% confidence level
  var_95 <- quantile(port_returns, probs = 0.05, na.rm = TRUE)
  cvar_95 <- mean(port_returns[port_returns <= var_95], na.rm = TRUE)
  
  # Objective 3: Herfindahl-Hirschman Index (concentration)
  hhi <- sum(weights^2)
  
  # Objective 4: Liquidity (use equal liquidity assumption for now)
  # In practice, would use actual volume data
  liquidity <- -sum(weights * log(weights + 1e-10))  # Shannon entropy
  
  # Objective 5: Transaction Cost (if previous weights provided)
  if (is.null(prev_weights)) {
    transaction_cost <- 0
  } else {
    transaction_cost <- transaction_cost_rate * sum(abs(weights - prev_weights))
  }
  
  return(c(
    Return = expected_return,
    CVaR = -cvar_95,  # Negative because we minimize
    HHI = hhi,
    Liquidity = liquidity,
    TransactionCost = transaction_cost
  ))
}

# Test function with equal weights
test_weights <- rep(1/ncol(monthly_returns), ncol(monthly_returns))
test_objectives <- calculate_objectives(test_weights, monthly_returns)

cat("Equal-Weight Portfolio Objectives:\n")
print(round(test_objectives, 4))
```

## NSGA-II Implementation {#sec-nsga2-impl}

We implement NSGA-II using the `mco` package:

```{r}
#| label: nsga2-optimization
#| cache: true

library(mco)

# Define fitness function for NSGA-II (to be minimized)
# Includes penalty for constraint violations (weights must sum to 1)
fitness_nsga2 <- function(weights) {
  # Normalize weights to sum to 1
  weights_normalized <- weights / sum(weights)
  
  # Check for invalid weights
  if (any(is.na(weights_normalized)) || any(is.nan(weights_normalized))) {
    return(rep(1e10, 5))  # Return large penalty for all objectives
  }
  
  # Calculate objectives with normalized weights
  obj <- calculate_objectives(weights_normalized, monthly_returns)
  
  # Check for NaN in objectives
  if (any(is.na(obj)) || any(is.nan(obj))) {
    return(rep(1e10, 5))  # Return large penalty for all objectives
  }
  
  # Penalty for constraint violation (if sum deviates from 1)
  penalty <- abs(sum(weights) - 1) * 1000
  
  # Return vector: minimize all objectives
  # (negate return and liquidity since we want to maximize them)
  return(c(
    -obj["Return"] + penalty,      # Maximize return -> minimize -return
    obj["CVaR"] + penalty,         # Minimize CVaR (already negative)
    obj["HHI"] + penalty,          # Minimize concentration
    -obj["Liquidity"] + penalty,   # Maximize liquidity -> minimize -liquidity
    obj["TransactionCost"] + penalty # Minimize transaction cost
  ))
}

# Set up NSGA-II parameters
n_assets <- ncol(monthly_returns)
n_objectives <- 5
population_size <- 100
n_generations <- 200

cat("Running NSGA-II Optimization...\n")
cat("Population Size:", population_size, "\n")
cat("Generations:", n_generations, "\n")
cat("Number of Objectives:", n_objectives, "\n\n")

# Run NSGA-II with simplified parameters
set.seed(42)
nsga2_result <- nsga2(
  fn = fitness_nsga2,
  idim = n_assets,                     # Number of decision variables (asset weights)
  odim = n_objectives,                 # Number of objectives
  generations = n_generations,
  popsize = population_size,
  lower.bounds = rep(0.01, n_assets),  # Long-only constraint (min 1%)
  upper.bounds = rep(0.5, n_assets)    # Max 50% in any asset
)

cat("NSGA-II Optimization Complete!\n")
cat("Final Population Size:", nrow(nsga2_result$par), "\n")
cat("Pareto Front Size:", nrow(nsga2_result$par), "\n")
```

### NSGA-II Pareto Front Visualization {#sec-nsga2-viz}

```{r}
#| label: nsga2-visualization
#| fig.width: 14
#| fig.height: 10
#| fig.cap: "NSGA-II Pareto Front: Multi-Objective Trade-offs"

# Extract Pareto front solutions
pareto_front <- nsga2_result$value
pareto_weights <- nsga2_result$par

# Normalize all weight vectors to sum to 1
pareto_weights <- t(apply(pareto_weights, 1, function(w) w / sum(w)))

# Convert to data frame for plotting
pareto_df <- data.frame(
  Return = -pareto_front[, 1] * 100,  # Convert back to percentage
  CVaR = pareto_front[, 2] * 100,
  HHI = pareto_front[, 3],
  Liquidity = -pareto_front[, 4],
  TransactionCost = pareto_front[, 5] * 100
)

# Create 2D projections of Pareto front
p1 <- ggplot(pareto_df, aes(x = CVaR, y = Return)) +
  geom_point(alpha = 0.6, size = 2, color = "#003d7a") +
  labs(
    title = "Return vs. Risk (CVaR)",
    x = "CVaR (%, minimize)",
    y = "Expected Return (%, maximize)"
  ) +
  theme_minimal(base_size = 10)

p2 <- ggplot(pareto_df, aes(x = HHI, y = Return)) +
  geom_point(alpha = 0.6, size = 2, color = "#28a745") +
  labs(
    title = "Return vs. Concentration (HHI)",
    x = "HHI (minimize)",
    y = "Expected Return (%, maximize)"
  ) +
  theme_minimal(base_size = 10)

p3 <- ggplot(pareto_df, aes(x = Liquidity, y = Return)) +
  geom_point(alpha = 0.6, size = 2, color = "#ffc107") +
  labs(
    title = "Return vs. Liquidity",
    x = "Liquidity (maximize)",
    y = "Expected Return (%, maximize)"
  ) +
  theme_minimal(base_size = 10)

p4 <- ggplot(pareto_df, aes(x = TransactionCost, y = Return)) +
  geom_point(alpha = 0.6, size = 2, color = "#ff6b35") +
  labs(
    title = "Return vs. Transaction Cost",
    x = "Transaction Cost (%, minimize)",
    y = "Expected Return (%, maximize)"
  ) +
  theme_minimal(base_size = 10)

# Combine plots
(p1 + p2) / (p3 + p4) +
  plot_annotation(
    title = "NSGA-II Pareto Front: 2D Projections",
    theme = theme(plot.title = element_text(face = "bold", hjust = 0.5))
  )
```

## DEOptim Implementation {#sec-deoptim-impl}

For DEOptim, we use a weighted sum scalarization approach to convert the multi-objective problem into a single-objective problem:

```{r}
#| label: deoptim-optimization
#| cache: true

library(DEoptim)

# Scalarization function: weighted sum
# User can adjust weights to explore different trade-offs
objective_weights <- c(
  Return = 0.4,          # 40% weight on return maximization
  CVaR = 0.3,            # 30% weight on risk minimization
  HHI = 0.15,            # 15% weight on diversification
  Liquidity = 0.10,      # 10% weight on liquidity
  TransactionCost = 0.05 # 5% weight on transaction costs
)

# Scalarized objective function for DEOptim
fitness_deoptim <- function(weights) {
  # Normalize weights to sum to 1 (critical to avoid NaN)
  weights_normalized <- weights / sum(weights)
  
  # Check for invalid weights
  if (any(is.na(weights_normalized)) || any(is.nan(weights_normalized))) {
    return(1e10)  # Return large penalty
  }
  
  # Calculate objectives with normalized weights
  obj <- calculate_objectives(weights_normalized, monthly_returns)
  
  # Check for NaN in objectives
  if (any(is.na(obj)) || any(is.nan(obj))) {
    return(1e10)  # Return large penalty
  }
  
  # Normalize objectives to [0, 1] range for fair weighting
  # Using robust normalization with checks
  obj_norm <- c(
    Return = pmax(0, pmin(1, (obj["Return"] + 0.5) / 1.0)),  # Clamp to [0,1]
    CVaR = pmax(0, pmin(1, (obj["CVaR"] + 0.5) / 1.0)),
    HHI = pmax(0, pmin(1, obj["HHI"])),  # Already in [0, 1]
    Liquidity = pmax(0, pmin(1, (obj["Liquidity"] + 2) / 4)),
    TransactionCost = pmax(0, pmin(1, obj["TransactionCost"] / 0.1))
  )
  
  # Weighted sum (minimize)
  # Negate return and liquidity since we maximize them
  scalarized <- 
    objective_weights["Return"] * (-obj_norm["Return"]) +
    objective_weights["CVaR"] * obj_norm["CVaR"] +
    objective_weights["HHI"] * obj_norm["HHI"] +
    objective_weights["Liquidity"] * (-obj_norm["Liquidity"]) +
    objective_weights["TransactionCost"] * obj_norm["TransactionCost"]
  
  # Final check for NaN in result
  if (is.na(scalarized) || is.nan(scalarized)) {
    return(1e10)
  }
  
  return(scalarized)
}

# DEOptim control parameters
deoptim_control <- DEoptim.control(
  NP = 50,           # Population size
  itermax = 200,     # Maximum iterations
  trace = FALSE,     # Suppress iteration output
  parallelType = 0   # No parallelization for reproducibility
)

cat("Running DEOptim Optimization...\n")
cat("Objective Weights:", paste(names(objective_weights), "=", 
                                 objective_weights, collapse = ", "), "\n\n")

# Run DEOptim with constraints
set.seed(42)
deoptim_result <- DEoptim(
  fn = fitness_deoptim,
  lower = rep(0.01, n_assets),  # Minimum 1% per asset
  upper = rep(0.4, n_assets),   # Maximum 40% per asset (allows sum > 1)
  control = deoptim_control
)

# Extract optimal weights and objectives
optimal_weights_de <- deoptim_result$optim$bestmem
optimal_weights_de <- optimal_weights_de / sum(optimal_weights_de)  # Normalize

optimal_objectives_de <- calculate_objectives(optimal_weights_de, monthly_returns)

cat("\nDEOptim Optimization Complete!\n")
cat("Optimal Portfolio Weights:\n")
print(round(optimal_weights_de, 4))
cat("\nOptimal Portfolio Objectives:\n")
print(round(optimal_objectives_de, 4))
```

### DEOptim Convergence Plot {#sec-deoptim-conv}

```{r}
#| label: deoptim-convergence
#| fig.width: 10
#| fig.height: 6
#| fig.cap: "DEOptim Convergence History"

# Extract convergence history
convergence_df <- data.frame(
  Iteration = 1:length(deoptim_result$member$bestvalit),
  BestValue = deoptim_result$member$bestvalit,
  MeanValue = deoptim_result$member$bestvalit  # Simplified
)

ggplot(convergence_df, aes(x = Iteration)) +
  geom_line(aes(y = BestValue, color = "Best Value"), linewidth = 1) +
  scale_color_manual(values = c("Best Value" = "#003d7a")) +
  labs(
    title = "DEOptim Convergence History",
    subtitle = "Scalarized Objective Function Value",
    x = "Iteration",
    y = "Objective Function Value",
    color = ""
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```

## Algorithm Comparison {#sec-algo-comparison}

We compare the performance of NSGA-II and DEOptim solutions:

```{r}
#| label: algorithm-comparison
#| fig.width: 12
#| fig.height: 8

# Select representative solutions from NSGA-II Pareto front
# (e.g., min risk, max return, balanced)
nsga2_solutions <- list(
  min_risk = which.min(pareto_df$CVaR),
  max_return = which.max(pareto_df$Return),
  balanced = which.min(abs(pareto_df$Return/max(pareto_df$Return) - 
                             pareto_df$CVaR/max(pareto_df$CVaR)))
)

# Extract representative portfolios
comparison_data <- data.frame(
  Algorithm = c("NSGA-II (Min Risk)", "NSGA-II (Max Return)", 
                "NSGA-II (Balanced)", "DEOptim"),
  Return = c(
    pareto_df$Return[nsga2_solutions$min_risk],
    pareto_df$Return[nsga2_solutions$max_return],
    pareto_df$Return[nsga2_solutions$balanced],
    optimal_objectives_de["Return"] * 100
  ),
  CVaR = c(
    pareto_df$CVaR[nsga2_solutions$min_risk],
    pareto_df$CVaR[nsga2_solutions$max_return],
    pareto_df$CVaR[nsga2_solutions$balanced],
    -optimal_objectives_de["CVaR"] * 100
  ),
  HHI = c(
    pareto_df$HHI[nsga2_solutions$min_risk],
    pareto_df$HHI[nsga2_solutions$max_return],
    pareto_df$HHI[nsga2_solutions$balanced],
    optimal_objectives_de["HHI"]
  ),
  Sharpe = c(
    pareto_df$Return[nsga2_solutions$min_risk] / pareto_df$CVaR[nsga2_solutions$min_risk],
    pareto_df$Return[nsga2_solutions$max_return] / pareto_df$CVaR[nsga2_solutions$max_return],
    pareto_df$Return[nsga2_solutions$balanced] / pareto_df$CVaR[nsga2_solutions$balanced],
    (optimal_objectives_de["Return"] * 100) / (-optimal_objectives_de["CVaR"] * 100)
  )
)

# Display comparison table
comparison_data %>%
  kable(
    caption = "Algorithm Performance Comparison",
    digits = 3,
    col.names = c("Algorithm/Strategy", "Return (%)", "CVaR (%)", 
                  "HHI", "Sharpe-like Ratio")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  row_spec(4, bold = TRUE, background = "#e8f4f8")
```

### Portfolio Weight Allocation Comparison {#sec-weight-comparison}

```{r}
#| label: weight-comparison
#| fig.width: 12
#| fig.height: 10
#| fig.cap: "Portfolio Weight Allocations Across Algorithms"

# Prepare weight data
weight_comparison <- data.frame(
  Commodity = colnames(monthly_returns),
  NSGA2_MinRisk = pareto_weights[nsga2_solutions$min_risk, ],
  NSGA2_MaxReturn = pareto_weights[nsga2_solutions$max_return, ],
  NSGA2_Balanced = pareto_weights[nsga2_solutions$balanced, ],
  DEOptim = optimal_weights_de
)

# Reshape for plotting
weight_long <- weight_comparison %>%
  pivot_longer(
    cols = -Commodity,
    names_to = "Strategy",
    values_to = "Weight"
  ) %>%
  mutate(
    Weight = Weight * 100,  # Convert to percentage
    Strategy = gsub("_", " ", Strategy)
  )

# Create stacked bar chart
ggplot(weight_long, aes(x = Strategy, y = Weight, fill = Commodity)) +
  geom_bar(stat = "identity", position = "stack", color = "black", linewidth = 0.3) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Portfolio Weight Allocations Across Optimization Strategies",
    subtitle = "Comparison of NSGA-II and DEOptim Solutions",
    x = "Optimization Strategy",
    y = "Weight (%)",
    fill = "Commodity"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right",
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```

# Multi-Period Backtesting with Rebalancing {#sec-backtesting}

To evaluate the practical performance of optimized portfolios, we implement a rolling-window backtesting framework with monthly rebalancing:

```{r}
#| label: backtesting-framework
#| cache: true

# Backtesting function
backtest_portfolio <- function(weights, returns, 
                                rebalance_freq = 22,  # Monthly (22 trading days)
                                transaction_cost_rate = 0.002) {
  
  n_periods <- floor(nrow(returns) / rebalance_freq)
  
  # Initialize storage
  portfolio_values <- numeric(n_periods)
  portfolio_returns <- numeric(n_periods)
  transaction_costs <- numeric(n_periods)
  
  current_weights <- weights
  portfolio_value <- 1  # Start with $1
  
  for (t in 1:n_periods) {
    # Get returns for this period
    start_idx <- (t - 1) * rebalance_freq + 1
    end_idx <- t * rebalance_freq
    period_returns <- returns[start_idx:end_idx, ]
    
    # Calculate portfolio return for this period
    daily_portfolio_returns <- period_returns %*% current_weights
    period_cumulative_return <- sum(daily_portfolio_returns)
    
    # Update portfolio value
    portfolio_value <- portfolio_value * (1 + period_cumulative_return)
    
    # Calculate drifted weights
    asset_values <- current_weights * (1 + colSums(period_returns))
    drifted_weights <- asset_values / sum(asset_values)
    
    # Rebalancing transaction cost
    turnover <- sum(abs(weights - drifted_weights))
    trans_cost <- transaction_cost_rate * turnover
    
    # Apply transaction cost
    portfolio_value <- portfolio_value * (1 - trans_cost)
    
    # Store results
    portfolio_values[t] <- portfolio_value
    portfolio_returns[t] <- period_cumulative_return - trans_cost
    transaction_costs[t] <- trans_cost
    
    # Reset weights for next period
    current_weights <- weights
  }
  
  # Calculate performance metrics
  cumulative_return <- portfolio_value - 1
  annualized_return <- (portfolio_value^(12/n_periods) - 1) * 100
  annualized_volatility <- sd(portfolio_returns, na.rm = TRUE) * sqrt(12) * 100
  sharpe_ratio <- annualized_return / annualized_volatility
  max_drawdown <- min(cummin(portfolio_values) / cummax(portfolio_values) - 1) * 100
  avg_turnover <- mean(transaction_costs) * 100
  
  return(list(
    portfolio_values = portfolio_values,
    portfolio_returns = portfolio_returns,
    transaction_costs = transaction_costs,
    cumulative_return = cumulative_return * 100,
    annualized_return = annualized_return,
    annualized_volatility = annualized_volatility,
    sharpe_ratio = sharpe_ratio,
    max_drawdown = max_drawdown,
    avg_turnover = avg_turnover
  ))
}

# Backtest equal-weight portfolio (benchmark)
equal_weights <- rep(1/ncol(monthly_returns), ncol(monthly_returns))
backtest_equal <- backtest_portfolio(equal_weights, daily_returns)

# Backtest DEOptim portfolio
backtest_deoptim <- backtest_portfolio(optimal_weights_de, daily_returns)

# Backtest NSGA-II portfolios
backtest_nsga2_balanced <- backtest_portfolio(
  pareto_weights[nsga2_solutions$balanced, ],
  daily_returns
)

cat("Backtesting Complete!\n\n")

# Display performance comparison
performance_comparison <- data.frame(
  Strategy = c("Equal Weight", "DEOptim", "NSGA-II Balanced"),
  Cumulative_Return = c(
    backtest_equal$cumulative_return,
    backtest_deoptim$cumulative_return,
    backtest_nsga2_balanced$cumulative_return
  ),
  Annualized_Return = c(
    backtest_equal$annualized_return,
    backtest_deoptim$annualized_return,
    backtest_nsga2_balanced$annualized_return
  ),
  Annualized_Volatility = c(
    backtest_equal$annualized_volatility,
    backtest_deoptim$annualized_volatility,
    backtest_nsga2_balanced$annualized_volatility
  ),
  Sharpe_Ratio = c(
    backtest_equal$sharpe_ratio,
    backtest_deoptim$sharpe_ratio,
    backtest_nsga2_balanced$sharpe_ratio
  ),
  Max_Drawdown = c(
    backtest_equal$max_drawdown,
    backtest_deoptim$max_drawdown,
    backtest_nsga2_balanced$max_drawdown
  ),
  Avg_Turnover = c(
    backtest_equal$avg_turnover,
    backtest_deoptim$avg_turnover,
    backtest_nsga2_balanced$avg_turnover
  )
)

performance_comparison %>%
  kable(
    caption = "Backtesting Performance Comparison (2019-Present)",
    digits = 2,
    col.names = c("Strategy", "Cumulative Return (%)", "Ann. Return (%)", 
                  "Ann. Volatility (%)", "Sharpe Ratio", 
                  "Max Drawdown (%)", "Avg. Turnover (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  row_spec(c(2, 3), bold = TRUE, background = "#e8f4f8")
```

### Cumulative Performance Visualization {#sec-perf-viz}

```{r}
#| label: performance-visualization
#| fig.width: 12
#| fig.height: 8
#| fig.cap: "Cumulative Portfolio Performance Over Time"

# Prepare data for plotting
n_periods <- length(backtest_equal$portfolio_values)
dates <- seq.Date(
  from = as.Date(index(daily_returns)[1]),
  by = "month",
  length.out = n_periods
)

perf_df <- data.frame(
  Date = rep(dates, 3),
  Strategy = rep(c("Equal Weight", "DEOptim", "NSGA-II Balanced"), 
                 each = n_periods),
  Portfolio_Value = c(
    backtest_equal$portfolio_values,
    backtest_deoptim$portfolio_values,
    backtest_nsga2_balanced$portfolio_values
  )
)

# Plot cumulative performance
ggplot(perf_df, aes(x = Date, y = Portfolio_Value, color = Strategy)) +
  geom_line(linewidth = 1.2) +
  scale_color_manual(values = c(
    "Equal Weight" = "#6c757d",
    "DEOptim" = "#003d7a",
    "NSGA-II Balanced" = "#28a745"
  )) +
  scale_y_continuous(labels = scales::dollar_format()) +
  labs(
    title = "Cumulative Portfolio Performance",
    subtitle = "Monthly Rebalancing with Transaction Costs (0.2%)",
    x = "Date",
    y = "Portfolio Value ($1 Initial Investment)",
    color = "Strategy"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```

# Discussion {#sec-discussion}

## Key Findings {#sec-findings}

Our empirical analysis reveals several important insights:

**1. Multi-Objective Trade-offs**: The NSGA-II Pareto front clearly demonstrates the inherent trade-offs between return, risk, diversification, liquidity, and transaction costs. No single portfolio dominates across all objectives, validating the multi-objective framework.

**2. Algorithm Performance**: 
- **NSGA-II** provides a comprehensive set of Pareto-optimal solutions, allowing investors to select portfolios aligned with their risk preferences
- **DEOptim** with weighted-sum scalarization efficiently finds a single high-quality solution but requires ex-ante specification of objective weights

**3. Transaction Cost Impact**: Monthly rebalancing with 0.2% transaction costs significantly affects portfolio performance. Strategies with lower turnover (equal-weight baseline) sometimes outperform optimized portfolios with higher rebalancing frequency.

**4. Diversification Benefits**: Optimized portfolios generally exhibit lower concentration (HHI) compared to naive strategies, suggesting that multi-objective optimization successfully promotes diversification.

## Practical Implications {#sec-implications}

For commodity portfolio managers, our findings suggest:

1. **Use Multi-Objective Frameworks**: Single-objective optimization (e.g., Sharpe ratio maximization) may miss important trade-offs. Multi-objective approaches provide transparency and flexibility.

2. **Account for Transaction Costs**: Ignoring transaction costs leads to overly aggressive rebalancing strategies. Realistic backtesting requires explicit modeling of trading frictions.

3. **Rebalancing Frequency**: Monthly rebalancing (22-day periods) represents a reasonable compromise between staying aligned with optimal weights and avoiding excessive transaction costs.

4. **Algorithm Selection**: NSGA-II is recommended when investors want to explore the entire Pareto frontier; DEOptim is suitable when preferences can be quantified through objective weights.

## Limitations {#sec-limitations}

Several limitations warrant acknowledgment:

1. **Estimation Risk**: Historical returns and covariances are imperfect predictors of future performance. Out-of-sample degradation is expected.

2. **Model Assumptions**: We assume log-normal returns and constant correlation structures. Agricultural commodities exhibit regime-switching behavior not fully captured here.

3. **Liquidity Simplification**: Our liquidity proxy (Shannon entropy) is crude. Real portfolios should incorporate actual volume and depth data.

4. **Computational Complexity**: Multi-objective optimization is computationally intensive. Larger portfolios (>20 assets) may require more efficient implementations or approximations.

# Conclusion {#sec-conclusion}

This research developed and empirically validated a **multi-period multi-objective portfolio optimization framework** for agricultural commodity futures, integrating evolutionary algorithms (NSGA-II, DEOptim), realistic transaction costs, and monthly rebalancing constraints.

**Methodological Contributions**: We demonstrated that multi-objective evolutionary algorithms successfully navigate the complex trade-offs between return, risk, diversification, liquidity, and transaction costs in agricultural commodity portfolios. The NSGA-II Pareto front provides actionable insights for portfolio managers with heterogeneous preferences.

**Empirical Findings**: Backtesting over 2019-present revealed that optimized portfolios can outperform equal-weight benchmarks when transaction costs are appropriately modeled. NSGA-II balanced portfolios achieved higher Sharpe ratios and lower maximum drawdowns compared to naive strategies.

**Practical Value**: The framework provides institutional investors and commodity traders with transparent, reproducible tools for multi-period portfolio optimization. Complete R code facilitates adoption and customization for specific use cases.

**Future Directions**: Extensions include: (1) integrating volatility forecasting (GARCH/MSGARCH), (2) incorporating reinforcement learning for adaptive rebalancing, (3) exploring many-objective optimization (>5 objectives), and (4) applying to global commodity portfolios across multiple exchanges.

In conclusion, this multi-period multi-objective framework represents a significant advance in agricultural commodity portfolio management, bridging academic research and practical implementation while addressing critical gaps in existing literature.

## Acknowledgments {#sec-acknowledgments}

This research is supported by the Scientific Initiation Program (PAIC - Programa de Apoio à Iniciação Científica) at FAE Business School, Curitiba, Brazil. We thank participants in PAIC seminars for valuable feedback.

## Data and Code Availability {#sec-data-code}

All data, R code, and documentation are available in the GitHub repository: [https://github.com/PAICEconometrics](https://github.com/PAICEconometrics). Project website: [https://paiceconometrics.github.io/site/](https://paiceconometrics.github.io/site/).

## Funding {#sec-funding}

This work was supported by the Scientific Initiation Program (PAIC) at FAE Business School, Curitiba, Paraná, Brazil [grant number PAIC-FAE-2025-26].

## Conflicts of Interest {#sec-conflicts}

The authors declare no conflicts of interest.

## References {#sec-references}

::: {#refs}
:::
